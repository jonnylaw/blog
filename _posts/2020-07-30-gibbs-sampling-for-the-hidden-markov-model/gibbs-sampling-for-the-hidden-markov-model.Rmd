---
title: "Gibbs Sampling for the Hidden Markov Model"
description: |
  A short description of the post.
author:
  - name: Jonny Law
    url: {https://twitter.com/lawsy}
date: 07-30-2020
draft: TRUE
output:
  distill::distill_article:
    self_contained: false
categories:
  - Scala
  - Bayesian
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(jonnylaw)
library(tidyverse)
```

In this post we will consider the backward smoothing algorithm for a hidden Markov model (HMM). While exploring the derivation and implementation we will consider how to avoid the use of mutable state and implement the algorithm in a purely functional way. This post follows from the previous post discussing [hidden Markov models] and functional programming, the inference scheme developed in that post was a Metropolis-Hastings algorithm where the marginal likelihood calculated using the HMM forward algorithm.

To illustrate the ideas required to implement the backward smoothing algorithm for the HMM. As an extension, we will consider another parameter inference algorithm, a Gibbs sampling algorithm targeting the posterior distribution of the transition matrix.

The 

```{r}
state_transitions <- function(
  n_states,
  states) {
  n <- length(states)
  zeros <- matrix(0, nrow = n_states, ncol = n_states)
  
  purrr::reduce2(states[-n], states[-1], function(acc, from, to) {
    acc[from, to] <- acc[from, to] + 1
    acc
  }, .init = zeros)
}
```

```{r}
hmm_backward_step <- function(beta, y, transition_matrix, observation) {
  normalise(transition_matrix %*% (observation(y) * beta))
}

hmm_backward <- function(ys, transition_matrix, observation) {
  purrr::accumulate(
    rev(ys),
    hmm_backward_step,
    observation = observation, 
    transition_matrix = transition_matrix,
    .init = c(1, 1)
  ) %>% rev()
}

hmm_forward_backward <- function(ys, x0, transition_matrix, observation) {
  n <- length(ys)
  f <- hmm_forward(ys, x0, transition_matrix, observation)
  b <- hmm_backward(ys, transition_matrix, observation)
  purrr::map2(f, b[-(n+1)], ~ normalise(.x * .y))
}

normalise <- function(a) {
  a / sum(a)
}
```

## Simple HMM

The transition matrix used to simulate the sequence of states and observations is

$$P = \begin{pmatrix}
0.5 & 0.5 \\
0.4 & 0.6
\end{pmatrix}$$

The emission matrix used to simulate the sequence of states and observations is

$$B = \begin{pmatrix}
0.2 & 0.8 \\
0.9 & 0.1
\end{pmatrix}.$$

```{r}
P <- matrix(c(0.5, 0.5, 0.4, 0.6), byrow = T, ncol = 2)
B <- matrix(c(0.2, 0.8, 0.9, 0.1), byrow = T, ncol = 2)
simple_hmm <- hmm_simulate(300, c(1, 0), P, function(state) sample(1:2, size = 1, prob = B[state,]))

simple_hmm %>% 
  filter(time < 100) %>% 
  pivot_longer(-time, values_to = "value", names_to = "key") %>% 
  ggplot(aes(x = time, y = value)) +
  geom_step() +
  facet_wrap(~key, ncol = 1)
```

```{r filtered-state}
fwd <- hmm_forward(simple_hmm$y, x0 = c(0, 1), transition_matrix = P, observation = function(y) B[,y])
tibble(
  time = seq_len(length(fwd)),
  filtered_state = purrr::map_dbl(fwd, which.max),
  p_state1 = purrr::map_dbl(fwd, ~ .[1])
) %>% 
  inner_join(simple_hmm, by = "time") %>% 
  pivot_longer(c("x", "y", "p_state1", "filtered_state"), names_to = "key", values_to = "value") %>% 
  ggplot(aes(x = time, y = value)) +
  geom_step() +
  facet_wrap(~key, ncol = 1, scales = "free_y")
```

```{r smoothed-state}
backward <- hmm_backward(ys = simple_hmm$y, transition_matrix = P, observation = function(y) B[,y])

tibble(
  time = seq_len(length(fwd)),
  smoothed_p_state1 = map_dbl(backward, ~ .[1])[-301],
  filtered_p_state1 = purrr::map_dbl(fwd, ~ .[1])
) %>% 
  inner_join(simple_hmm, by = "time") %>% 
  pivot_longer(c("x", "y", "smoothed_p_state1", "filtered_p_state1"), names_to = "key", values_to = "value") %>% 
  ggplot(aes(x = time, y = value)) +
  geom_step() +
  facet_wrap(~key, ncol = 1, scales = "free_y")

```

## Gibbs Sampler

Calculate $p(z_t = i | z_{t+1} = j, y_{1:T})$

```{r}
hmm_backward_sample_step <- function(
   sampled_state,
   alpha,
   alpha1,
   y1,
   transition_matrix,
   observation) {
   observation_dist <- observation(y1, sampledState)
   transition <- transitionMatrix[, sampledState]

   probs <- ((observation_dist %*% transition) * alpha) / alpha1

   sample(x = seq_len(length(probs)), size = 1, prob = probs)
 }
```

Perform backward sampling for the HMM

```{r}
hmm_backward_sample <- function(ys,
                               alphas, # matrix
                               observation,
                               transition_matrix) {
 d <- ncol(alphas)
 n <- length(ys)
 sample_last <- sample(seq_len(d), size = 1, prob = alphas[n,])
 
 accumulate3(
   rev(ys),
   alphas[[-n]],
   alphas[[-1]],
   hmm_backward_step,
   observation = observation, 
   transition_matrix = transition_matrix, 
   .init = sample_last
 )
}
```

Functional Backward sampling

```{r}
accumulate_3 <- function(x, y, z, f, ..., init, direction = "forward") {
  res <- list()
  res[[1]] <- init
  for (i in seq_len(length(x) - 1) + 1) {
     res[[i]] <- f(res[[i-1]], x[[i]], y[[i]], z[[i]])
  }
  res
}
```


Sample a value of the latent-state of an HMM

```{r}
hmm_forward_backward_sample <- function(ys,
                                       x0,
                                       observation,
                                       transitionMatrix) = {
 alphas = hmm_forward(ys, x0, observation, transitionMatrix)
 hmm_backward_sample(ys, alphas, observation, transitionMatrix)
}
```

Sample a value of the transition matrix from a product of Dirichlet distributions

```{r}
sample_theta <- function(xs: Vector[Int], alpha: DenseVector[Double]): DenseMatrix[Double] = {
   val nStates = 2
   val stateTransitions = Ctmc.stateTransitions(nStates, xs)
   val out: Array[Array[Double]] = breeze.util.JavaArrayOps.dmDToArray2(stateTransitions).
     map(x => Dirichlet(alpha + DenseVector(x)).draw.data)
   breeze.util.JavaArrayOps.array2DToDm(out)
 }

 case class GibbsState(transitionMatrix: DenseMatrix[Double], xs: Vector[Int])
```

```{r}
 def gibbs_step(
   alpha,
   ys,
   x0,
   observation) {
   transitionMatrix <- sample_theta(state.xs, alpha)
   new_state <- forward_backward_sample(ys, x0, observation, transitionMatrix)
   GibbsState(transitionMatrix, newState)
 }
```

Functional sampling

```{r}
iterate_dbl <- function(init, f, ..., n)
```


```{r}
 gibbs_hmm <- function(
   alpha,
   ys,
   x0,
   observation) = {
   val nStates = length(x0)
   val transitionMatrix = new DenseMatrix(nStates, nStates, Dirichlet(alpha).sample(nStates).toArray.flatMap(_.data))
   val xs = forwardBackwardSample(ys, x0, observation, transitionMatrix)
   Iterator.iterate(GibbsState(transitionMatrix, xs))(gibbsStep(alpha, ys, x0, observation))
 }
```

## Dishonest Casino

```{r}
build_transition_matrix <- function(theta) {
  a <- theta[1]; b <- theta[2]
  matrix(c(a, 1 - a, 1 - b, b), byrow = T, nrow = 2)
}

observation <- function(y) {
  c(ifelse(y == 6, 1 / 5, 1 / 10), 1 / 6)
}

normalise <- function(a) {
  a / sum(a)
}

sim_observation <- function(x) {
  ifelse(
      x == 1, 
      sample(6, size = 1), 
      sample(6, size = 1, prob = normalise(c(rep(1, times = 5),  5)))
    )
}

transition <- function(x, P) {
  sample(2, size = 1, prob = P[x, ])
}

sim_markov <- function(n, P) {
  x <- numeric(n)
  y <- numeric(n)
  x[1] <- 1
  y[1] <- sim_observation(x[1])
  for (i in seq_len(n - 1)) {
    x[i + 1] <- transition(x[i], P)
    y[i + 1] <- sim_observation(x[i + 1])
  }
  tibble(time = seq_len(n), x, y)
}

a <- 0.3
b <- 0.1
P <- build_transition_matrix(c(a, b))
sims <- sim_markov(300, P)
```

State transitions

```{r}
state_transitions(n_states = 2, states = sims$x)
```




```{r}
simple_hmm <- read_csv("~/git/ctmc/data/simple_hmm.csv")

simple_hmm %>% 
  
```

```{r simple_hmm}
gibbs <- read_csv("~/git/ctmc/models/simple_hmm_gibbs.csv")

gibbs %>% 
  group_by(chain) %>% 
  mutate(iteration = row_number()) %>% 
  pivot_longer(c("p1", "p2", "p3", "p4"), names_to = "parameter", values_to = "value") %>% 
  jonnylaw::plot_diagnostics()
```


