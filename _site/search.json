[
  {
    "objectID": "posts/2020-05-01-hidden-markov-model/index.html",
    "href": "posts/2020-05-01-hidden-markov-model/index.html",
    "title": "Functional Programming and Hidden Markov Models",
    "section": "",
    "text": "The hidden Markov model is a state-space model with a discrete latent state, \\(x_{1:T}\\) and noisy observations \\(y_{1:T}\\). The model can be described mathematically as\n\\[p(y_{1:T}, x_{1:T}) = p(x_1)p(y_1|x_1)\\prod_{t=2}^Tp(y_t|x_t)p(x_t|x_{t-1})\\]\nWhere \\(y_{1:T} = y_1, \\dots, y_T\\) represents the sequence of observed values and \\(x_{1:T} = x_1, \\dots, x_T\\) is the sequence of latent, unobserved values. The state space is assumed to be finite and countable, \\(X \\in \\{1,\\dots,K\\}\\) and the time gaps between each observation are constant. The observation distribution can be either continuous or discrete.\nThe model can be visualised using a state-transition diagram where observed nodes are rectangular and latent nodes are circular. The arrows represent any transitions which can be made and also convey conditional independence assumptions in the Model. The state forms a first order Markov process, which means \\(p(x_t|x_{t-1},\\dots,x_1) = p(x_t|x_{t-1})\\) and each observation is conditionally independent of all others given the corresponding value of the latent state at that time, \\(y_t \\perp\\!\\!\\!\\perp y_{1:t-1},y_{t+1:T}\\)"
  },
  {
    "objectID": "posts/2020-05-01-hidden-markov-model/index.html#example-the-occasionally-dishonest-casino",
    "href": "posts/2020-05-01-hidden-markov-model/index.html#example-the-occasionally-dishonest-casino",
    "title": "Functional Programming and Hidden Markov Models",
    "section": "Example: The occasionally dishonest casino",
    "text": "Example: The occasionally dishonest casino\nThe casino can choose to use a fair dice, in which case the observation distribution is categorical with probabilities \\(p = \\{\\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}\\}\\). The casino can also choose a loaded dice which has the following probabilities, \\(p = \\{\\frac{1}{10}, \\frac{1}{10}, \\frac{1}{10}, \\frac{1}{10}, \\frac{1}{10}, \\frac{1}{5}\\}\\), hence it is more likely to roll a six with the loaded dice.\nWe want to infer when the casino is using the loaded dice, the latent state \\(x \\in \\{L, F\\}\\) for loaded and fair respectively. We assume we already know the transition matrix\n$$P =\n\\[\\begin{pmatrix}\n\n\n\\alpha & 1 - \\alpha \\\\\n1 - \\beta & \\beta\n\\end{pmatrix}\\]\n.$$\n\n\n\nThe observation distribution is \\(p(y_t|x_t = j)\\). This implies we have a two element vector since the state can take one of two values \\(j = \\{L, F\\}\\).\n\n\n\n\n\n\nWe can simulate data from this process by specifying values of the parameters, \\(\\alpha = 0.3\\) and \\(\\beta = 0.1\\). This means if the casino is using the loaded dice we will transition to the fair dice with probability \\(1 - \\alpha\\) and if the casino is using the fair dice there is a \\(1 - \\beta\\) probability of transitioning to the loaded dice. The algorithm to simulate from this Hidden Markov model is\n\nSpecify the initial state of the dice, \\(x_1 = L\\)\nSimulate an initial observation conditional on the dice used, \\(y_1 \\sim p(y_1|x_1)\\)\nSimulate the next transition by drawing from a categorical distribution with probabilities corresponding to the row of the transition matrix corresponding the current state, \\(P_{x_t, \\cdot}\\)\nSimulate an observation conditional on the state, \\(y_t \\sim p(y_t|x_t)\\)\nRepeat 3 - 4 until the desired number of realisations are simulated\n\n\n\n\nThe plot below shows 300 simulations from the occasionally dishonest casino."
  },
  {
    "objectID": "posts/2020-05-01-hidden-markov-model/index.html#filtering",
    "href": "posts/2020-05-01-hidden-markov-model/index.html#filtering",
    "title": "Functional Programming and Hidden Markov Models",
    "section": "Filtering",
    "text": "Filtering\nNow we wish to identify when the casino is using the loaded dice. We can use the forward filtering algorithm. The first step of the forward algorithm is to the prediction step:\n\\[p(x_t = k|y_{1:t-1}) = \\sum_{j=1}^K p(x_t = k|x_{t-1}=j)p(x_{t-1}=k|y_{1:t-1})\\]\nThen we observe a new value of the process \\(y_t\\), and perform the update step where we apply Bayes’ Theorem\n$$\n\\[\\begin{aligned}\n\n\np(x_t = k \\mid y_{1:t}) = p(x_t = k\\mid y_t,y_{1:t-1}) &= \\frac{p(y_{t}|x_t = k, y_{1:t-1})p(x_t = k|y_{1:t-1})}{p(y_{t})} \\\\\n&= \\frac{p(y_{t}|x_t = k)p(x_t = k|y_{1:t-1})}{\\sum_{j=1}^Kp(y_{t}|x_t = j)p(x_t = j|y_{1:t-1})}\n\\end{aligned}\\]\n$$\nWhich can be calculated recursively by defining \\(\\alpha_t(k) = p(x_t = k \\mid y_{1:t})\\) then we have the recursive update\n\\[\\begin{aligned}\n\\alpha_t(k) &= p(y_{t}|x_t = k)p(x_t = k|y_{1:t-1}) \\\\\n&= p(y_{t}|x_t = k)\\sum_{j=1}^Kp(x_t = k|x_{t-1} = j)p(x_{t-1}\\mid y_{1:t-1})\\\\\n&= p(y_{t}|x_t = k)\\sum_{j=1}^Kp(x_t = k|x_{t-1} = j)\\alpha_{t-1}(k)\n\\end{aligned}\\]\nEssentially we have use the posterior of the previous time point, \\(\\alpha_{t-1}(k)\\) as the prior for next observation. Then we advance the latent-state using the transition distribution \\(p(x_t = k|x_{t-1} = j)\\) and calculate the likelihood of the observation at time \\(t\\) using the observation distribution \\(p(y_{t}|x_t = k)\\).\nTo implement the forward algorithm in R we can use a higher-order function, a fold, from the R package purrr. A higher-order function is a function which accepts a function as an argument or returns a function instead of a value such as a double or int. This might seem strange at first, but it is very useful and quite common in statistics. Consider maximising a function using an optimisation routine, we pass in a function and the initial arguments and the optimisation function and the function is evaluated at many different values until a plausible maximum is found. This is the basis of the optim function in R.\nHigher-order functions can be motivated by considering a foundational principle of functional programming, to write pure functions which do not mutate state. A pure function is one which returns the same output value for the same function arguments. This means we can’t mutate state by sampling random numbers, write to disk or a database etc. Advanced functional programming languages, such as Haskell, encapsulates this behaviour in Monads. However, Monads and other higher-kinded types are not present in R. While we can’t use all the useful elements of functional programming in R, we can use some, such as higher-order functions.\nOne result of avoiding mutable state is that we can’t write a for-loop, since a for-loop has a counter which is mutated at each iteration (i = i + 1). To overcome this apparent obstacle we can use recursion. Consider the simple example of adding together all elements in a vector, if we are naive we can write a for-loop.\n\nseq <- 1:10\ntotal <- 0\nfor (i in seq_along(seq)) {\n  total = total + seq[i]\n}\ntotal\n\n[1] 55\n\n\nThis implementation has two variables which are mutated to calculate the final results. To avoid mutating state, we can write a recursive function which calls itself.\n\nloop <- function(total, seq) {\n  if (length(seq) == 0) {\n    total\n  } else {\n    loop(total + seq[1], seq[-1])\n  }\n}\n\nloop(0, 1:10)\n\n[1] 55\n\n\nR does not have tail-call elimination and hence this recursive function will not work with long sequences, however it does not mutate any state. We can generalise this function to be a higher-order function.\n\nfold <- function(init, seq, f) {\n  if (length(seq) == 0) {\n    init\n  } else {\n    fold(f(init, seq[1]), seq[-1], f)\n  }\n}\n\nHere the function fold applies the user-specified binary function f to the initial value init and the first element of the sequence. The result of applying f to these values is then used as the next initial value with the rest of the sequence. We can use this to calculate any binary reduction we can think of.\n\nfold(1, seq, function(x, y) x * y)\n\n[1] 3628800\n\n\nThis example is equivalent to the reduce function in purrr. purrr::reduce by default can be used to combine the elements of a vector or list using a binary function starting with the first element in the list. For instance we can calculate the sum of a vector of numbers\n\npurrr::reduce(1:10, function(x, y) x + y)\n\n[1] 55\n\n\nWe can also use the function shorthand provided in purrr, where function(x, y) x + y can be written ~ .x + .y.\nOther arguments provided to the reduce function can change its behaviour such as reversing the direction by changing the .direction argument (which will not affect the above computation, since addition is associative, ie. \\((1 + (2 + 3)) = ((1 + 2) + 3)\\)). We can also provide an initial value (.init) to the computation, instead of starting with the first (or last) element of the list.\npurrr::accumulate is similar to reduce, however it does not discard intermediate computations.\n\npurrr::accumulate(1:10, `+`)\n\n [1]  1  3  6 10 15 21 28 36 45 55\n\n\nHence, if we change the direction this will change the output.\n\npurrr::accumulate(1:10, `+`, .dir = \"backward\")\n\n [1] 55 54 52 49 45 40 34 27 19 10\n\n\nThese functions can appear strange at first, however they don’t suffer from common problems such as off-by-one errors when writing a for-loop with indexing.\nThe accumulate function can be used to write the forward algorithm by first writing a single step in the forward algorithm. The function forward_step accepts the current smoothed state at time t-1, alpha, and the observed value at time t, y. The arguments observation and P represent the observation distribution and the transition matrix respectively and remain constant in this example\n\nforward_step <- function(alpha, y, observation, P) {\n  normalise(observation(y) * t(P) %*% alpha)\n}\n\nThe forward algorithm can then be written using the accumulate function by first calculating the initial value of alpha and using this as the value .init then the function forward_step is used with the values of observation and P set. accumulate then takes uses the initial value, .init and the first value of the observations, ys (technically the second since we use the first to initialise alpha) to produce the next alpha value. This new alpha value is passed to the next invocation of forward_step along with the next observed value and so on until the observation vector is exhausted.\n\nforward <- function(ys, x0, observation, P) {\n  alpha <- normalise(observation(ys[1]) * x0)\n  purrr::accumulate(\n    ys[-1],\n    forward_step,\n    observation = observation,\n    P = P,\n    .init = alpha\n  )\n}\n\nWe assume that the dice used for the initial roll can be either loaded or fair with equal probability."
  },
  {
    "objectID": "posts/2020-05-01-hidden-markov-model/index.html#parameter-inference",
    "href": "posts/2020-05-01-hidden-markov-model/index.html#parameter-inference",
    "title": "Functional Programming and Hidden Markov Models",
    "section": "Parameter inference",
    "text": "Parameter inference\nWe can calculate the log-probability of the evidence using the forward algorithm, this is the sum of un-normalised filtering distribution\n\\[\\log p(y_{1:T}) = \\log \\sum_{i=1}^T\\sum_{j=1}^K p(x_t=j\\mid y_{1:t-1})p(y_t|x_t = j)\\]\nThis can be used in a Metropolis-Hastings algorithm to determine the posterior distribution of the parameters in the transition matrix, \\(\\alpha\\) and \\(\\beta\\). We can keep a running total of log-likelihood by returning a list from the forward step containing the log-likelihood and the posterior probability of the states given the observation.\n\nll_step <- function(state, y, observation, P) {\n  unnorm_state <- observation(y) * t(P) %*% state[[2]]\n  list(\n    state[[1]] + sum(log(unnorm_state)),\n    normalise(unnorm_state)\n  )\n}\n\nTo return only the log-likelihood we can use purrr::reduce.\n\nlog_likelihood <- function(ys, x0, observation, P) {\n  alpha <- normalise(observation(ys[1]) * x0)\n  init <- list(0, alpha)\n  purrr::reduce(ys, function(x, y) ll_step(x, y, observation, P), .init = init)[[1]]\n}\n\nWe can use this marginal-likelihood in a Metropolis-Hastings algorithm. We define the prior on the parameters of the transition matrix to be independent Gamma distributions with shape, \\(\\alpha = 3\\), and rate \\(\\beta = 3/0.1\\). The log-posterior is the sum of the log-likelihood calculated using the forward filtering algorithm and the log-prior.\n\n\n\nThe proposal distribution is a normal centered at the un-constrained value of the parameter. We use the logit function to transform \\(\\alpha\\) and \\(\\beta\\) from \\(\\operatorname{logit}:[0, 1] \\rightarrow \\mathbb{R}\\) then propose using a Normal distribution centered as the un-constrained value and proceed to transform the parameter back to the original scale using the logistic function, \\(\\operatorname{logistic}:\\mathbb{R} \\rightarrow [0, 1]\\).\n\n\n\n\n\n\nWe draw 10,000 iterations from the Metropolis algorithm, the parameter diagnostics are plotted below."
  },
  {
    "objectID": "posts/2019-02-25-sampling/index.html",
    "href": "posts/2019-02-25-sampling/index.html",
    "title": "Sampling from a distribution with a known CDF",
    "section": "",
    "text": "\\[Pr(g(U) \\leq x) = Pr(U \\leq g^{-1}(x)) = g^{-1}(x)\\]\nSince the CDF of the uniform distribution over the interval \\([0, 1]\\) is:\n$$\\[\\begin{align*}\n\n\n  F_U(u) =\n  \\begin{cases}\n    0 & u < 0 \\\\\n    u & u \\in [0, 1) \\\\\n    1 & u \\geq 1\n  \\end{cases}\n\\end{align*}\\]$$\nThen \\(F_x^{-1}(X) = g(x)\\) as required. The algorithm below summarises the inverse sampling procedure.\n\nSample \\(u \\sim U[0, 1]\\)\nEvaluate \\(x = F^{-1}(u)\\)\nReturn \\(x\\)\n\nMost statistical packages will expose the quantile function for common distributions making it practical to use inverse sampling. The figure below shows a histogram of 1,000 simulated values from a \\(\\textrm{Gamma}(3, 4)\\) distribution using the inverse CDF method, the analytical density is plotted in red.\nThe figure below shows samples from \\(\\textrm{Gamma}(3, 4)\\) using the inverse CDF method plotted with the analytical PDF.\n\ninverse_cdf_sample <- function(inv_cdf) {\n  u <- runif(1)\n  inv_cdf(u)\n}\n\ninv_cdf <- function(x) qgamma(p = x, shape = 3, rate = 4)\ngamma_samples <- replicate(1000, inverse_cdf_sample(inv_cdf))\n\nggplot(tibble(gamma_samples)) +\n  geom_histogram(aes(x = gamma_samples, y = ..density..), alpha = 0.4) +\n  stat_function(\n    fun = function(x) dgamma(x, shape = 3, rate = 4),\n    aes(colour = \"Gamma Density\")\n  ) +\n  theme(\n    text = element_text(size = 12), legend.title = element_blank(),\n    legend.text = element_text(size = rel(1.0)), legend.position = c(0.8, 0.8)\n  ) +\n  ylab(\"density\") +\n  xlab(\"value\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{law2019,\n  author = {Jonny Law},\n  title = {Sampling from a Distribution with a Known {CDF}},\n  date = {2019-02-25},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJonny Law. 2019. “Sampling from a Distribution with a Known\nCDF.” February 25, 2019."
  },
  {
    "objectID": "posts/2019-04-16-multi-armed-bandits/index.html",
    "href": "posts/2019-04-16-multi-armed-bandits/index.html",
    "title": "Multi-armed Bandits in Scala",
    "section": "",
    "text": "A Multi-armed Bandit\nA multi-armed bandit is an analogy taken from the one-armed bandit slot machines where a lever is pulled and the player has an unknown probability of a prize. A multi-armed bandit is a generalisation, whereby the player is faced with multiple one-armed bandits each of which could have different rewards. The problem is to determine the best bandit to play. One way to determine this is to randomly pull levers to get information on the payout for each bandit. Assuming the probability of payout is constant in time, then after a period of exploration the player will be able to know which bandits pay the most.\n\n\nEpsilon Greedy Method\nOne strategy to maximise the expected long-term reward from a bandit is to choose the bandit with the largest long-term reward a fraction of the time and the rest of the time choose a bandit uniformly at random in order to continually explore the space of actions. At each time step, the reward for a given action can be calculated and the long-term reward can be calculated as the function:\n\\[Q_{t+1}(A) = Q_t(A) + \\frac{R_t(A) - Q_t(A)}{N_t(A)}\\] where \\(A\\) is the current action, \\(Q_t(A)\\) is the long-term reward at time \\(t\\) for action \\(A\\), \\(R_t(A)\\) is the instantaneous reward for action \\(A\\) at time \\(t\\) and \\(N_t(A)\\) is the total number of times action \\(A\\) has been performed by time step \\(t\\). Before writing the algorithm for the epsilon greedy algorithm, first we define a few helper functions.\nThe first is to sample a value uniformly a random from a selection of values.\ndef sample(selection: Vector[Int]): Rand[Int] = {\n    for {\n        i <- Multinomial(DenseVector.ones[Double](selection.size))\n    } yield selection(i)\n}\nIf there are multiple actions with the same long-term reward then the next action should be selected randomly from all the actions which maximise the long term reward.\ndef maxActionWithTies(longTermReward: Vector[Double]): Rand[Int] = {\n    val maxReward = longTermReward.max\n    val rewards = longTermReward.zipWithIndex.\n          filter { case (r, a) => r == maxReward }.map(_._2)\n    if (rewards.size > 1) {\n        sample(rewards)        \n    } else {\n        Rand.always(rewards.head)\n    }\n}\nThen a single step of the epsilon greedy algorithm can be written\ncase class BanditState(\n    reward: Array[Double],\n    longTermReward: Vector[Double],\n    actions: Map[Int, Int]\n)\ndef banditStep(\n    epsilon: Double,\n    reward: Int => Rand[Double],\n    selectAction: (Map[Int, Int], Vector[Double]) => Rand[Int])(s: BanditState): Rand[BanditState] = {\n    for {\n        nextAction <- selectAction(s.actions, s.longTermReward)\n        newReward <- reward(nextAction)\n        prevCount = s.actions.get(nextAction).get\n        nextCount  = prevCount + 1\n        newLongTermReward = s.longTermReward(nextAction) + (newReward - s.longTermReward(nextAction)) / nextCount\n    } yield BanditState(s.reward :+ newReward, \n                s.longTermReward.updated(nextAction, newLongTermReward),\n                s.actions.updated(nextAction, nextCount))\n}\nFirstly, we define a BanditState which contains all of the rewards \\(R_t(A)\\) for each time step, a list of length equal to the number of actions containing the long-term reward for each action. actions represents \\(N_t(A)\\) using a map from the index of the action to the count of actions. The algorithm proceeds by sampling a uniform random number, if this number is less than the chosen value of epsilon, then a random action is sampled from a Multinomial distribution with equal probabilities, otherwise the algorithm selects the action which currently has the highest long-term reward. The values are updated according to the formula above.\nTo run this algorithm for a pre-determined number of steps, realise that it is recursive and completely determined by the count and long-term reward at the previous time step. Hence it can be implemented as a Markov chain.\ndef buildActions(actions: Int): Map[Int, Int] = {\n    (0 until actions).map(a => a -> 0).toMap\n}\n\ndef epsilonGreedy(\n    epsilon: Double, \n    actions: Int, \n    reward: Int => Rand[Double],\n    n: Int): BanditState = {\n    \n    val initState = BanditState(Array(0.0), Vector.fill(10)(0.0), buildActions(actions))\n    MarkovChain(initState)(banditStep(epsilon, reward, selectGreedy(epsilon))).steps.drop(n-1).next\n}\nWe can assume that the rewards for each of the ten actions is Normally distributed and define a suitable reward function\nval qs = Gaussian(0, 1).sample(10)\n\n// The reward is selected from a N(q(A_t), 1)\ndef r(qa: Seq[Double])(action: Int): Rand[Double] = \n    Gaussian(qa(action), 1)\n    \n//  qs: IndexedSeq[Double] = Vector(\n//    -1.1319170735731177,\n//    0.5392647196381599,\n//    0.7127636875526561,\n//    0.8765526115252499,\n//    -0.9555744042626685,\n//    -0.2723645491439034,\n//    0.10029206857194808,\n//    0.3758538986470721,\n//    1.9412629812694995,\n//    1.0620845496569054\n//)\nThen the algorithm can be run for a single multi-armed bandit\nval oneBandit = epsilonGreedy(0.5, 10, r(qs), 1000)\nThe distribution of actions at the end of 1,000 steps with epsilon = 0.5 and number of actions 10 is:\n\naction_distribution <- read_csv(here::here(\"notebooks/data/action_distribution.csv\"), \n                                col_names = c(\"action\", \"count\"))\n\nRows: 10 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): action, count\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\naction_distribution %>% \n  ggplot(aes(x = action, y = count)) +\n  geom_col()\n\n\n\n\nThe mean reward at action 8 was highest at approximately 1.95, the epsilon-greedy algorithm prefers to take action 8.\n\n\nMultiple Multi-armed Bandits\nNow to see the behaviour of a typical multi-armed bandit with a constant reward function, calculate the average reward for n = 2,000 10-arm bandits each with 1,000 steps.\nVector.fill(2000)(DenseVector(bandit(0.1, 10, r(qs), 1000).reward)).\n  reduce(_ + _).\n  map(_ / 2000)\nThe average reward for each time step can then be plotted, this can be used to evaluate different choices of epsilon. Different values of epsilon can be compared and the average reward can be calculated\nval data = List(0.0, 0.1, 0.5).map ( eps => averageReward(2000, 1000, eps))\n\naverage_reward <- read_csv(here::here(\"notebooks/data/average_reward.csv\"))\n\nRows: 3003 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): epsilon, step, reward\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\naverage_reward %>% \n  ggplot(aes(x = step, y = reward, colour = as.factor(epsilon))) +\n  geom_line() +\n  geom_label(data = filter(average_reward, step == 1000), \n            aes(label = epsilon, x = 950, y = reward), hjust = .5) +\n  theme(legend.position = \"none\") +\n  labs(title = \"Average reward by step for various values of epsilon\")\n\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{law2019,\n  author = {Jonny Law},\n  title = {Multi-Armed {Bandits} in {Scala}},\n  date = {2019-04-16},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJonny Law. 2019. “Multi-Armed Bandits in Scala.” April 16,\n2019."
  },
  {
    "objectID": "posts/2019-02-25-rejection_sampling/index.html",
    "href": "posts/2019-02-25-rejection_sampling/index.html",
    "title": "Bayesian Inference using rejection sampling",
    "section": "",
    "text": "Rejection Sampler\nThe rejection sampler is an algorithm which produces exact samples from the target distribution. Consider a problem where it is straightforward to evaluate the posterior density \\(p(\\cdot)\\) up to a constant. The rejection sampler algorithm proceeds as follows; start by sampling a value from a proposal distribution \\(\\psi^\\star \\sim q(\\cdot)\\), then accept the proposed value with probability \\(p(\\psi^\\star)/Mq(\\psi)\\), where \\(M\\) is an upper bound on \\(p/q\\). The algorithm below shows a single step of the rejection sampler algorithm which returns a single sample from the target distribution \\(p(\\cdot)\\).\n\nPropose \\(\\psi^\\star \\sim q(\\cdot)\\)\nContinuously sample \\(u \\sim U[0, 1]\\) and check the condition in step 3.\nIf \\(u < \\frac{p(\\psi^\\star)}{Mq(\\psi)}\\), set \\(\\psi^\\star\\) as a sample from \\(p\\)\nRepeat 1-3 until enough samples are attained\n\nThe figure below shows the empirical posterior distribution found for the coin flip experiment overlaid with the analytic posterior distribution. This algorithm performs well for low-dimensional problems, but finding the upper bound \\(M\\) can be challenging. The rejection algorithm does not work well in higher dimensions as many proposed moves are rejected. Adding extra dimensions to the problem results in the exponential increase in volume, this is known as the curse of dimensionality. More sophisticated algorithms are required for high dimensional target distributions.\n\n# Perform one rejection step\nrejection_sample <- function(prop, propPdf, log_density) {\n  u <- runif(1)\n  y <- prop(1)\n  \n  if (log(u) < log_density(y) - propPdf(y)) {\n    y\n  } else {\n    rejection_sample(prop, propPdf, log_density)\n  }\n}\n\nlog_density <- function(alpha, beta, Y, n) {\n  function(theta) {\n    dbeta(theta, alpha, beta, log = T) + dbinom(Y, n, theta, log = T)\n  }\n}\n\nsamples <- 1000\nlden <- log_density(alpha, beta, Y, n)\nrejection_samples <-\n  replicate(samples, rejection_sample(runif, function(x)\n    dunif(x, log = T), lden))\n\nggplot(tibble(rejection_samples)) +\n  geom_histogram(aes(x = rejection_samples, y = ..density..), alpha = 0.4) +\n  stat_function(fun =  posterior, aes(colour = \"Analytic posterior\")) +\n  theme(legend.position = \"none\") +\n  xlab(\"p_h\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nEmpirical Posterior distribution for the coin flip problem using 1,000 samples from the rejection sampler with a Uniform(0, 1) proposal distribution and M = 1. The analytic posterior distribution is plotted as a solid red line.\n\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{law2019,\n  author = {Jonny Law},\n  title = {Bayesian {Inference} Using Rejection Sampling},\n  date = {2019-02-25},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJonny Law. 2019. “Bayesian Inference Using Rejection\nSampling.” February 25, 2019."
  },
  {
    "objectID": "posts/2021-08-16-mc-dropout-uncertainty/index.html",
    "href": "posts/2021-08-16-mc-dropout-uncertainty/index.html",
    "title": "Uncertainty in Neural Networks",
    "section": "",
    "text": "Recently, I have been reading Probabilistic Deep Learning which introduces Bayesian methods for fitting Neural Networks using Tensorflow and Keras. One case study consists of a non-linear regression problem for a sinusoidal curve. Additionally, the curve is considered to have heteroskedastic variance, meaning the variance changes along the domain of the function. In this post I will consider approximating a non-linear function with constant (homoskedastic) variance and quantifying the uncertainty. I will be using PyTorch - because why not.\nUncertainty is an important concept in machine learning, if we have confidence in the predictions of model we are able to make more informed decisions. However, neural networks trained using traditional back-propagation typically return a single point estimate by training to minimise a loss function. There have been many attempts to incorporate uncertainty into neural networks, the most principled way is to fit a Bayesian Neural Network (BNNs) by placing prior distributions on the weights and calculating the posterior distribution using Bayes’ theorem:\n\\[p(\\theta| y) = \\frac{p(\\theta)p(y|\\theta)}{\\int_\\theta p(y|\\theta)p(\\theta)}\\]\nWhere \\(\\theta\\) represents the parameters in the neural network, ie. the weights and biases. \\(p(\\theta)\\) is the prior distribution, and \\(p(y|\\theta)\\) is the likelihood. These can all be specified. However, calculating the evidence, the denominator in the equation, \\(\\int_\\theta p(y|\\theta)p(\\theta)\\) is intractable analytically in most real-world problems, including BNNs. The gold standard for computing these integrals for real-world problems is MCMC. In the case of modern deep learning models, the parameter space is too high dimensional (ie. there are too many parameters!) for these methods to be computationally feasible (although (Izmailov et al. 2021) did use HMC for fitting NNs to the CIFAR-10 image dataset and IMDB review dataset using 512 TPUv3 devices). Hence, we look to approximate methods, such as variational inference, which can place additional assumptions on the form on the prior and posterior distributions. There are also non-Bayesian methods (such as deep ensembles) which can be evaluated to have desirable properties such as calibration. From the Wikipedia for statistical calibration “As Philip Dawid puts it,”a forecaster is well calibrated if, for example, of those events to which he assigns a probability 30 percent, the long-run proportion that actually occurs turns out to be 30 percent”.”\nIn this post we will investigate a single easy to implement method for uncertainty estimation, MC dropout (Gal and Ghahramani 2016), applied to a regression problem.\nLet’s start by creating simulating data from a simple model:\n$$\n$$\nWhere \\(a=2\\), \\(b=-3\\) and \\(\\sigma=1\\).\nCreate a neural net which can learn the non-linear function. We’ll use the class nn.ModuleList to allow us to experiment with different numbers of hidden layers. According to the MC Dropout paper, we must apply dropout to each layer in order for the procedure to be equivalent to variational inference - under a set of assumptions.\nSplit the data randomly into training and testing.\nTest the untrained model input and output shapes by making a prediction using the training data.\nUse Skorch to avoid writing the training boilerplate. Use the .fit method provided by Skorch.\nWe can visualise the learning curve for this model below.\nWe can see in the figure below that the predictions are in the right region, but using only a point prediction we miss out on capturing the uncertainty."
  },
  {
    "objectID": "posts/2021-08-16-mc-dropout-uncertainty/index.html#measurement-error-with-distribution",
    "href": "posts/2021-08-16-mc-dropout-uncertainty/index.html#measurement-error-with-distribution",
    "title": "Uncertainty in Neural Networks",
    "section": "Measurement error with Distribution",
    "text": "Measurement error with Distribution\nWe can represent the aleatoric uncertainty, ie. the uncertainty inherent in the data using a Normal distribution. We know the observation distribution of the data generating process is Normal with a standard deviation (called scale in PyTorch) of 1.0. We can learn this additional parameter using PyTorch, to do this we can introduce a new loss function and alter the forward function of the Neural Network module to include the standard deviation parameter. First we’ll consider how to write the new loss function, we need to calculate the log-likelihood of the observations then we wish to maximise this. Neural networks in PyTorch have optimisers with minimise the loss function, hence we will minimise the negative log-likelihood. Let’s first consider the probability density function of a Normal distribution with mean \\(\\mu \\in \\mathbb{R}\\) and standard deviation \\(\\sigma \\in \\mathbb{R}^+\\):\n\\[p(y | \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{1}{2\\sigma^2}(y-\\mu)^2\\right)\\]\nWe have multiple observations which are independent and normally distributed, hence for each batch we will need to calculate the product of the likelihood:\n\\[p(\\mathbb{y}|\\mu, \\sigma) = \\prod_{i=1}^B \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{1}{2\\sigma^2}(y_i-\\mu)^2\\right),\\]\nWhere \\(B\\) is the batch size, this involves multiplying small numbers together which can result in arithmetic underflow, hence we work on the log-scale which changes the calculation to addition:\n\\[\\log p(\\mathbb{y}|\\mu, \\sigma) =  - \\frac{B}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^B (y_i-\\mu)^2  \\]\nIn the case of the Neural net, \\(\\mu\\) is the output and \\(\\sigma\\) is an additional parameter. We can code the log-likelihood by converting this function into PyTorch or using the build in distributions.\n\nfrom torch.distributions import Normal\nimport math\n\nnormal_model = NonLinearRegression(0.1, 64, 3)\ninputs = model(x_input)\nlabels = torch.tensor(y_train, dtype=torch.float)\n\nmu = inputs\nlog_sigma = torch.tensor(0.0, dtype=torch.float)\n\n# Calculate manually\nmanual_ll = - 0.5 * math.log(2.0 * math.pi) - \\\n  log_sigma - 0.5 * ((labels - mu) / log_sigma.exp()) ** 2\n\n# Use the built in log_prob function\nlog_likelihood = Normal(mu, log_sigma.exp()).log_prob(labels)\n\nlog_likelihood.sum(), manual_ll.sum()\n\n(tensor(-617.9488, grad_fn=<SumBackward0>), tensor(-617.9488, grad_fn=<SumBackward0>))\n\n\nWe can modify the nn.Module to return an additional parameter representing the log of the standard deviation of the Normal distribution. Additionally, the forward model will return the predicted mean and the global standard deviation - this is necessary when using Skorch, since the standard form of the loss function is def loss(y_pred, y_true).\n\nimport torch.nn as nn\nimport torch\nimport torch.nn.functional as F\n\nclass NonLinearRegressionNormal(nn.Module):\n    def __init__(self, dropout, hidden_size, hidden_layers):\n        super(NonLinearRegressionNormal, self).__init__()\n        self.input = nn.Linear(1, hidden_size)\n        self.dropout = nn.Dropout(dropout)\n        self.linears = nn.ModuleList(\n          [nn.Linear(hidden_size, hidden_size) for i in range(hidden_layers)])\n        self.dropouts = nn.ModuleList(\n          [nn.Dropout(dropout) for i in range(hidden_layers)])\n        self.output = nn.Linear(hidden_size, 1)\n        self.log_sigma = nn.Parameter(torch.tensor(1.0))\n\n    def forward(self, x):\n        x = self.input(x)\n        x = F.relu(x)\n        x = self.dropout(x)\n        for l, d in zip(self.linears, self.dropouts):\n          x = l(x)\n          x = F.relu(x)\n          x = d(x)\n        x = self.output(x)\n        return x, self.log_sigma\n\nThe standard deviation, sigma, is constant, so in a custom training loop (not using skorch) we could simply pass the model definition to the loss function directly and extract the sigma parameter as follows. This would mean the forward function of the nn.Module can remain the same as the first model. The loss function could look like the following:\n\ndef normal_pdf(model, X, y_true):\n  preds = model(X)\n  return Normal(preds, model.log_sigma.exp()).log_prop(y_true).sum\n\nThen create a loss function as an nn.Module:\n\nfrom skorch.regressor import NeuralNetRegressor\n\nclass NormalLoss(nn.Module):\n  def  __init__(self):\n    super(NormalLoss, self).__init__()\n\n  def forward(self, inputs, labels):\n    mu, log_sigma = inputs\n    log_likelihood = Normal(mu, log_sigma.exp()).log_prob(labels)\n\n    return - log_likelihood.sum()\n\nTrain the model as usual:\n\nepochs = 500\n\nnet_normal = NeuralNetRegressor(\n    module=NonLinearRegressionNormal,\n    module__dropout=0.1,\n    module__hidden_size=64,\n    module__hidden_layers=3,\n    optimizer=torch.optim.AdamW,\n    iterator_train__shuffle=True,\n    criterion=NormalLoss,\n    max_epochs=epochs,\n    verbose=0\n)\n\nx_train_input = torch.tensor(x_train, dtype=torch.float).unsqueeze(-1)\nnet_normal.fit(x_train_input, torch.tensor(y_train, dtype=torch.float))\n\n<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n  module_=NonLinearRegressionNormal(\n    (input): Linear(in_features=1, out_features=64, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (linears): ModuleList(\n      (0): Linear(in_features=64, out_features=64, bias=True)\n      (1): Linear(in_features=64, out_features=64, bias=True)\n      (2): Linear(in_features=64, out_features=64, bias=True)\n    )\n    (dropouts): ModuleList(\n      (0): Dropout(p=0.1, inplace=False)\n      (1): Dropout(p=0.1, inplace=False)\n      (2): Dropout(p=0.1, inplace=False)\n    )\n    (output): Linear(in_features=64, out_features=1, bias=True)\n  ),\n)\n\n\nThen calculate some predictions, the actual function is plotted using blue, with the predictions and prediction interval plotted in red. This is an MLE solution with a 95% confidence interval."
  },
  {
    "objectID": "posts/2021-08-16-mc-dropout-uncertainty/index.html#uncertainty-with-mc-dropout",
    "href": "posts/2021-08-16-mc-dropout-uncertainty/index.html#uncertainty-with-mc-dropout",
    "title": "Uncertainty in Neural Networks",
    "section": "Uncertainty with MC Dropout",
    "text": "Uncertainty with MC Dropout\nWe have looked at how to incorporate aleatoric uncertainty, to understand the uncertainty in the parameters (epistemic uncertainty) we can use MC Dropout. Dropout is a method of avoiding overfitting at training time by removing “connections” in a neural network. However, if we leave dropout on when making predictions, then we create an ensemble of models which output slightly different predictions. It turns out that this is equivalent Bayesian variational inference with some assumptions. We can then calculate the mean and and uncertainty intervals we wish.\nWe can easily implement MC dropout and visualise the uncertainty provided with this method. First, we extract the module from the Skorch NeuralNet class and put it in train mode, this means we make predictions with dropout ON.\n\nnet_normal.module_.train()\n\nNonLinearRegressionNormal(\n  (input): Linear(in_features=1, out_features=64, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n  (linears): ModuleList(\n    (0): Linear(in_features=64, out_features=64, bias=True)\n    (1): Linear(in_features=64, out_features=64, bias=True)\n    (2): Linear(in_features=64, out_features=64, bias=True)\n  )\n  (dropouts): ModuleList(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Dropout(p=0.1, inplace=False)\n    (2): Dropout(p=0.1, inplace=False)\n  )\n  (output): Linear(in_features=64, out_features=1, bias=True)\n)\n\n\nLet’s write a convenience function for making multiple predictions and combining them into a single numpy array.\n\ndef get_predictions(model, x, n):\n  # Make multiple predictions\n  mus, sigmas = zip(*[model(x) for _ in range(n)])\n\n  # Sample from the observation distribution using each mean and the global sigma\n  return [Normal(mu, log_sigma.exp()).sample().detach().numpy() for mu in list(mus)]\n\nWe then have a collection of predictions which we can use to calculate summaries using monte carlo. We can calculate the expectation by calculating the mean of all the predictions, and probability intervals by ordering the predictions and selecting the appropriate values, using np.quantile.\n\ndef get_probability_interval(preds, interval):\n  lower_int = (1. - interval) / 2\n  upper_int = interval + lower_int\n\n  # Calculate percentiles and mean\n  lower = np.quantile(preds, lower_int, axis=0)\n  mean = np.mean(preds, axis=0)\n  upper = np.quantile(preds, upper_int, axis=0) \n    \n  return lower, mean, upper\n\nFirst, we will predict a single point, calculate the mean and the 89% probability interval.\n\ntest_point = 5.0\npreds = get_predictions(net_normal.module_, \n    torch.tensor(test_point, dtype=torch.float).unsqueeze(-1), \n    1000)\n\nlower, mean, upper = get_probability_interval(preds, 0.89)\n\n\n\n\n\n\nNext, we can use the same method to predict several points and give the impression of a function. If we extend the \\(\\sin\\) function we can see that the uncertainty on the inputs which are out of the domain of the training examples is quite large. We can evaluate the calibration of these intervals in domain and out of domain by creating a new training split which omits data in a certain interval.\n\nx_in = np.linspace(-5, 15, 50)\n\npreds = get_predictions(\n    net_normal.module_, \n    torch.tensor(x_in, dtype=torch.float).unsqueeze(-1),\n    1000)"
  },
  {
    "objectID": "posts/2021-08-16-mc-dropout-uncertainty/index.html#calculate-coverage-of-probability-interval",
    "href": "posts/2021-08-16-mc-dropout-uncertainty/index.html#calculate-coverage-of-probability-interval",
    "title": "Uncertainty in Neural Networks",
    "section": "Calculate coverage of probability interval",
    "text": "Calculate coverage of probability interval\nWe can calculate the coverage of the probability interval using an experiment. We first train a neural network generating data from the same noisy function. We have \\(\\mu = 5\\sin(x + 3)\\) and the observations corrupted by Gaussian noise, \\(y_i \\sim \\mathcal{N}(\\mu, 1^2)\\). Then we sample 100 random uniform test points between 0 and 10 and make probabilistic predictions by calculating 1,000 predictions using MC Dropout and calculating 95% probability intervals. This should account for epistemic uncertainty in the parameters and aleatoric uncertainty inherent in the observed data. We then calculate the proportion of predictions which fall into the interval, this should be close to 95%.\n\ndef coverage_experiment():\n  # Generate training data\n  x_train = np.linspace(0, 10, 50)\n  _, y_train = generate_data(x_train)\n\n  # Fit model to training data\n  x_train_input = torch.tensor(x_train, dtype=torch.float).unsqueeze(-1)\n  net_normal.fit(x_train_input, torch.tensor(y_train, dtype=torch.float))\n\n  # Generate testing data from the same generative model\n  n_test = 100\n  x_test = np.random.uniform(0, 10, n_test)\n  _, y_test = generate_data(x_test)\n\n  net_normal.module_.train()\n\n  # Calculate predictions on test data\n  preds = get_predictions(\n      net_normal.module_,\n      torch.tensor(x_test, dtype=torch.float).unsqueeze(-1),\n      1000)\n\n  lower, mean, upper = get_probability_interval(preds, 0.95)\n\n  # Calculate proportion of predictions which fall into interval\n  in_interval = sum([l <= y <= u for y, l, u in zip(y_test, lower, upper)])\n  return in_interval / n_test\n\nLet’s repeat this experiment 100 times and plot a histogram of the resulting coverage."
  },
  {
    "objectID": "posts/2020-03-17-tidy-tuesday-the-office/index.html",
    "href": "posts/2020-03-17-tidy-tuesday-the-office/index.html",
    "title": "Tidy Tuesday: The Office",
    "section": "",
    "text": "First we download the ratings for each office episode using the tidytuesdayR package.\nWe can use glimpse from the tibble package to see the column types and some example data from the head of the table.\nFirstly, I will plot the distribution of ratings by season. We can see that the ratings dropped after season 8 when Steve Carell left the show.\nUsing the schrute package we can get every line of dialogue and additional episode information including the writers and the directors.\nNext, I wanted to see the number of episodes per writer.\nNext, I would like to see which writers produce the highest rated episodes. Determining the writer who writes the best episodes is challenging since writers often collaborate and some writers have only written a handful of episodes. Initially I plotted the IMDB rating for each episode written by each writer regardless of who they collaborated with.\nSteve Carell appears to have the highest median episode rating, however he has written only two episodes! It looks like Greg Daniels is the real MVP, with many consistently well received episodes."
  },
  {
    "objectID": "posts/2020-03-17-tidy-tuesday-the-office/index.html#a-model-for-writers",
    "href": "posts/2020-03-17-tidy-tuesday-the-office/index.html#a-model-for-writers",
    "title": "Tidy Tuesday: The Office",
    "section": "A Model for Writers",
    "text": "A Model for Writers\nWe could fit a hierarchical model to the rating by writer using the BRMS package which uses Stan to perform full Bayesian inference for hierarchical distributional models. The hierarchical model allows the ratings to be shared across writers, hence writers with a small number of episode credits will be pulled towards the overall mean rating of all episodes. The model specification can be written as\n\\[\\begin{aligned}\n\\mathbf{Y} &\\sim \\textrm{Beta}(\\mu\\phi, (1 - \\mu)\\phi), \\\\\n\\mu &= \\mathbf{X}\\beta + \\mathbf{Z}\\nu, \\\\\np(\\beta) &= \\mathcal{N}(0, 5^2) \\\\\np(\\nu) &= \\mathcal{N}(0, \\sigma^2) \\\\\np(\\sigma) &= \\frac{1}{2}t(3, 0, 10) \\\\\np(\\phi) &= \\textrm{Gamma}(0.01, 0.01).\n\\end{aligned}\\]\nWhere \\(Y\\) represents the scaled IMDB rating (\\(Y = \\textrm{IMDB Rating} / 10\\)). The parameters we wish to estimate include \\(\\beta\\), which is the latent population-level effect and \\(\\nu\\) which is the latent group-level effect. The Beta distribution has support in \\([0, 1]\\) so the ratings are scaled by dividing by ten. We can recover the true scale by multiplying by 10 when considering the posterior fitted values. The response Beta distribution is parameterised such that the mean is \\(\\mu\\) and the variance is \\(\\operatorname{Var}(Y) = \\mu(1-\\mu)/(1+\\phi)\\) so the variance of the response decreases as \\(\\phi\\) increases, \\(\\phi\\) is known as a precision parameter for the Beta distribution. The design matrix \\(X\\) contains the intercept representing the overall mean IMDB rating. The design matrix \\(Z\\) is a matrix containing ones.\nThere are 40 group level effects, drawn from a Normal distribution with standard deviation \\(\\sigma\\). \\(\\sigma\\) has a half student-t prior which controls the regularisation of the group level effects. Effectively the level of regularisation for the group level effects is learned from the data. The Stan wiki provides a good reference to the literature on prior choices.\nFirst rescale the rating to be between zero and one.\n\nmodel_data <- writers_by_episode %>% \n  mutate(rating = imdb_rating / 10)\n\nTo define and fit the model use the brm function. The formula rating ~ (1 | writer) specified that we want a group-level effect for each writer. The population level intercept is included by default. The response family is specified to be the Beta distribution and the prior distribution for the population intercept is specified as a Normal distribution with mean 0 and standard deviation 5. The other priors are default and specified above.\n\nfit <- brm(rating ~ 1 + (1 | writer), family = Beta, data = model_data, prior = set_prior(\"normal(0, 5)\", class = \"Intercept\"))\n\nThe model is fit using Hamiltonian Monte Carlo, the sampling code is written in C++. If you are familiar with Stan, you can extract the Stan code from the model using stancode(fit).\nNext we plot the posterior fitted values using the tidybayes package and overlay the actual episode ratings using points. Those with fewer writing credits have a larger posterior credible interval.\n\nadd_fitted_draws(newdata = model_data, model = fit) %>%\n  mutate(fitted_rating = .value * 10) %>%\n  median_qi(fitted_rating, .width = c(.95, .8, .5)) %>%\n  ungroup() %>%\n  mutate(writer = forcats::fct_reorder(writer, fitted_rating)) %>%\n  ggplot(aes(y = writer, x = fitted_rating)) +\n  geom_interval(aes(xmin = .lower, xmax = .upper)) +\n  geom_point(aes(x = imdb_rating), data = writers_by_episode) +\n  scale_color_brewer() +\n  labs(\n    title = \"Posterior Fitted Values for IMDB Rating Ordered by Posterior Mean\",\n    subtitle = \"Actual episode ratings are plotted as points\",\n    x = \"IMDB Rating\",\n    y = \"\"\n  ) +\n  theme(legend.position = \"none\") +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n\n# ggsave(\"brms_ratings_by_writer.png\", width = 7, height = 8)"
  },
  {
    "objectID": "posts/2020-03-27-bayesian-inference-for-an-sir-model/index.html",
    "href": "posts/2020-03-27-bayesian-inference-for-an-sir-model/index.html",
    "title": "Bayesian Inference for an SIR Model",
    "section": "",
    "text": "library(tidyr)\n\nWarning: package 'tidyr' was built under R version 4.1.2\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.1.2\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(readr)\n\nWarning: package 'readr' was built under R version 4.1.2\n\nlibrary(ggplot2)\nlibrary(jonnylaw)\nlibrary(deSolve)\n\nWarning: package 'deSolve' was built under R version 4.1.2\n\nlibrary(patchwork)\ntheme_set(theme_minimal())\nJohns Hopkins University have put together a repository containing confirmed cases of COVID19, deaths and recovered patients. Below we plot the confirmed cases, confirmed recovered and deaths."
  },
  {
    "objectID": "posts/2020-03-27-bayesian-inference-for-an-sir-model/index.html#sir-model",
    "href": "posts/2020-03-27-bayesian-inference-for-an-sir-model/index.html#sir-model",
    "title": "Bayesian Inference for an SIR Model",
    "section": "SIR Model",
    "text": "SIR Model\nThe system of ordinary differential equations (ODE) for the Susceptible Infected Recovered (SIR) model is given by\n\\[\\begin{align}\n& \\frac{dS}{dt} = - \\frac{\\beta I S}{N}, \\\\\n& \\frac{dI}{dt} = \\frac{\\beta I S}{N}- \\gamma I, \\\\\n& \\frac{dR}{dt} = \\gamma I,\\\\\n& N = S + I + R.\n\\end{align}\\]\nWhere \\(S\\) is the number of susceptible, \\(I\\) the total infected and \\(R\\) the total recovered. \\(\\gamma\\) is the recovery rate (\\(1/\\gamma\\) is the infectious period), \\(\\beta\\) is the infection rate (\\(1/\\beta\\) is the time between contacts). These parameters are unobserved.\nWe can Use deSolve to solve the ODE system startin with an initial state of 66.4 million people susceptible and one infected. This produces a simulation conditional on the parameters chosen. The parameters can change depending on each countries reaction to the virus. For instance the infection rate can be lowered by quarantine or social distancing, thus reducing the contact rate \\(\\beta\\).\n\nparameters <- c(beta = 0.5, gamma = 1/4.5)\ninitial_state <- c(S = 66.4e6, I = 1, R = 0) \n\nsir <- function(t, state, parameters) {\n  with(as.list(c(state, parameters)), {\n    N <- sum(S, I, R)\n    dS = -beta * S * I / N\n    dI = beta * S * I / N - gamma * I\n    dR = gamma * I\n    \n    list(c(dS, dI, dR))\n  })  \n}\n\ntimes <- seq_len(100)\nout <- ode(y = initial_state, times = times, func = sir, parms = parameters)\n\n\n\nDon't know how to automatically pick scale for object of type deSolve/matrix. Defaulting to continuous.\n\n\n\n\n\nConsider the model in this pre-print from Lourenco et al 2020, which has since been criticised in this response. We observe the cumulative deaths\n\\[\\Lambda_t = \\rho\\eta R_{t-\\psi},\\]\nwhere \\(\\rho\\) is the proportion of the population at risk of severe disease, \\(\\eta\\) is the probability of dying with the severe disease. \\(R_{t-\\psi}\\) is the removed population with a delay between the time of infection represented by \\(\\psi\\). The parameters are given prior distributions in the paper, we can simulate multiple trajectories of the cumulative deaths by first simulating from the prior distribution then solving the SIR system. The prior distributions as given in the paper are\n\\[\\begin{aligned}\n  \\frac{1}{\\gamma} &\\sim \\mathcal{N}(4.5, 1^2), \\\\\n  \\psi &\\sim \\mathcal{n}(17, 2^2), \\\\\n  R_0 &\\sim \\mathcal{n}(2.25, 0.2^2), \\\\\n  \\eta &\\sim \\mathcal{n}(0.14, 0.007^2), \\\\\n  \\rho &\\sim \\text{Gamma}(5, 5/0.01).\n\\end{aligned}\\]\nThere is also a parameter for the time of introduction relative to the time of the first reported case, \\(\\tau\\). It has a strange prior distribution, being uniform from \\(-\\infty\\) to \\(\\infty\\). Obviously this parameter can not be positive, since a confirmed case indicates that the time of introduction is in the past.\n\n\n\n\n\n\n\n\nWe can simulate more times from the prior and calculate the empirical intervals instead of plotting raw trajectories. The initial state is \\(S = 66.44 \\times 10^6\\), \\(I = 1\\) and \\(R = 0\\). The initial time is taken to be one week before the first confirmed case in the UK.\n\n\nWarning: Transformation introduced infinite values in continuous y-axis\nTransformation introduced infinite values in continuous y-axis\nTransformation introduced infinite values in continuous y-axis\nTransformation introduced infinite values in continuous y-axis\nTransformation introduced infinite values in continuous y-axis"
  },
  {
    "objectID": "posts/2020-03-27-bayesian-inference-for-an-sir-model/index.html#inference-method",
    "href": "posts/2020-03-27-bayesian-inference-for-an-sir-model/index.html#inference-method",
    "title": "Bayesian Inference for an SIR Model",
    "section": "Inference method",
    "text": "Inference method\nThe inference method is explained clearly in Lourenço et al (2017), albeit with a different model. The Metropolis algorithm with a symmetric random walk proposal distribution is used, the likelihood is the product of independent Poisson distributions\n\\[\\mathcal{L}(y_{1:T}|\\Lambda_{1:T}, \\theta^\\star) = \\prod_{t=1}^T\\left(\\textrm{Poisson}(y_t;\\Lambda_t)\\right)\\]\nThe steps to perform inference for the static parameters are summarised below\n\nPropose new (log) parameters from a symmetric Normal distribution \\(\\log(\\theta^\\star) \\sim \\mathcal{N}(\\log\\theta^\\star\\mid\\log\\theta, \\sigma I_d)\\)\nSolve the ODE using the deSolve package using the proposed parameters\nCalculate the un-normalised log-posterior \\(\\log p(\\Lambda_{1:T}, \\theta^\\star\\mid y_{1:T}) = \\log p(\\theta) +\\sum_{t=1}^T\\log\\left(\\textrm{Poisson}(y_t\\mid\\Lambda_t)\\right)\\)\nAccept the new parameters with probability \\(\\alpha\\) where\n\n\\[\\alpha = \\min\\left(1, \\frac{p(\\Lambda_{1:T}, \\theta^\\star\\mid y_{1:T})}{p(\\Lambda_{1:T}, \\theta\\mid y_{1:T})}\\right).\\]\nFirst we specify the likelihood in R.\n\nlog_likelihood_sir <- function(parameters, ys, initial_state) {\n  initial_state <- c(S = 60e6, I = 1, R = 0) # \n  \n  # Transition function\n  sir <- function(t, state, parameters) {\n    beta <- parameters[1] * parameters[2]\n    gamma <- parameters[2]\n    \n    with(as.list(state), {\n      N <- sum(S, I, R)\n      dS = -beta * S * I / N\n      dI = beta * S * I / N - gamma * I\n      dR = gamma * I\n      \n      list(c(dS, dI, dR))\n    })  \n  }\n  \n  sir_sim <-\n    deSolve::ode(\n      y = initial_state,\n      times = seq_along(ys),\n      func = sir,\n      parms = parameters\n    )\n  \n  cumulative_deaths <- function(t, R, parameters) {\n    R[max(1, t - parameters[5])] * parameters[3] * parameters[4]\n  }\n  \n  lambdas <- purrr::map_dbl(sir_sim[, 1], ~ cumulative_deaths(t = .x, sir_sim[, 4], parameters))\n  \n  ll <- sum(dpois(x = ys, lambda = lambdas, log = TRUE))\n  \n  if_else(is.nan(ll) || is.na(ll), -Inf, ll)\n}\n\nThen we specify the prior distributions.\n\nlog_prior <- function(parameters) {\n  r0 = parameters[1]; gamma = parameters[2]; rho = parameters[3]\n  eta = parameters[4]; psi = parameters[5]\n  \n  dnorm(1/gamma, mean = 4.5, sd = 1, log = TRUE) +\n    dnorm(psi, mean = 17, sd = 2, log = TRUE) +\n    dnorm(r0, mean = 2.25, sd = 0.2, log = TRUE) +\n    dnorm(eta, mean = 0.14, sd = 0.007, log = TRUE) +\n    dgamma(rho, shape = 5, rate = 5/0.01, log = TRUE)\n}\n\nproposal <- function(p) {\n  p * exp(rnorm(5, sd = c(0.02, 0.02, 0.02, 0.02, 0.05)))\n}\n\ninitial_parameters <- c(r0 = 2.25, gamma = 1/4.5, rho = 0.01, eta = 0.14, psi = 17)\nys <- uk %>% pull(deaths)\n\nWe initialise the parameters at the mean of the prior distributions and simulate 1 million iterations from the Metropolis algorithm. The first half are discarded and every 100th iteration is retained in an attempt to reduce auto-correlation in the chain.\n\niters <-\n  jonnylaw::metropolis(\n    theta = initial_parameters,\n    function(p) log_likelihood_sir(ys = ys, parameters = p) + log_prior(p),\n    proposal = proposal,\n    1e6, \n    chains = 2, \n    parallel = TRUE\n  )\n\nWarning: Strategy 'multiprocess' is deprecated in future (>= 1.20.0). Instead,\nexplicitly specify either 'multisession' or 'multicore'. In the current R\nsession, 'multiprocess' equals 'multicore'.\n\n\nWarning: UNRELIABLE VALUE: Future ('<none>') unexpectedly generated random\nnumbers without specifying argument 'seed'. There is a risk that those random\nnumbers are not statistically sound and the overall results might be invalid.\nTo fix this, specify 'seed=TRUE'. This ensures that proper, parallel-safe random\nnumbers are produced via the L'Ecuyer-CMRG method. To disable this check, use\n'seed=NULL', or set option 'future.rng.onMisuse' to \"ignore\".\n\n\nWarning: UNRELIABLE VALUE: Future ('<none>') unexpectedly generated random\nnumbers without specifying argument 'seed'. There is a risk that those random\nnumbers are not statistically sound and the overall results might be invalid.\nTo fix this, specify 'seed=TRUE'. This ensures that proper, parallel-safe random\nnumbers are produced via the L'Ecuyer-CMRG method. To disable this check, use\n'seed=NULL', or set option 'future.rng.onMisuse' to \"ignore\".\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nThe next plot shows both the prior and posterior distribution. The prior is the solid black line and the posterior samples are plotted in a histogram. Most of the prior distributions are narrow and hence have resulted in little change. The posterior mean of the infectious period, \\(1/gamma\\) is approximately 4 days, down from the prior mean of 4.5. The posterior mean of \\(\\psi\\) is, 13.5, 3.5 days shorter than the prior mean.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNow plot the posterior cumulative death curve.\n\n\nWarning: Transformation introduced infinite values in continuous y-axis\nTransformation introduced infinite values in continuous y-axis\nTransformation introduced infinite values in continuous y-axis\nTransformation introduced infinite values in continuous y-axis\n\n\n\n\n\nLet’s simulate forward 100 days from the hypothesised start date, 2020-01-26 using the posterior distribution."
  },
  {
    "objectID": "posts/2020-03-03-tidy_tuesday_nhl_data/index.html",
    "href": "posts/2020-03-03-tidy_tuesday_nhl_data/index.html",
    "title": "Tidy Tuesday: NHL Goalscorers",
    "section": "",
    "text": "First install the Tidy Tuesday R package.\nThe data for this Tuesday can be downloaded using tt_load.\nUnfortunately this only grabbed one file - the top 250 goalscorers. First look at this file."
  },
  {
    "objectID": "posts/2020-03-03-tidy_tuesday_nhl_data/index.html#post-some-results-to-twitter",
    "href": "posts/2020-03-03-tidy_tuesday_nhl_data/index.html#post-some-results-to-twitter",
    "title": "Tidy Tuesday: NHL Goalscorers",
    "section": "Post some results to Twitter",
    "text": "Post some results to Twitter\nNow use the twitteR library to post the plots directly to Twitter without leaving R. You must connect to the Twitter API using OAuth as described in the README for twitteR, I set the Twitter application keys in my .Renviron file which is never committed to public version control (this can be easily edited using usethis::edit_r_environ()).\n\nlibrary(twitteR)\noauth <- setup_twitter_oauth(\n  Sys.getenv(\"TWITTER_API_KEY\"),\n  Sys.getenv(\"TWITTER_API_SECRET_KEY\"),\n  access_token = Sys.getenv(\"TWITTER_ACCESS_TOKEN\"),\n  access_secret = Sys.getenv(\"TWITTER_ACCESS_TOKEN_SECRET\")\n)\n\nWith twitteR we can get the most recent #tidytuesday posts\n\nsearchTwitter('#tidytuesday', n = 10)\n\nUnfortunately the twitteR API (I think people tend to use rtweet now!) is a little outdated and requires tweets to be less than 140 characters (however this can be bypassed using bypassCharLimit = TRUE) and we can’t post multiple images in the same tweet using the mediaPath argument. So unfortunately I had to resort to posting my graphs manually!\n\nupdateStatus(\n  \"Can Alex Ovechkin overhaul Wayne Gretzky's all time NHL goal scoring record. It appears as if Wayne slowed down in the latter years of his career. #rstats #TidyTuesday\",\n  mediaPath = c(\"cumulative_goals.png\", \"goals_per_season.png\"),\n  bypassCharLimit = TRUE\n)"
  },
  {
    "objectID": "posts/2020-03-10-tidy-tuesday-us-tuition-data/index.html",
    "href": "posts/2020-03-10-tidy-tuesday-us-tuition-data/index.html",
    "title": "Tidy Tuesday: US Tuition Data",
    "section": "",
    "text": "library(jonnylaw)\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.1.2\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr)\n\nWarning: package 'tidyr' was built under R version 4.1.2\n\nlibrary(ggplot2)\nlibrary(gghighlight)\nlibrary(tidybayes)\n\nWarning: package 'tidybayes' was built under R version 4.1.2\n\ntheme_set(theme_minimal())\nThis weeks data consists of tuition costs, salary potential and diversity information of US colleges. This includes 2 year colleges which offer associate degrees, certificates and diplomas and 4 year colleges which offer bachelors and masters degrees. These are further split by private institutions, public and for profit. Additionally, Universities in the US charge different tuition fees for in-state or out-of-state students. Also, the ticket price is not always reflective of the students costs. The fees can be wholly or partially subsidised by scholarships and financial aid.\nThe first question which I wanted to answer is which universities have the highest tuition cost and what type of institution are they.\ntidybayes can be used to plot the distribution of in state costs and out of state costs."
  },
  {
    "objectID": "posts/2020-03-10-tidy-tuesday-us-tuition-data/index.html#historical-tuition-data",
    "href": "posts/2020-03-10-tidy-tuesday-us-tuition-data/index.html#historical-tuition-data",
    "title": "Tidy Tuesday: US Tuition Data",
    "section": "Historical Tuition Data",
    "text": "Historical Tuition Data\nAnother dataset contains the historical tuition values in adjusted US dollars. We can see that private and public tuitions have doubled for four year courses since 1985. It’s quite a lot more expensive to attend college in the US now than it was 35 years ago!\n\ntuesdata$historical_tuition %>% \n  mutate(year = substr(year, 1, 4) %>% as.numeric()) %>% \n  ggplot(aes(x = year, y = tuition_cost, colour = tuition_type)) +\n  geom_line() +\n  facet_wrap(~type, ncol = 3) +\n  theme_bw() +\n  theme(legend.position = \"bottom\") +\n  scale_y_continuous(labels = scales::dollar_format()) +\n  labs(title = \"Tuition cost in 2016/17 dollars\")"
  },
  {
    "objectID": "posts/2020-03-10-tidy-tuesday-us-tuition-data/index.html#most-cost-effective-universities",
    "href": "posts/2020-03-10-tidy-tuesday-us-tuition-data/index.html#most-cost-effective-universities",
    "title": "Tidy Tuesday: US Tuition Data",
    "section": "Most cost effective Universities",
    "text": "Most cost effective Universities\nTo quantify the most cost effective university to attend, divide the mid career pay by the total tuition paid for a 4-year degree (bachelors or masters degree).\n\nsalary <- tuesdata$salary_potential\n\nsalary %>% \n  left_join(tuesdata$tuition_cost %>% filter(degree_length == \"4 Year\")) %>% \n  pivot_longer(c(\"out_of_state_total\", \"in_state_total\"), names_to = \"tuition_type\", values_to = \"tuition\") %>% \n  mutate(ratio = mid_career_pay / tuition,\n         name_cost = paste(name, scales::dollar(tuition))) %>%\n  ggplot(aes(x = ratio, y = tuition)) +\n  geom_point() +\n  facet_wrap(~tuition_type, ncol = 1) +\n  scale_y_continuous(labels = scales::dollar_format()) +\n  xlab(\"Mid Career Earnings / Tuition Fee\") +\n  ylab(\"Tuition\") +\n  labs(title = \"Yearly Tuition Costs and Mid Career Earnings\")\n\nJoining, by = \"name\"\n\n\nWarning: Removed 428 rows containing missing values (geom_point)."
  },
  {
    "objectID": "posts/2021-08-04-entity-embeddings/index.html",
    "href": "posts/2021-08-04-entity-embeddings/index.html",
    "title": "Entity Embeddings",
    "section": "",
    "text": "The tidymodels framework in R has a function for constructing Entity Embeddings from categorical features. The library is know as embed and the heavy lifting (neural network fitting) is performed using Keras. What if we want something similar in Python and sklearn. First, we will aim to understand what an embedding is and how it can be created (and re-used). Embeddings are familiar to those who have used the Word2Vec model for natural language processing (NLP). Word2Vec is a shallow neural network trained on a corpus of (unlabelled) documents. The task of the network is to predict a context word close to the original word. The resulting shallow network has an “embedding matrix” which has the same number of rows as the number of words in the corpus vocabulary and a user-chosen embedding dimension as the number of columns. Each row represents the position of a word in the embedding space and its location is very close to its meaning. Additionally, we can perform arithmetic with the embeddings and get reasonable answers.\nWe can use this same technique to embed high-dimensional categorical variables when we have lots of data. This can be seen in a 2017 publication from ASOS, an online fashion retailer (Customer Lifetime Value Prediction Using Embeddings, Chamberlain et. al., KDD 2017)."
  },
  {
    "objectID": "posts/2021-08-04-entity-embeddings/index.html#pytorch-model",
    "href": "posts/2021-08-04-entity-embeddings/index.html#pytorch-model",
    "title": "Entity Embeddings",
    "section": "PyTorch Model",
    "text": "PyTorch Model\nFirst we must create a new Neural Network architecture, in PyTorch this means that we extend torch.nn.Module class which requires the implementation of a forward method. The forward method creates a prediction from the input, the method consists of applications of matrix multiplications and activations. In this case, we have an Embedding module for each categorical feature (of dimension (n_categories, hidden_dim)), created using nn.ModuleList. The embedding module enables us to “look up” the corresponding row of the embedding matrix for that categorical variable and return the embedding for that category. For the continuous features, we have a linear layer of dimension (num_cont, hidden_dim) which can then be combined using torch.cat, the ReLU activation function is used and the output is calculated using another linear layer of dimension (2 hidden_dim, num_output_classes). There is no activation on the network, since it is typically more efficient to use a loss function which also includes the calculation of the activation function, BCEWithLogitsLoss vs BCELoss.\nPyTorch implements the backprop algorithm which will create a backward function, this backward function is the derivative of the network with respect to the input. This derivative is used in the optimisation algorithms to learn the values of the parameters which minimise the loss function.\nWe will start with some imports required to use PyTorch.\n\nimport torch.nn as nn\nimport torch\n\n\nclass EmbeddingClassification(nn.Module):\n    \"\"\"Embed a single categorical predictor\n    \n    Keyword Arguments:\n    \n    num_output_classes: int\n    num_cat_classes: list[int]\n    num_cont: int\n    embedding_dim: int\n    hidden_dim: int\n    \"\"\"\n    def __init__(self, num_output_classes, num_cat_classes, num_cont, \n    embedding_dim=64, hidden_dim=64):\n        super().__init__()\n        # Create an embedding for each categorical input\n        self.embeddings = nn.ModuleList([nn.Embedding(nc, embedding_dim) for nc in num_cat_classes])\n        self.fc1 = nn.Linear(in_features=len(num_cat_classes) * embedding_dim, out_features=hidden_dim)\n        self.fc2 = nn.Linear(in_features=num_cont, out_features=hidden_dim)\n        self.relu = nn.ReLU()\n        self.out = nn.Linear(2 * hidden_dim, num_output_classes)\n        \n    def forward(self, x_cat, x_con):\n        # Embed each of the categorical variables\n        x_embed = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n        x_embed = torch.cat(x_embed, dim=1)\n        x_embed = self.fc1(x_embed)\n        x_con = self.fc2(x_con)\n        x = torch.cat([x_con, x_embed.squeeze()], dim=1)\n        x = self.relu(x)\n        return self.out(x)"
  },
  {
    "objectID": "posts/2021-08-04-entity-embeddings/index.html#titanic-dataset",
    "href": "posts/2021-08-04-entity-embeddings/index.html#titanic-dataset",
    "title": "Entity Embeddings",
    "section": "Titanic Dataset",
    "text": "Titanic Dataset\nI will show how the embeddings work in practice using the titanic dataset. This is not the ideal dataset to use with embeddings since each categorical variable has a small number of categories, however it is well understood and useful for pedagogical purposes.\n\nimport pandas as pd\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder\n\nSEED=7\n\nFirst we must pre-process the data,\n\nParse the Name column to extract the title as an additional categorical variable\nSelect the columns to include\nInterpolate the numeric columns using a KNNImputer\nSplit the data into a training/test split\n\n\ndf = pd.read_csv('titanic.csv')\n\n# Derive title column\ndf['Title'] = df['Name'].str.extract('([A-Za-z]+\\.)', expand = False)\n\n# Count the occurences of Title by category\ndef get_category_count(x, categorical_columns):\n    return [Counter(x[c]) for c in categorical_columns]\n  \n# Filter low occurences (less than or equal to 3?)\ncat_counts = get_category_count(df, [\"Title\"])\nrare_titles = [k for k, v in cat_counts[0].items() if v < 3]\ndf['Title'].replace(to_replace=rare_titles, value='other', inplace=True)\n\ninclude = ['Sex', 'Age', 'Fare', 'Title']\nx = df[include]\ny = df['Survived']\n\n# Define the numeric and categorical columns\nnum_cols = ['Fare', 'Age']\ncat_cols = ['Sex', 'Title']\n\n# Split the data into training and test\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state=SEED)\n\n# Interpolate the numeric columns using KNN and scale using the StandardScaler\nnum_standard = Pipeline(steps=[\n    ('imputer', KNNImputer(n_neighbors=5)),\n    ('scaler', StandardScaler())\n])\n\nWe then need to encode the categorical variables by assigning a number to each of the possiblities. This allows us to use an embedding layer in the PyTorch neural network (NN). NNs only work with numerical input.\n\npreprocessor = ColumnTransformer(\ntransformers=[\n    (\"num_std\", num_standard, num_cols),\n    (\"ordinal_encode\", OrdinalEncoder(), cat_cols),\n    ]\n)\n\npreprocessed = preprocessor.fit_transform(x_train, y=None)\npreprocessed_df = pd.DataFrame(preprocessed, columns=num_cols + cat_cols)\n\n\ndef get_categorical_dimensions(x, categorical_columns):\n  count_of_classes = get_category_count(x, categorical_columns)\n  return [len(count) for count in count_of_classes]\n\n\ndef entity_encoding_classification(x, categorical_columns, num_classes):\n  \"\"\"\n  Convenience function for the EmbeddingClassification model which     \n  \n  Keyword Arguments:\n  x: pandas df\n  y: target column\n  categorical_columns: list[int] a list of the indices of the categorical columns\n  num_classes: int the number of output classes of the target column\n  \"\"\"\n  x_con = x.drop(categorical_columns, axis=1)\n  categorical_dimension = get_categorical_dimensions(x, categorical_columns)\n  return EmbeddingClassification(num_classes, categorical_dimension, len(x_con.columns))\n\nNow we can create the Pytorch model using the function we just defined.\n\nmodel = entity_encoding_classification(x_train, cat_cols, 1)\n\nWe will not write out own training loop, instead we will use the Skorch library. The Skorch library allows us to use the sklearn API with our own PyTorch models. Skorch provides classes, such as NeuralNetBinaryClassifier, with default loss functions (binary cross entropy in this case), train/validation split logic, console logging of loss, validation loss etc. These can be customised, and additional call-backs can be added such as model checkpointing, early stopping, custom scoring metrics and all metrics from sklearn. Other types of model (regression, semi-supervised, reinforcement learning etc.) can be fit using the more generic class NeuralNet.\n\nfrom skorch import NeuralNetBinaryClassifier\n\nnet = NeuralNetBinaryClassifier(\n    module = model,\n    iterator_train__shuffle=True, \n    max_epochs=100,\n    verbose=False\n)\n\nTo pass multiple arguments to the forward method of the Skorch model we must specify a SliceDict such that Skorch can access the data and pass it to the module properly.\n\nfrom skorch.helper import SliceDict\n\nXs = SliceDict(\n    x_cat=preprocessed_df[cat_cols].to_numpy(dtype=\"long\"), \n    x_con=torch.tensor(preprocessed_df[num_cols].to_numpy(), dtype=torch.float)\n)\n\nWe can now use the sklearn fit method with our PyTorch model. This trains the weights of the neural network using back-propagation.\n\nnet.fit(Xs, y=torch.tensor(y_train, dtype=torch.float))\n\n<class 'skorch.classifier.NeuralNetBinaryClassifier'>[initialized](\n  module_=EmbeddingClassification(\n    (embeddings): ModuleList(\n      (0): Embedding(2, 64)\n      (1): Embedding(7, 64)\n    )\n    (fc1): Linear(in_features=128, out_features=64, bias=True)\n    (fc2): Linear(in_features=2, out_features=64, bias=True)\n    (relu): ReLU()\n    (out): Linear(in_features=128, out_features=1, bias=True)\n  ),\n)\n\n\nFinally, we pre-process the test data by re-using the pipelines from the training data and we can calculate the test accuracy.\n\nfrom sklearn.metrics import classification_report\n\nx_test_pre = preprocessor.transform(x_test)\npreprocessed_test = pd.DataFrame(x_test_pre, columns=num_cols + cat_cols)\n\nXs_test = SliceDict(\n    x_cat=preprocessed_test[cat_cols].to_numpy(dtype=\"long\"), \n    x_con=torch.tensor(preprocessed_test[num_cols].to_numpy(), dtype=torch.float)\n)\n\nnet.score(Xs_test, y_test)\n\n0.7309417040358744\n\n\nThis post shows how to implement entity embeddings using Python, and how to incorporate custom PyTorch models into an sklearn pipeline."
  },
  {
    "objectID": "posts/2019-08-09-bayesian_survival/index.html",
    "href": "posts/2019-08-09-bayesian_survival/index.html",
    "title": "Bayesian Survival Analysis: Exponential Model",
    "section": "",
    "text": "Consider an arbitrary interval where the expected number of events in the interval is denoted as \\(\\lambda\\). The number of events in this interval is Poisson distributed with rate \\(\\lambda\\). To see this, proceed to subdivide the interval into \\(n\\) smaller intervals \\(t_1, \\dots, t_n\\) in which the probability of an event occurring in each small interval is \\(\\lambda / n\\) and can be represented as an independent Bernoulli trial. The number of events in the entire interval is distributed according to a Binomial distribution with number of trials \\(n\\) and probability of success \\(\\lambda / n\\). If the intervals are infinitesimally small, in the limit as \\(n \\rightarrow \\infty\\), then number of trials increases and the Binomial distribution tends to the Poisson distribution:\n\\[\\begin{align*}\nf(k) &= \\lim_{n\\rightarrow\\infty} {n \\choose k}\\left(\\frac{\\lambda}{n}\\right)^k\\left(1-\\left(\\frac{\\lambda}{n}\\right)\\right)^{n-k}, \\\\\n&= \\lim_{n\\rightarrow\\infty} \\frac{n!}{(n-k)!k!}\\left(\\frac{\\lambda}{n}\\right)^k\\left(1-\\left(\\frac{\\lambda}{n}\\right)\\right)^{n}\\left(1-\\left(\\frac{\\lambda}{n}\\right)\\right)^{-k}, \\\\\n&= \\lim_{n\\rightarrow\\infty}\\frac{n(n-1)\\dots(n-k+1)(n-k)!}{(n-k)!n^k}\\frac{\\lambda^ke^{-\\lambda}}{k!} \\cdot 1, \\\\\n&= 1 \\cdot \\frac{\\lambda^ke^{-\\lambda}}{k!}.\n\\end{align*}\\]\nThis is the probability mass function of the Poisson distribution and corresponds to the probability of observing exactly \\(k\\) events in an interval with expected number of events \\(\\lambda\\). The Poisson probability mass function can be plotted for various values of \\(\\lambda\\):"
  },
  {
    "objectID": "posts/2019-08-09-bayesian_survival/index.html#fitting-the-exponential-model-using-brms",
    "href": "posts/2019-08-09-bayesian_survival/index.html#fitting-the-exponential-model-using-brms",
    "title": "Bayesian Survival Analysis: Exponential Model",
    "section": "Fitting the exponential model using BRMS",
    "text": "Fitting the exponential model using BRMS\nIn general, parametric survival models can be fitted using sampling based methods such as MCMC. The package brms can be used as a straightforward interface to stan.\nTo express this model using brms, we model the followup time directly while considering censoring. The event is considered right-censored if a death has not occurred, where fustat = 1 and the formula to specify the followup time is right censored is futime | cens(fustat). This is followed by distributed by ~ and the covariates of interest. To compare it to the analytic result above we consider the model with only an intercept and no covariates. Note that this model is not exactly the same since the prior is on specified on the log of the rate, \\(\\lambda\\).\n\nfit_exponential <-\n  brm(\n    futime | cens(fustat) ~ 1,\n    data = ovarian,\n    family = brmsfamily(\"exponential\"),\n    cores = 4,\n    prior = prior(\"normal(0.0, 3.0)\", \"Intercept\")\n  )\n\n\nsummary(fit_exponential)\n\n Family: exponential \n  Links: mu = log \nFormula: futime | cens(fustat) ~ 1 \n   Data: ovarian (Number of observations: 26) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     7.00      0.26     6.51     7.55 1.00     1772     1778\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nThe figure on the left below compares the analytic survival function for the exponential model on the left, to the sampling based survival function using 100 draws from the posterior distribution. In addition, the thick black line on the right-hand plot represents the median survival calculated from 4,000 draws from the posterior distribution"
  },
  {
    "objectID": "posts/2016-12-13-SeasonalDlm/index.html",
    "href": "posts/2016-12-13-SeasonalDlm/index.html",
    "title": "Seasonal DLM",
    "section": "",
    "text": "CitationBibTeX citation:@online{law2016,\n  author = {Jonny Law},\n  title = {Seasonal {DLM}},\n  date = {2016-12-13},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJonny Law. 2016. “Seasonal DLM.” December 13, 2016."
  },
  {
    "objectID": "posts/2019-02-22-national_xc/index.html",
    "href": "posts/2019-02-22-national_xc/index.html",
    "title": "A Statistical Model for Finishing Positions at the National Cross Country",
    "section": "",
    "text": "A linear model\n\n\n\nThe goal is to fit a model, where the outcome is the position at the national and the input is the position at the northern XC. This then allows us to determine the quality of the field at each XC and determine what position you are likely to finish in the National this season given a result in the area championships. A simple linear model has each observation (runner) considered independent with normally distributed errors.\n\\[Y_i = \\beta^T x_i + \\varepsilon_i, \\quad \\mathcal{N}(0, \\sigma^2).\\]\nThree separate models are fit, one for each area championship under consideration. To construct the dataset for each of the models we join the results together from the area and nationals in 2018 by name and exclude those who didn’t participate in both. We fit the model using least squares and see that the coefficient associated with the finishing position in the northerns is 2.23 and the intercept is 95. This means that given your finishing position in the Northern XC, just add 95 and multiple by 2.23 to get an approximate finishing position in the 2018 National XC.\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n95.1\n25.2\n3.8\n0\n\n\nposition_northern\n2.2\n0.1\n17.1\n0\n\n\n\n\n\nNext we plot a Normal Q-Q plot to check the residuals are Normally distributed. If the residuals (the errors, \\(Y_i - \\varepsilon_i, i = 1,\\dots,N\\)) are Normally distributed the conclusions drawn from the model are valid. The Q-Q plots look reasonable (except maybe the midlands (centre)) with only a few outliers identified by R.\n\n\n\n\n\nNormal Q-Q plots (Left) Northern. (Centre) Midlands. (Right) Southerns.\n\n\n\n\nNext we can plot the actual values and the “line of best fit”. This is the regression line given by the data, we can see this generally captures the relationship quite well.\n\n\n\n\n\nLooking at the line of best fit, the data appears to be linear, however exceptional performances in both competitions are not accurately modelled.\nThe coefficients for the midlands and the southerns simple linear regression are as follows:\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n190.8\n45.5\n4.2\n0\n\n\nposition_midlands\n3.6\n0.4\n8.9\n0\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n90.3\n17.5\n5.2\n0\n\n\nposition_southern\n1.8\n0.1\n25.6\n0\n\n\n\n\n\n\n\nPredict 2019 National placing using the linear model\nNow we’d like to use this data in order to predict a performance in 2019. I ran in the Northern XC, finished 289th. The linear model predicts a mean finishing position of 742, given by the equation:\n\\[\\textrm{finish_nationals} = 95 + 2.239 * 289\\]\n\n\n       1 \n742.3531 \n\n\nMy actual finishing position was 904.\n\n\n\n\nCitationBibTeX citation:@online{law2019,\n  author = {Jonny Law},\n  title = {A {Statistical} {Model} for {Finishing} {Positions} at the\n    {National} {Cross} {Country}},\n  date = {2019-02-22},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJonny Law. 2019. “A Statistical Model for Finishing Positions at\nthe National Cross Country.” February 22, 2019."
  },
  {
    "objectID": "posts/2021-09-27-model-comparison/index.html",
    "href": "posts/2021-09-27-model-comparison/index.html",
    "title": "Model Comparison with Hierarchical Models",
    "section": "",
    "text": "One common problem in machine learning is comparing models. Some choose to calculate a single metric (accuracy, ROC AUC etc.) and compare the value across several models, however fitting multiple models to the same train-test split can result in overfitting. To combat this, we can perform k-fold cross validation. Additionally, we can then use a statistical model to determine if the difference in performance between the models fit on the same k-folds is real or random variation in the sampled test sets. This post uses a method common to meta-analysis, when combining and understanding results from multiple related trials with possibly different datasets. This method has been used for comparing ML models and a detailed treatment for ML model comparison can be found in Benavoli et al. (2017).\nTo evaluate the methods, we will first simulate some data. Let’s consider a multiple linear regression with polynomial relationships.\n\\[\n\\begin{aligned}\ny_i \\sim \\mathcal{N}(x_1 \\beta_1 + x_2^2\\beta_2 + x_3^3\\beta_3, \\sigma^2)\n\\end{aligned}\n\\]\nWe have a dataset of size \\(n = 1000\\), we split the dataset into \\(k = 5\\) folds by sampling 5 non-overlapping test sets. We use the vfold_cv function from rsample.\nNext, we propose a few candidate models. We can specify the model which is used to generate the data and a random forest which should do a good job to unpick the relationship.\nWe can now specify a workflow set, this includes a recipe for each model.\nFigure @ref(fig:plot-results) (left) shows the root mean squared error (RMSE) between each models prediction and the corresponding actual value in the test set. The results appear as a box-plot since the\n\\[\\text{RMSE} = \\sqrt{\\sum_{i=1}^N (y_i - f(x_i))^2}\\]\nWhere \\(N\\) is the number of data points in the test dataset (it’s \\(N = 200\\) in our example), \\(y_i\\) is value of the \\(i^{th}\\) test example and \\(f(x_i)\\) is the prediction for the \\(i^{th}\\) datapoint.\nFigure @ref(fig:plot-results) (right) shows the R-squared value, the proportion of explained variance. The R squared value is calculated by\n\\[R^2 = 1 - \\frac{SS_\\text{res}}{SS_{\\text{tot}}}\\]\nWhere,\n\\[SS_{\\text{res}}=\\sum_{i=1}^N (y_i - f(x_i))^2,\\\\\nSS_\\text{tot} = \\sum_{i=1}^N(y_i - \\bar{y})^2.\\]"
  },
  {
    "objectID": "posts/2021-09-27-model-comparison/index.html#hierarchical-model",
    "href": "posts/2021-09-27-model-comparison/index.html#hierarchical-model",
    "title": "Model Comparison with Hierarchical Models",
    "section": "Hierarchical Model",
    "text": "Hierarchical Model\nWe must ensure the \\(k\\)-folds we sample are identical across models. We can then use a statistical model to determine if the differences between models are real or simply random variation in the sampled test sets. To perform the comparison we consider the RMSE for each of the \\(k=5\\) folds. \\(y_{ij}\\), \\(i = 1, \\dots, k\\), \\(j = 1, \\dots N_\\text{models}\\) is the calculated root mean squared error for the \\(i^{th}\\) fold, with the \\(j^{th}\\) model. We use a log transformation on the RMSE, which is a positive real number, \\(\\mathbb{R}_{\\geq 0}\\), which transforms the metric to be unconstrained on the real line \\(\\operatorname{log}: \\mathbb{R}_{\\geq 0} \\rightarrow \\mathbb{R}\\). The outcome is then suitable to model using a Normal distribution.\n$$\n\\[\\begin{aligned}\ny_{ij} &= \\mathcal{N}(\\mu_{ij}, \\sigma^2), \\\\\n\\mu_{ij} &= (\\beta_0 + b_i) + \\beta_1 x_{i1} + \\beta_2 x_{i2}, \\\\\nb_i &\\sim t(1), \\\\\n\\beta_j &\\sim \\mathcal{N}(0, 10), \\\\\n\\sigma &\\sim \\operatorname{Exponential}(1).\n\\end{aligned}\\]\n$$\nThis is a random intercept model, where \\(b_i\\) is drawn from a t-distribution with 1 degree of freedom. This means the coefficients, \\(\\beta_j\\) will be the same across folds in each model and the difference between folds is modeled by the random intercept. For our purposes, we are not interested in the difference between folds, just the difference between the models represented by the \\(\\beta_j\\) coefficients. The variation between the metrics for each fold will inform us how certain our posterior predictions are. Figure @ref(fig:performance-folds) shows the RMSE and R-squared for each of the five folds.\n\n\n\n\n\nPerformance metrics for each fold in the 5-fold cross validation. We can see that due to sampling variation, there is a difference between the measured performance for each fold.\n\n\n\n\n\n# To compare between models, we have as the id column the fold under consideration.\n# each column then corresponds to a model with the same metric.\nfit <- results_df %>%\n  select(id = fold, model = wflow_id, rmse) %>%\n  pivot_wider(names_from = model, values_from = rmse) %>%\n  tidyposterior::perf_mod(\n    formula = statistic ~ model + (1 | id), \n        transform=tidyposterior::ln_trans,\n    prior_intercept = rstanarm::student_t(df = 1)\n  )\n\n\n\n\nFigure @ref(fig:posterior-performance) (left) shows the posterior distribution of the RMSE for the two linear regression models applied to the simulated dataset. Figure @ref(fig:posterior-performance) (right) shows the posterior difference between the estimated RMSE for the linear regression model specified with the known data generating process, compared to the linear regression model without polynomial terms. There is 95% probability that the RMSE of the model which uses the known data generating process is 0.61 smaller than linear regression model specified without polynomial terms.\n\n\n\n\n\nPosterior predictive distributions for the performance of the the regression models. (Left) RMSE for each model. (Right) Difference in the RMSE for the two linear regression models."
  },
  {
    "objectID": "posts/2019-06-14-bayesian-linear-regression/index.html",
    "href": "posts/2019-06-14-bayesian-linear-regression/index.html",
    "title": "Bayesian Linear Regression with Gibbs Sampling in R",
    "section": "",
    "text": "Linear regression models are commonly used to explain relationships between predictor variables and outcome variables. The data consists of pairs of independent observations \\((y_i, x_i)\\) where \\(y_i \\in \\mathbb{R}\\) represents the outcome variable of the \\(i^\\text{th}\\) observation and \\(x_i \\in \\mathbb{R}^m\\) represents the predictors (or covariates) of the \\(i^\\text{th}\\) observation. The specification for this model is:\n\\[y_i = \\alpha + x_i^T\\beta + \\varepsilon_i, \\quad \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2).\\]\nThe parameters of the model include the intercept (or overall mean) \\(\\alpha \\in \\mathbb{R}\\), the coefficients of the predictor variables, \\(\\beta \\in \\mathbb{R}^m\\) is a \\(m \\times 1\\) column vector and the standard deviation of the un-modelled noise, \\(\\sigma \\in \\mathbb{R}\\)."
  },
  {
    "objectID": "posts/2019-06-14-bayesian-linear-regression/index.html#the-model-as-a-data-generating-process",
    "href": "posts/2019-06-14-bayesian-linear-regression/index.html#the-model-as-a-data-generating-process",
    "title": "Bayesian Linear Regression with Gibbs Sampling in R",
    "section": "The Model as a Data Generating Process",
    "text": "The Model as a Data Generating Process\nIn order to manufacture a deeper understand of linear regression it is useful to explore the model as a data generating process. This allows us to understand when linear regression is applicable, how to effectively perform parameter inference and how to assess the model fit. If the model is suitable for the application, then synthetic data from the model with appropriately chosen parameters should be indistinguishable from real observed data. The parameters used to generate the simulated data are known and hence inference algorithms should be able to reliably recover these parameters using the simulated data.\nFirst consider a simple linear regression (a regression where there is only one predictor variable) which links height to weight. We assume that height will be of adults and measured in cm. This is a continuous variable and we might think that this could be modelled using a Normal distribution with a mean of \\(150\\) and a standard deviation of \\(20\\). Let’s simulate some values:\n\nheights <- rnorm(100, mean = 150, sd = 20)\nqplot(heights, geom = \"histogram\")\n\n\n\n\nWe have simulated 100 heights and plotted them on a histogram. The tallest adults are 200cm and the smallest are 100cm. Now that we have our heights, it remains to choose a suitable value for the parameter \\(\\alpha\\) which will be the intercept and the coefficient \\(\\beta\\) which will be multiplied by height to determine the weight in kilograms. In addition, a value of the unmodelled noise \\(\\sigma\\) must be chosen, this seems reasonable since we know that other factors apart from height determine an individuals weight.\n\nalpha <- 60\nbeta <- 0.3\nsigma <- 5\nweights <- purrr::map_dbl(heights, ~ rnorm(1, mean = alpha + beta * ., sd = sigma))\nqplot(weights, geom = \"histogram\")\n\n\n\n\nFor every height, we have simulated an associated weight using purrrs map_dbl. We can plot the height against the weight and see that there is a generally increasing trend, this is expected since our chosen value of the coefficient \\(\\beta = 0.5\\).\n\nqplot(heights, weights)\n\n\n\n\nWhen performing an applied analysis in a business context, it might be tempting to stop here after plotting the relationship between height and weight. However these heights and weights are only a sample of a population - we wish to make statements which pertain to the entire population. If we consider the sample representative of the population then a properly fitted statistical model will allow us to make statements about the population which this sample is drawn from. As an example of a common business problem, this could include sales of a product - we wish to make statements about future sales which we can’t possibly have seen and hence a statistical model is important."
  },
  {
    "objectID": "posts/2019-06-14-bayesian-linear-regression/index.html#fitting-the-model",
    "href": "posts/2019-06-14-bayesian-linear-regression/index.html#fitting-the-model",
    "title": "Bayesian Linear Regression with Gibbs Sampling in R",
    "section": "Fitting the model",
    "text": "Fitting the model\nA parametric model is described by a distribution \\(p(y|\\theta)\\) where \\(y\\) represents the observed data and \\(\\theta\\) represents the parameters. These parameters are unknown, but represent properties of the model. The distribution of the observed data is controlled by the values of the parameters, \\(\\theta\\). The goal of Bayesian inference is to learn which values of the parameters are consistent with the observed data. The parameters are unknown and can’t be determined precisely, however the more data collected the more accurate the posterior inferences can be.\nIn the Bayesian paradigm, the parameters also have a distribution. Before the data is observed, this is referred to as the prior distribution \\(p(\\theta)\\) which can incorporate the hypothesis of the analyst. The goal is to determine the posterior distribution of the parameters given the observed data, this can be achieved using Bayes theorem:\n\\(p(\\theta|y) = \\frac{p(\\theta)p(y|\\theta)}{\\int_\\theta p(\\theta)p(y|\\theta)d\\theta}\\)\nThe likelihood for linear regression with \\(n\\) univariate observations, \\(\\textbf{y} = y_1,\\dots,y_n\\) is written as\n\\[p(\\textbf{y}|\\psi) = \\prod_{i=1}^n\\mathcal{N}(\\alpha + x_i^T\\beta, \\tau),\\]\nnote that the likelihood is parameterised in terms of the precision \\(\\tau = \\frac{1}{\\sigma^2}\\). Standard prior distributions for simple linear regression are chosen to be\n\\[\\begin{align*}\np(\\tau) &= \\textrm{Gamma}(\\alpha_\\sigma, \\beta_\\sigma), \\\\\np(\\alpha) &= \\mathcal{N}(\\mu_\\alpha, \\sigma^2_\\alpha), \\\\\np(\\beta) &= \\mathcal{N}(\\mu_\\beta, \\sigma^2_\\beta).\n\\end{align*}\\]\n\nGibbs Sampling\nGibbs sampling works by alternately sampling from the conditional conjugate distribution. It can often be faster for models which are specified using the conjugate structure, however the choice of prior distribution is not flexible (but the parameterisation is). The algebra below is not required to implement a Gibbs sampling algorithm as there are probabilistic programming languages such as BUGS and JAGS which work out the required maths.\nUsing the likelihood and priors from the section above we can derive the conditionally conjugate posterior distributions:\n$$\\[\\begin{align*}\n\n\np(\\tau|\\textbf{y}, \\textbf{x}, \\beta, \\alpha) &= p(\\tau)\\prod_{i=1}^np(y_i|\\psi), \\\\\n&= \\textrm{Gamma}(\\tau|\\alpha_\\sigma, \\beta_\\sigma)\\prod_{i=1}^n\\mathcal{N}(y_i|\\alpha + x_i^T\\beta, \\sigma^2), \\\\\n&\\propto \\tau^{\\alpha_\\tau-1}e^{-\\beta_\\tau\\tau}\\tau^{\\frac{n}{2}}\\exp\\left\\{-\\frac{\\tau}{2}\\sum_{i=1}^n(y_i-\\alpha - x_i^T\\beta)^2\\right\\}, \\\\\n&= \\tau^{\\alpha_\\tau-1 + \\frac{n}{2}}\\exp\\left\\{-\\beta_\\tau\\tau-\\frac{\\tau}{2}\\sum_{i=1}^n(y_i-\\alpha - x_i^T\\beta)^2\\right\\},\\\\\n&=\\textrm{Gamma}\\left(\\alpha_\\tau+\\frac{n}{2}, \\beta_\\tau +\\frac{1}{2}\\sum_{i=1}^n(y_i-\\alpha - x_i^T\\beta)^2\\right).\n\\end{align*}\\]$$\n\\[\\begin{align*}\np(\\alpha|\\textbf{y}, \\textbf{x}, \\beta, \\tau) &= \\mathcal{N}(\\alpha|\\mu_\\alpha, \\tau_\\alpha)\\prod_{i=1}^n\\mathcal{N}(y_i|\\alpha + x_i^T \\beta, \\tau), \\\\\n&\\propto \\tau^{\\frac{1}{2}}_\\alpha\\exp\\left\\{-\\frac{\\tau_\\alpha}{2}(\\alpha-\\mu_\\alpha)^2\\right\\}\\tau^\\frac{n}{2}\\exp\\left\\{-\\frac{\\tau}{2}\\sum_{i=1}^n(y_i-\\alpha-x_i^T \\beta)^2\\right\\}, \\\\\n&= \\exp\\left\\{-\\frac{\\tau_\\alpha}{2}(\\alpha-\\mu_\\alpha)^2-\\frac{\\tau}{2}\\sum_{i=1}^n(y_i-\\alpha-x_i^T \\beta)^2\\right\\}, \\\\\n&= \\exp \\left\\{ -\\frac{1}{2}\\left(\\alpha^2(\\tau_\\alpha + n\\tau) + \\alpha(-2\\tau_\\alpha\\mu_\\alpha - 2\\tau\\sum_{i=1}^n (y_i - x_i^T \\beta)) \\right) + C \\right\\}, \\\\\n&= \\mathcal{N}\\left((\\tau_\\alpha + n\\tau)^{-1}\\left(\\tau_\\alpha + \\tau\\sum_{i=1}^n (y_i - x_i^T \\beta)\\right), \\tau_\\alpha + n\\tau\\right).\n\\end{align*}\\]\n$$\\[\\begin{align*}\n\n\np(\\beta|\\textbf{y}, \\textbf{x}, \\alpha, \\tau) &= \\mathcal{N}(\\beta|\\mu_\\beta, \\tau_\\beta)\\prod_{i=1}^n\\mathcal{N}(y_i|\\alpha + x_i^T \\beta, \\tau), \\\\\n&\\propto \\tau^{\\frac{1}{2}}_\\beta\\exp\\left\\{-\\frac{\\tau_\\beta}{2}(\\beta-\\mu_\\beta)^2\\right\\}\\tau^\\frac{n}{2}\\exp\\left\\{-\\frac{\\tau}{2}\\sum_{i=1}^n(y_i-\\alpha-x_i^T \\beta)^2\\right\\}, \\\\\n&= \\exp\\left\\{-\\frac{\\tau_\\beta}{2}(\\beta-\\mu_\\beta)^2-\\frac{\\tau}{2}\\sum_{i=1}^n(y_i-\\alpha-x_i^T \\beta)^2\\right\\}, \\\\\n&= \\exp \\left\\{ -\\frac{1}{2}\\left(\\beta^2(\\tau_\\beta + \\tau\\sum_{i=1}^nx_i^2) + \\beta(-2\\tau_\\beta\\mu_\\beta - 2\\tau\\sum_{i=1}^n (y_i - \\alpha) x_i) \\right) + C \\right\\}, \\\\\n&= \\mathcal{N}\\left((\\tau_\\beta + \\sum_{i=1}^nx_i^2\\tau)^{-1}\\left(\\tau_\\beta + \\tau\\sum_{i=1}^n (y_i - \\alpha )x_i\\right), \\tau_\\beta + \\tau\\sum_{i=1}^nx_i^2 \\right).\n\\end{align*}\\]$$\nThis allows us to construct a Gibbs Sampler for the linear regression model by alternating sampling from the precision, \\(\\tau\\) given the latest value of the coefficient vector \\(\\beta\\) and vice versa. The functions to sample from the conditional posterior distributions are written in R as:\n\nsample_tau <- function(ys, alpha, beta, alpha0, beta0) {\n  rgamma(1,\n    shape = alpha0 + nrow(ys) / 2,\n    rate = beta0 + 0.5 * sum((ys$y - (alpha + as.matrix(ys$x) %*% beta))^2)\n  )\n}\n\nsample_alpha <- function(ys, beta, tau, mu0, tau0) {\n  prec <- tau0 + tau * nrow(ys)\n  mean <- (tau0 + tau * sum(ys$y - as.matrix(ys$x) %*% beta)) / prec\n  rnorm(1, mean = mean, sd = 1 / sqrt(prec))\n}\n\nsample_beta <- function(ys, alpha, tau, mu0, tau0) {\n  prec <- tau0 + tau * sum(ys$x * ys$x)\n  mean <- (tau0 + tau * sum((ys$y - alpha) * ys$x)) / prec\n  rnorm(1, mean = mean, sd = 1 / sqrt(prec))\n}\n\nThen a function which loops through each conditional distribution in turn is defined using the three functions defined above. Each conditional distribution is dependent on the parameter draw made immediately above.\n\ngibbs_sample <- function(ys,\n                         tau0,\n                         alpha0,\n                         beta0,\n                         m,\n                         alpha_tau,\n                         beta_tau,\n                         mu_alpha,\n                         tau_alpha,\n                         mu_beta,\n                         tau_beta) {\n  tau <- numeric(m)\n  alpha <- numeric(m)\n  beta <- numeric(m)\n  tau[1] <- tau0\n  alpha[1] <- alpha0\n  beta[1] <- beta0\n  \n  for (i in 2:m) {\n    tau[i] <-\n      sample_tau(ys, alpha[i - 1], beta[i - 1], alpha_tau, beta_tau)\n    alpha[i] <-\n      sample_alpha(ys, beta[i - 1], tau[i], mu_alpha, tau_alpha)\n    beta[i] <- sample_beta(ys, alpha[i], tau[i], mu_beta, tau_beta)\n  }\n  \n  tibble(iteration = seq_len(m),\n         tau,\n         alpha,\n         beta)\n}\n\n\nys <- tibble(y = weights, \n             x = heights)\n\n\nplan(multiprocess)\niters <- future_map_dfr(\n  .x = 1:2,\n  .f = function(x) gibbs_sample(\n      ys,\n      tau0 = 0.5,\n      alpha0 = 60,\n      beta0 = 0.3,\n      m = 1e4,\n      alpha_tau = 3,\n      beta_tau = 2,\n      mu_alpha = 0,\n      tau_alpha = 0.01,\n      mu_beta = 0,\n      tau_beta = 0.01\n    ),\n  .id = \"chain\"\n)"
  },
  {
    "objectID": "posts/2019-06-14-bayesian-linear-regression/index.html#making-the-markov-chain-more-efficient",
    "href": "posts/2019-06-14-bayesian-linear-regression/index.html#making-the-markov-chain-more-efficient",
    "title": "Bayesian Linear Regression with Gibbs Sampling in R",
    "section": "Making the Markov chain more efficient",
    "text": "Making the Markov chain more efficient\nIn order to get this chain to mix better, the predictor (the height, \\(x\\)) can be centered by subtracting the mean. This will result in the intercept being higher than when using the untransformed data, since the outcome variable (the weight, \\(y\\)) is not transformed. In order to recover the value of the parameter\n\ngibbs_sample_centered <- function(ys,\n                         tau0,\n                         alpha0,\n                         beta0,\n                         m,\n                         alpha_tau,\n                         beta_tau,\n                         mu_alpha,\n                         tau_alpha,\n                         mu_beta,\n                         tau_beta) {\n  tau <- numeric(m)\n  alpha <- numeric(m)\n  beta <- numeric(m)\n  tau[1] <- tau0\n  alpha[1] <- alpha0\n  beta[1] <- beta0\n  \n  mean_x = mean(ys$x)\n  ys$x = ys$x - mean_x\n\n  for (i in 2:m) {\n    tau[i] <- sample_tau(ys, alpha[i - 1], beta[i - 1], alpha_tau, beta_tau)\n    alpha[i] <- sample_alpha(ys, beta[i - 1], tau[i], mu_alpha, tau_alpha)\n    beta[i] <- sample_beta(ys, alpha[i], tau[i], mu_beta, tau_beta)\n  }\n\n  tibble(\n    iteration = seq_len(m),\n    tau,\n    alpha = alpha - mean_x * beta,\n    beta\n  )\n}\n\n\niters_centered <- future_map_dfr(\n  .x = 1:2,\n  .f = function(x) gibbs_sample_centered(\n      ys,\n      tau0 = 0.5,\n      alpha0 = 60,\n      beta0 = 0.3,\n      m = 1e4,\n      alpha_tau = 3,\n      beta_tau = 2,\n      mu_alpha = 0,\n      tau_alpha = 0.01,\n      mu_beta = 0,\n      tau_beta = 0.01\n    ),\n  .id = \"chain\"\n)\n\n\niters_centered %>% \n  filter(iteration > 1000) %>% \n  gather(key = \"parameter\", value, -chain, -iteration) %>%\n  plot_diagnostics_sim(actual_values)\n\n\n\n\nThe draws from the Gibbs sampling algorithm are draws from the posterior distribution which can be used to produce summaries required for inference using the linear model. Posterior fitted values, ie. a straight line, can be plotted by sampling pairs of values (\\(\\alpha, \\beta\\)) from the MCMC output and plotting them using the equation of a straight line (\\(y = \\alpha + \\beta x\\)). This gives an indication of the uncertainty in the parameter estimates."
  },
  {
    "objectID": "posts/2017-10-26-harrier-league-cross-country/index.html",
    "href": "posts/2017-10-26-harrier-league-cross-country/index.html",
    "title": "Harrier League Cross Country",
    "section": "",
    "text": "The Harrier League is a cross country running league with seven fixtures across the North East of England in the 2017/18 season across the winter months from September ’17 until March ’18.\nThe Harrier League is unique to other cross country fixtures because the senior runners are divided up into slow, medium and fast packs. In the senior men’s race, the slow runners start first followed 2 minutes 30 seconds later by the medium pack runners, then a further 2 minutes 30 seconds by the fast pack runners.\nIn order to progress to the fast pack, runners must first run in the slow pack and finish in the top 10% of finishers, this entitles them to run from the medium pack. If they then finish in the top 10% from the medium pack, then they can run from the fast pack.\nTeams are split into three divisions and final team positions are calculated within each division by ordering the first six runners (four in the senior women) by race time. This is the total time elapsed from when the slow pack starts to when the runner crosses the finish line. Let’s answer one interesting question, what would the results be from the past weekends fixture without the handicaps, i.e. if everyone started from scratch.\nThe code for this analysis was written using R and the tidyverse. The full code can be found on Github. Let me know if you’d like me to answer other questions about the harrier league."
  },
  {
    "objectID": "posts/2017-10-26-harrier-league-cross-country/index.html#senior-men",
    "href": "posts/2017-10-26-harrier-league-cross-country/index.html#senior-men",
    "title": "Harrier League Cross Country",
    "section": "Senior Men",
    "text": "Senior Men\nIn the senior men’s race there are six counters, any team with less than six runners will be removed from the final results. Now, we can calculate the position of each runner within each division by the actual running time of each runner.\n\nmens_results_raw = htmltab(doc = \"http://www.harrierleague.com/results/2017-18/druridge/SenM.htm\")\nmens_results = clean_results(mens_results_raw)\n\n\n\nSenior Men’s Division One\n\n\n\n\n\n\n\n\nposition\nclub\ntotal_points\ncounters\n\n\n\n\n1\nTyne Bridge Harriers\n89\nPaul O’Mara (9), James Dunce (2), Tom Charlton (4), Alasdair Blain (26), Tony Carter (21), Paul Turnbull (27)\n\n\n2\nDurham City Harriers\n111\nAlexander Cook (22), Jonathan Wilkinson (8), Francisco Martinez-Sevilla (16), Michael Wade (17), David Cross (36), Robin Linten (12)\n\n\n3\nMorpeth Harriers & AC\n129\nRobert Balmbra (1), Thomas Innes (23), Tony Lewis (37), Richard Castledine (39), Alistair Douglass (14), Mark Snowball (15)\n\n\n4\nSunderland Harriers\n149\nSean Mackie (31), Paul Blakey (10), Andrew Powell (3), Robert Walker (20), Steven Duffy (33), Paul Merrison (52)\n\n\n5\nGateshead Harriers\n159\nMatthew Linsley (43), Ross Christie (13), Conrad Franks (7), Steven Asquith (31), Kevin Connolly (18), Peter Grimoldby (47)\n\n\n6\nHeaton Harriers\n188\nMatt Hetherington (19), Sam Thorpe (30), James Meader (24), James Mckenzie (11), Mark Oliver (50), Ian Norman (54)\n\n\n7\nElvet Striders\n255\nStephen Jackson (5), Jack Lee (57), Jason Harding (34), Michael Mason (25), Phil Ray (66), Scott Watson (68)\n\n\n8\nBirtley AC\n348\nAdrian Bailes (6), Peter Farnie (40), Karl Oakes (79), Peter Gill (44), Mark Hornsby (87), Trevor Crewe (92)\n\n\n9\nNorth Shields Poly\n374\nPaul West (29), Michael Parkinson (27), Michael Gibson (78), Paul Davies (49), William Powis (95), Richard Hanley (96)\n\n\n10\nWallsend Harriers\n445\nSimon Lyon (35), David Diston (76), Jack Armstrong (57), Brian Hetherington (59), Keith Odonnell (108), Paul James (110)\n\n\n\n\n\n\nSenior Men’s Division Two\n\n\n\n\n\n\n\n\nposition\nclub\ntotal_points\ncounters\n\n\n\n\n1\nJarrow & Hebburn AC\n90\nAndy Burn (1), Jonny Evans (3), Kevin Emmett (20), Jack Brown (25), Jonathan Gilroy (14), Conal Tuffnell (27)\n\n\n2\nAlnwick Harriers\n122\nDan Turnbull (5), Adam Fletcher (22), Steve Carragher (10), Ian Simon (34), Dominic Harris (21), Philip Hemsley (30)\n\n\n3\nGosforth Harriers\n132\nTom Coates (18), Maurice Bourke (31), Andrew Heppell (15), Jonny Stephenson (24), James McCreesh (13), Neil Ramsay (31)\n\n\n4\nElswick Harriers\n176\nIain Hardy (40), Lee Bennett (7), John Bell (43), Mark Turnbull (19), Kevin Richardson (11), David Armstrong (56)\n\n\n5\nSaltwell Harriers\n181\nGraham Stephenson (28), Iain Armstrong (12), Fred Smith (44), Jim Thompson (16), Matt O’Brien (16), Peter Mullarkey (65)\n\n\n6\nSouth Shields Harriers\n214\nLuke Adams (2), Jeff Mcgurty (40), Paul Owen (45), Neil Turner (46), Stephen Mackin (53), Mark Wilson (28)\n\n\n7\nBlyth RC\n219\nGraeme Stewart (36), Tony Horsley (38), Gary Jones (8), Graham Wood (51), Calum Storey (22), Paul Whalley (64)\n\n\n8\nSunderland Strollers\n253\nCallum Thom (9), Luke Mccormack (49), Ritchie Gerry (26), Paul Dunlop (66), Michael Dixon (68), Ken Maynard (35)\n\n\n9\nSedgefield Harriers\n311\nJames Oldfield (4), David Bentley (42), Mark Raine (48), David Walker (56), Mil Walton (77), Chris Lines (84)\n\n\n10\nBlackhill\n319\nJordan Bell (6), Ian Young (55), Gary Dixon (60), Jonathan Richards (68), Daryl Priestley (79), Michael Mcdonald (51)\n\n\n11\nCrook AC\n847\nPaul Brennan (90), Geoff Hewitson (98), Mark Nichol (148), Gerry Hehir (168), Lloyd Ashby (169), Paul Wragg (174)\n\n\n\n\n\n\nSenior Men’s Division Three\n\n\n\n\n\n\n\n\nposition\nclub\ntotal_points\ncounters\n\n\n\n\n1\nLow Fell RC\n77\nGavin Thompson (13), David France (3), Ian Marriott (23), Fai Ng (25), Paul Harrison (9), Stephen Magrath (4)\n\n\n2\nHoughton AC\n80\nJuma Tatah (14), Stephen Johnson (21), Lee Dover (2), Adam Middleton (16), Tom Whelan (17), Thomas Grey (10)\n\n\n3\nBlaydon Harriers\n140\nDavid Garner (11), Isaac Dunn (5), James Ramshaw (30), James Dias (7), Jamie Boswell (41), Liam Friel (46)\n\n\n4\nDerwentside AC\n201\nGraham Marshall (18), Mark Davinson (29), David Reay (34), John S Donneky (8), Steven Dickson (27), Chris Lowes (85)\n\n\n5\nJesmond Joggers\n267\nJosh Freed (19), Angus Miller (33), Stuart Harper (43), Gregory Stamp (55), Tim Mcgahey (58), John Farr (59)\n\n\n6\nPonteland Runners\n268\nJohn Mcgargill (47), James Leiper (15), Chris Kenyon (56), Tim Allsop (20), Matthew Levison (62), Matty Bell (68)\n\n\n7\nAshington Hirst\n271\nKurt Heron (1), Paul White (6), Iain Singer (52), Martin Thompson (59), Philip Battista (74), Nic Crofts (79)\n\n\n8\nWashington Running Club\n302\nPeter Setterfield (24), Tim Jones (28), Craig Smith (50), Nick Butchart (51), Carl Smith (66), David Bannan (83)\n\n\n9\nClaremont RR\n391\nRoberto Marzo (22), Anthony Liddle (39), Danny Edwards (70), Duncan Scott (72), David Devennie (93), Dean O’Brien (95)\n\n\n10\nDerwent Valley Trail Runners\n445\nStephen Heseltine (38), Ian Hutchinson (49), Andrew Nesbit (76), Jordan Babak (91), Tony Curry (93), Dan English (98)\n\n\n11\nDerwent Valley Running Club\n553\nMark Marchant (35), Simon Woolley (79), Peter Storey (100), Nick Belcher (105), John Kirby (113), Steve Wade (121)\n\n\n12\nNewcastle Frontrunners\n587\nRussell Dickinson Deane (32), Phillip Hall (67), Mark Sutherland (75), Curtis Allen (123), Ken Hodson (144), Allen Dickinson Deane (146)"
  },
  {
    "objectID": "posts/2017-04-23-BreezeMcmc/index.html",
    "href": "posts/2017-04-23-BreezeMcmc/index.html",
    "title": "MCMC with Scala Breeze",
    "section": "",
    "text": "CitationBibTeX citation:@online{law2017,\n  author = {Jonny Law},\n  title = {MCMC with {Scala} {Breeze}},\n  date = {2017-04-23},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJonny Law. 2017. “MCMC with Scala Breeze.” April 23, 2017."
  },
  {
    "objectID": "posts/2017-01-04-FailureInFunctionalProgramming/index.html",
    "href": "posts/2017-01-04-FailureInFunctionalProgramming/index.html",
    "title": "Using Monads for Handling Failures and Exceptions",
    "section": "",
    "text": "In this post I will give a practical introduction to some useful structures for handling failure in functional programming."
  },
  {
    "objectID": "posts/2017-01-04-FailureInFunctionalProgramming/index.html#referential-transparency",
    "href": "posts/2017-01-04-FailureInFunctionalProgramming/index.html#referential-transparency",
    "title": "Using Monads for Handling Failures and Exceptions",
    "section": "Referential Transparency",
    "text": "Referential Transparency\nOne of the most important properties of functional programming is referential transparency and programming with pure functions. This means we can substitute a pure function with its result, for intance if we have the function def f = 1 + 2, we can replace every occurence of f with 3 and the final evaluation will remain unchanged\nThis simple idea can lead to difficulties when considering functions which involve side effects, such as reading from external sources or generating random numbers. One example of a side effect is an exception, an imperative programmer might write a function to calculate a square root as:\ndef unsafe_sqrt(a: Double): Double = {\n  if (a > 0) math.sqrt(a)\n  else throw new Exception(\"Can't calculate square root of negative number\")\n}\nThis compiles fine, however if we wrote this function for an end user and they didn’t look at the implementation they might not know the function can possibly return an exception."
  },
  {
    "objectID": "posts/2017-01-04-FailureInFunctionalProgramming/index.html#try",
    "href": "posts/2017-01-04-FailureInFunctionalProgramming/index.html#try",
    "title": "Using Monads for Handling Failures and Exceptions",
    "section": "Try",
    "text": "Try\nIn order to make it clear that a function can fail, we can return a Try:\ndef try_sqrt(a: Double): Try[Double] = {\n  if (a > 0) Success(math.sqrt(a))\n  else Failure(throw new Exception(\"Can't calculate square root of negative number\"))\n}\nNow, if someone were to use this function they would be forced to deal with the Try return type and understand that the function can return an exception. Try is actually an algebraic datatype (ADT), an illustrative implementation is:\nsealed trait Try[+A]\ncase class Success[+A](a: A) extends Try[A]\ncase class Failure[+A](exception: Throwable) extends Try[A]\nThis means that a Try can either be a Success or Failure. Learn more about Try in Daniel Westheide’s excellent Neophyte’s Guide to Scala."
  },
  {
    "objectID": "posts/2017-01-04-FailureInFunctionalProgramming/index.html#option",
    "href": "posts/2017-01-04-FailureInFunctionalProgramming/index.html#option",
    "title": "Using Monads for Handling Failures and Exceptions",
    "section": "Option",
    "text": "Option\nAnother simple structure to represent computations which may fail is Option, this is an algebraic datatype:\nsealed trait Option[+A]\ncase class Some[+A](a: A) extends Option[A]\ncase class None extends Option[Nothing]\nIn this case, option can either contain a value using the constructor Some, or can represent the absense of a value using None. This provides less information on failure that Try, but nevertheless is sometimes useful. We can re-write the sqrt function to return an optional value\ndef option_sqrt(a: Double): Option[Double] = {\n  if (a > 0) Some(math.sqrt(a))\n  else None\n}\nNow, when provide an incorrect argument to the function, we get None as the result."
  },
  {
    "objectID": "posts/2017-01-04-FailureInFunctionalProgramming/index.html#nested-maps",
    "href": "posts/2017-01-04-FailureInFunctionalProgramming/index.html#nested-maps",
    "title": "Using Monads for Handling Failures and Exceptions",
    "section": "Nested Maps",
    "text": "Nested Maps\nOption and Try are both monads (strictly Try is not a proper monad), which means they are equipped with two methods which satisfy the monad laws. The two methods defined for all monads are:\ntrait Monad[A, M[_]] {\n  def flatMap[B](f: A => M[B]): M[B]\n  def pure(a: A): M[A]\n}\nWe can define all the functions on Try and Option using these two functions, for instance map:\ndef map[B](f: A => B): M[B] = this.flatMap(a => pure(f(a)))\nNow, we can use the map function to compose option_sqrt and try_sqrt:\ndef sqrt_twice(a: Double): Try[Option[Double]] = try_sqrt(a) map option_sqrt\nHowever, what if we want to apply another function to a value returned by this function:\ndef f(a: Double) = a + 1\nsqrt_twice(81) map (_.map(f))\n// Success(Some(4.0))\nWe get the correct value, but we have to apply map twice, this seems cumbersome. There is a better way!"
  },
  {
    "objectID": "posts/2017-01-04-FailureInFunctionalProgramming/index.html#monad-transformers",
    "href": "posts/2017-01-04-FailureInFunctionalProgramming/index.html#monad-transformers",
    "title": "Using Monads for Handling Failures and Exceptions",
    "section": "Monad Transformers",
    "text": "Monad Transformers\nThe functional programming library cats, short for category, has some built in types for dealing with nesting in a more elegent way. The type OptionT[F[_], A] can be used instead of F[Option[A]], our F[_] type in this case is Try[A]\nimport cats.implicits._\nimport cats.data.OptionT\n\ndef sqrt_twice_trans(a: Double): OptionT[Try, Double] = \n  OptionT.fromOption[Try](option_sqrt(a)) flatMap (b => OptionT.liftF(try_sqrt(b))\nOptionT provides the function fromOption to transform the result of the option_sqrt function into the OptionT monad. The function liftF is used to lift any monad, in this case Try into the OptionT monad. This compiles and we if we now try to apply the function def f(a: Double) = a + 1 to the result of this function we only need a single call to map. This is because OptionT is also a monad:\nsqrt_twice_trans(81) map f\n// OptionT(Success(Some(4.0)))\nThis may seem like quite a lot of effort to remove a call to map, but removing unecessary duplication can help with readability of code, and enable bugs to be spotted earlier. The code has been assembled in a Github gist."
  },
  {
    "objectID": "posts/2016-12-12-KalmanFilter/index.html",
    "href": "posts/2016-12-12-KalmanFilter/index.html",
    "title": "The Kalman Filter in Scala",
    "section": "",
    "text": "A Dynamic Linear Model (DLM) is a special type of state space model, where the state and observation equations are Normally distributed and linear. A general DLM can be written as follows:\n\\[\\begin{aligned} y_t &= F_t x_t + \\nu_t,  &\\nu_t &\\sim \\mathcal{N}(0, V_t) \\\\\nx_t &= G_tx_{t-1} + \\omega_t &\\omega_t &\\sim \\mathcal{N}(0, W_t), \\end{aligned}\\]\n\\(y_t\\) represents the observation of the process at time \\(t\\), \\(x_t\\) is the value of the unobserved state at time \\(t\\). The observation error \\(\\nu_t\\) and the system error \\(\\omega_t\\) are independent and identically distributed Normal random variables. \\(F_t\\) is the observation matrix which transforms the state space to the observation, \\(G_t\\) is the state transition matrix."
  },
  {
    "objectID": "posts/2016-12-12-KalmanFilter/index.html#forward-simulating-from-the-dlm",
    "href": "posts/2016-12-12-KalmanFilter/index.html#forward-simulating-from-the-dlm",
    "title": "The Kalman Filter in Scala",
    "section": "Forward Simulating from the DLM",
    "text": "Forward Simulating from the DLM\nA first order polynomial DLM with constant \\(V\\) and \\(W\\), and \\(F_t = 1\\), \\(G_t = 1\\). can be simulated in scala as follows:\nimport breeze.stats.distributions.Gaussian\n\ncase class Data(time: Time, observation: Observation, state: Option[State])\ncase class Parameters(v: Double, w: Double, m0: Double, c0: Double)\n\ndef simulate(p: Parameters): Stream[Data] = {\nval stateSpace = Stream.iterate(Gaussian(p.m0, sqrt(p.c0)).draw)(x => Gaussian(x, sqrt(p.w)).draw)\n  stateSpace.zipWithIndex map { case (x, t) =>\n    Data(t, x + Gaussian(0, sqrt(p.v)).draw, Some(x)) \n  }\n}\n\nval p = Parameters(3.0, 0.5, 0.0, 10.0)\n// simulate 16 different realisations of 100 observations, representing 16 stations\nval data = (1 to 16) map (id => (id, simulate(p).take(100).toVector))\nWe use the built in streaming library’s iterate function to specify the evolution of the latent state. The initial state \\(x_0\\) is a sample drawn from a normal distribution with mean \\(m_0\\) and variance \\(C_0\\), \\(x_t \\sim \\mathcal{N}(x_0 ; m_0, C_0)\\). The Breeze numerical computing library provides many statistical and mathematical functions is used. Subsequent states are generated by adding \\(\\mathcal{N}(0, W)\\) to the previous state:\n\\[x_t = x_{t-1} + \\omega, \\qquad \\omega \\sim \\mathcal{N}(0, V)\\]\nWe then construct a Stream of Data objects. The Data object has a timestamped observation and an optional state space. We construct the observation at time \\(t\\) by simply adding the observation noise to the state space \\(y_t \\sim \\mathcal{N}(y_t | x_t, V)\\). The state is optional because we can’t observe the state of real data, only simulated data will have a known state.\nA graph of the data from four “stations”, produced using ggplot2 in R is shown in the figure below.\n\n\n\n\n\n\nAn Aside on Referential Transparency\nNote that the function simulate is not referentially transparent, meaning the function will return a different Stream of data each time we run it. Referential transparency is important in functional programming, to allow us to easily reason about complex programs. The Breeze library implements another object for stateful random number generation, the Process object. The MarkovChain object can be used to construct a process without drawing explicitly from the distribution until we run the program. Firstly define a single step of the random walk:\nimport breeze.stats.distributions._\n\ndef step_rw(p: Parameters): Double => Rand[Double] = \n  x => Gaussian(x, p.w)\nIf step_rw is supplied with a set of Parameters, it returns a function from the current state, which is assumed to be materialised, to the next state, which is a Rand[Double]. The actual random number isn’t generated until we sample from distribution represented by Rand. Next, we can construct a MarkovChain using the transition kernel stepRw:\nval random_walk: Process[Double] = MarkovChain(0.0)(step_rw(p))\nrandom_walk.\n  steps.\n  take(100)"
  },
  {
    "objectID": "posts/2016-12-12-KalmanFilter/index.html#the-kalman-filter",
    "href": "posts/2016-12-12-KalmanFilter/index.html#the-kalman-filter",
    "title": "The Kalman Filter in Scala",
    "section": "The Kalman Filter",
    "text": "The Kalman Filter\nThe Kalman Filter can be used to determine the posterior distribution of the state space given the current observation and the \\(p(x_t|D_{t})\\), where \\(D_t = \\{Y_t, D_{t-1}\\}\\) and \\(D_0\\) is the initial information, comprising of the parameters mode parameters \\(W_0\\) and \\(V_0\\) and the initial state \\(x_0 \\sim N(m_0, C_0)\\). The full treatment of the Kalman Filter can be found in the excellent Bayesian Forecasting for Dynamic Models by West and Harrison.\nI will present the filtering equations for the simple model in this post. Suppose we start with the posterior distribution of \\(x_{t-1} \\sim N(m_{t-1}, C_{t-1})\\). The first thing we need to do is advance the state, the equation to advance the state is a simple Markov transition \\(x_t = x_{t-1} + \\omega_t\\). We simply add the system variance, the system variance is drawn from a Normal distribution with zero mean and variance \\(W\\). The sum of two Normal distributions is Normal with the mean and variance added, hence the prior for \\((x_t | D_{t-1}) \\sim N(m_{t-1}, C_{t-1} + W)\\).\nNext we need to construct the observation, using the observation equation which is commonly called the one-step forecast for the series, \\(y_t = x_t + \\nu_t\\), since \\(\\nu_t\\) is Normally distributed with zero mean and variance \\(V\\), the distribution of the one step forecast is, \\((y_t|D_{t-1}) \\sim N(m_{t-1}, C_{t-1} + W + V)\\).\nNow, we observe the true value of \\(y_t\\) and are able to construct the posterior distribution of \\((x_t | D_t) \\sim N(m_t, C_t)\\). \\(m_t = m_{t-1} + A_t e_t\\) and \\(C_t = A_tV\\). \\(A_t = \\frac{C_{t-1} + W}{ C_{t-1} + W + V}\\) is known as the regression coefficient, and \\(e_t = Y_t - m_{t-1}\\). This result can be shown using properties of the multivariate normal distribution, and is presented in full in Bayesian Forecasting for Dynamic Models by West and Harrison.\nWe now have the equations required to program up the Kalman Filter using Scala.\ncase class FilterState(data: Data, p: Parameters)\n\ndef filter(p: Parameters): (FilterState, Data) => FilterState = (s, d) => {\n  val r = s.p.c0 + p.w\n  val q = r + p.v\n  val e = d.observation - s.p.m0\n\n  // kalman gain\n  val k = r / q\n  val c1 = k * p.v\n  \n  // return the data with the expectation of the hidden state and the updated Parameters\n  FilterOut(Data(d.time, d.observation, Some(m1)), Parameters(p.v, p.w, m1, c1))\n} \nThe function filter simply takes in Parameters and one observation, represented by Data and returns the updated parameters required for the next step of the filter. Now we need to write a function which filters a sequence of Data, and returns a sequence consisting of the latent states, which we can do using the function scanLeft.\nA simplified function signature of scanLeft is given by: scanLeft[A](l: List[A], z: A)(f: (A, A) => A): List[A]. A list, l with elements of type A and an initial value, z also of type A if passed to a Function2 and accumulated into another list with elements of type A. The function f is applied to each element of the list pairwise, starting the the head of the lift and the zero element, z. Consider calculating the sum of a list of numbers:\nval numbers = List(1,2,3,4,5)\ndef sum(a: Int, b: Int): Int = a + b\n\nnumbers.scanLeft(0)(sum)\n// List(0, 1, 3, 6, 10, 15)\nThe first calculation is (0 + 1) = 1, which is then used as the first argument in the pairwise sum function, then the second calculation is (1 + 2) = 3, the result of which is used again in the next application of sum. Each intermediate step of the calculation is retained and appended to a list to be output when the list of number is exhausted, so we end up with a cumulative sum, List(0, 1, 3, 6, 10, 15). We can use scanLeft and the Function2, filter to calculate and retain the latent states in a DLM:\ndef filterSeries(data: Seq[Data], initParams: Parameters): Seq[FilterOut] = {\n  val initFilter = FilterState(data.head, params, 0.0) // initialise the filter\n\n  data.\n    scanLeft(initFilter)(filter(initParams)).\n    drop(1)\n}\nNow, we can apply the filter to all the stations simultaneously:\ndata.\n  groupBy{ case (id, _) => id }. //groups by id\n  map{ case (id, idAndData) =>\n  (id, idAndData map (x => x._2)) }. // changes into (id, data) pairs\n  map{ case (id, data) =>\n  (id, filterSeries(data.sortBy(_.time), p)) } // apply the filter to the sorted data\nWe can now plot the results of the filtering using R and ggplot2, overlaid with 95% prediction intervals.\n\nfiltered = read_csv(\n  here::here(\"notebooks/data/filteredDlm.csv\"),\n  c(\"stationId\", \"time\", \"observation\", \"stateMean\", \"m\", \"c\")\n)\n\n## calculate upper and lower 95% bounds of the state estimate\nfiltered %>%\n  select(-observation) %>%\n  inner_join(data, by = c(\"time\", \"stationId\")) %>%\n  filter(stationId %in% 1:4) %>%\n  mutate(upper = qnorm(p = 0.975, mean = m, sd = sqrt(c)), \n         lower = qnorm(p = 0.025, mean = m, sd = sqrt(c))) %>%\n  select(-c, -m, -observation) %>%\n  gather(key, value, -time, -stationId, -upper, -lower) %>%\n  ggplot(aes(x = time, y = value, linetype = key)) + \n  geom_line() +\n  geom_ribbon(aes(x = time, ymin = lower, ymax = upper), alpha = 0.3) +\n  facet_wrap(~stationId, scales = \"free\")\n\n\n\n\nThe full code is available in a notebook file and an ammonite script in the GitHub Repo associated with this blog."
  },
  {
    "objectID": "posts/2017-02-21-AkkaClient/index.html",
    "href": "posts/2017-02-21-AkkaClient/index.html",
    "title": "An Akka HTTP Client with JSON Parsing",
    "section": "",
    "text": "There are many sources of open data on the web, freely accessible via an Application Programming Interface (API) made available over the web. A common interchange format for these APIs is Javascript Object Notation (JSON) which is human readable and predictable, however is not in the correct format for analysis. The data needs to be parsed from the JSON string and made available as an object we can work with. This blog post considers a simple Akka Http client to read data from the Urban Observatory in Newcastle. If you just want to read the code, see this Gist."
  },
  {
    "objectID": "posts/2017-02-21-AkkaClient/index.html#exploring-the-api",
    "href": "posts/2017-02-21-AkkaClient/index.html#exploring-the-api",
    "title": "An Akka HTTP Client with JSON Parsing",
    "section": "Exploring the API",
    "text": "Exploring the API\nThe Urban Observatory consists of a grid of sensors around the North East, measuring traffic, pollution and weather. The focus of this post will be getting sensor data from a single sensor, N05171T, a traffic sensor located near the Metro Centre on Hollinside road. The metadata from this sensor can be found by querying an API endpoint: http://uoweb1.ncl.ac.uk/api/v1/sensor.json?api_key=&sensor_name=N05171T. Note that this requires authentication, using an API key. An API key can be requested using this form.\nThe result of this query is:\n\n\n{\n    \"type\": \"Traffic\",\n    \"geom\": {\n        \"type\": \"LineString\",\n        \"coordinates\": [\n            [\n                -1.674433347,\n                54.959041883\n            ],\n            [\n                -1.673947928,\n                54.959553799\n            ]\n        ]\n    },\n    \"active\": \"True\",\n    \"latest\": \"2017-02-21T08:23:06\",\n    \"base_height\": null,\n    \"sensor_height\": null,\n    \"name\": \"N05171T\",\n    \"source\": {\n        \"web_display_name\": \"NE Travel Data API (Third Party)\",\n        \"third_party\": true,\n        \"db_name\": \"Scoot Netravel Api\",\n        \"document\": \"\",\n        \"fancy_name\": \"NE Travel Data API\"\n    }\n}\n \n\n\nWe can see a bit of information about the sensor, including its location, time of latest reading and whether the sensor is active.\nIn order to retrieve the actual data from the sensor, we query the url http://uoweb1.ncl.ac.uk/api/v1/sensor/data/raw.json with the following required fields:\n\napi_key your API key here\nsensor_name N05171T\nstart_time 20170201\nend_time 20170202\n\nThis returns the following:\n\n\n{\n    \"type\": \"Traffic\",\n    \"geom\": {\n        \"type\": \"LineString\",\n        \"coordinates\": [\n            [\n                -1.674433347,\n                54.959041883\n            ],\n            [\n                -1.673947928,\n                54.959553799\n            ]\n        ]\n    },\n    \"active\": \"True\",\n    \"data\": {\n        \"Congestion\": {\n            \"data\": {\n                \"2017-02-01 01:36:46\": 0.0\n            },\n            \"meta\": {\n                \"name\": \"Congestion\",\n                \"theme\": \"Traffic\",\n                \"units\": \"%\"\n            }\n        },\n        \"Traffic Flow\": {\n            \"data\": {\n                \"2017-02-01 01:36:46\": 4.0\n            },\n            \"meta\": {\n                \"name\": \"Traffic Flow\",\n                \"theme\": \"Traffic\",\n                \"units\": \"Passenger Car Units\"\n            }\n        },\n        \"Average Speed\": {\n            \"data\": {\n                \"2017-02-01 13:21:46\": 35.0\n            },\n            \"meta\": {\n                \"name\": \"Average Speed\",\n                \"theme\": \"Traffic\",\n                \"units\": \"KmPH\"\n            }\n        }\n    },\n    \"latest\": \"2017-02-21T08:33:06\",\n    \"base_height\": null,\n    \"sensor_height\": null,\n    \"name\": \"N05171T\",\n    \"source\": {\n        \"web_display_name\": \"NE Travel Data API (Third Party)\",\n        \"third_party\": true,\n        \"db_name\": \"Scoot Netravel Api\",\n        \"document\": \"\",\n        \"fancy_name\": \"NE Travel Data API\"\n    }\n}\n \n\n\nAll but one of the readings have been stripped for each data object to emphasize the structure of the JSON returned by the API. We can see that sensor N05171T records traffic flow, congestion, and average speed. We can provide a further (optional) field to the Urban Observatory API to limit the results to return only one these. Let’s consider the only the average speed, measures in kmph. This is an unusual unit for the UK, as road speed is measured in miles per hour."
  },
  {
    "objectID": "posts/2017-02-21-AkkaClient/index.html#parsing-the-json-in-scala",
    "href": "posts/2017-02-21-AkkaClient/index.html#parsing-the-json-in-scala",
    "title": "An Akka HTTP Client with JSON Parsing",
    "section": "Parsing the JSON in Scala",
    "text": "Parsing the JSON in Scala\nThere are many JSON parsing libraries in Scala, including my favourite Circe which is a Typelevel project, providing generic parsers for case classes without additional boilerplate. However, Spray JSON and Akka HTTP work well together, so that is what we will be using today. In order to complete this tutorial, you will need the Akka HTTP and Spray JSON dependencies in your build.sbt file.\nlibraryDependencies ++=  Seq(\n  \"com.typesafe.akka\" %% \"akka-stream\" % \"2.4.17\",\n  \"com.typesafe.akka\" %% \"akka-http\" % \"10.0.3\",\n  \"com.typesafe.akka\" %% \"akka-http-spray-json\" % \"10.0.0\")\nFirstly, we describe the data we are interested in, in a collection of case classes representing the JSON data:\ncase class Sensor(name: String, data: SensorData)\ncase class SensorData(averageSpeed: AverageSpeed)\ncase class AverageSpeed(meta: Meta, data: Map[String, Double])\ncase class Meta(units: String, theme: String, name: String)\nWe extract the sensor name, and associated data, without bothering with the additional top-level fields. The sensor data field contains only average speed, by appending &variable=average speed to the end of the HTTP Get request.\nNow we have a domain model for the sensor data, we must provide a way for Spray JSON to parse the JSON to the case classes:\nimport spray.json._\nimport akka.http.scaladsl.marshallers.sprayjson.SprayJsonSupport\n\ntrait Protocols extends SprayJsonSupport with DefaultJsonProtocol {\n  implicit val metaFormat: RootJsonFormat[Meta] = \n    jsonFormat(Meta.apply, \"units\", \"theme\", \"name\")\n   implicit val averagespeedFormat: RootJsonFormat[AverageSpeed] = \n    jsonFormat(AverageSpeed.apply, \"meta\", \"data\")\n   implicit val sensorDataFormat: RootJsonFormat[SensorData] = \n    jsonFormat(SensorData.apply, \"Average Speed\")\n  implicit val sensorFormat: RootJsonFormat[Sensor] = \n    jsonFormat(Sensor.apply, \"name\", \"data\")\n}\nThis trait can be mixed in when the time comes to parse the JSON data. Let’s first test the JSON parsing by directly reading in the JSON we get when running the request in a web browser:\nobject TestJson extends App with Protocols {\n  val json_string = scala.io.Source.fromFile(\"data/traffic_sensor.json\").getLines.mkString\n\n  json_string.\n    parseJson.\n    convertTo[List[Sensor]].\n    foreach(println)\n}\nThere’s a bit going on here, first we have a file which contains the JSON String, this could have been pasted in directly to Scala. Then the string is parsed, this is possible since the TestJson object has the JSON Protocols trait we defined earlier mixed in using with."
  },
  {
    "objectID": "posts/2017-02-21-AkkaClient/index.html#making-an-api-request-using-akka-http",
    "href": "posts/2017-02-21-AkkaClient/index.html#making-an-api-request-using-akka-http",
    "title": "An Akka HTTP Client with JSON Parsing",
    "section": "Making an API Request using Akka HTTP",
    "text": "Making an API Request using Akka HTTP\nIn order to make an API request using Akka HTTP, we utilise the high-level client API based on Scala futures:\nimport akka.actor.ActorSystem\nimport akka.http.scaladsl.marshallers.sprayjson.SprayJsonSupport\nimport akka.http.scaladsl.model._\nimport akka.http.scaladsl.Http\nimport HttpMethods._\nimport akka.stream.ActorMaterializer\nimport Uri.Query\nimport scala.concurrent.Future\n\nimplicit val system = ActorSystem()\nimplicit val materializer = ActorMaterializer()\nimplicit val executionContext = system.dispatcher\n\nval uri = Uri(\"http://uoweb1.ncl.ac.uk/api/v1/sensor/data/raw.json\")\nval api_key = // your api key here\n\n  val query: Query = Query(\"api_key\" -> api_key,\n    \"sensor_name\" -> \"N05171T\",\n    \"start_time\" -> \"20170201\",\n    \"end_time\" -> \"20170202\",\n    \"variable\" -> \"average speed\")\n\nval res: Future[HttpResponse] = \n  Http().singleRequest(HttpRequest(GET, uri = uri.withQuery(query)))\nWe have created a Query object, which is just a sequence of (String, Sting), denoted using the nicer arrow syntax. The request is initialised simply as a singleRequest which retuns a Future containing the HttpResponse. The HttpResponse object contains the status (200 OK, 404 Not Found etc.), and importantly the body content, called HttpEntity, the HttpEntity in this case is simply the JSON. In order to verify we are able to make a requst to the Urban Observatory, we can match on the result of the future using andThen:\nres andThen {\n    case Success(response) => println(response)\n    case Failure(ex) => println(ex)\n  } onComplete {\n    _ => system.terminate()\n  }\nandThen expects a function from a Try, an algebraic data type (ADT) which can be either Success or Failure. When the future completes, we shutdown the Actor System required by Akka HTTP. When you run this minimal example, you should receive a response similar to:\nHttpResponse(200 OK,List(Date: Tue, 21 Feb 2017 09:27:24 GMT, Server: Apache/2.4.7 (Ubuntu), Vary\n: Cookie, X-Frame-Options: SAMEORIGIN),HttpEntity.Chunked(application/json),HttpProtocol(HTTP/1.1\n))\nThe server has returned 200 OK, some headers and some response data. In order to access the response data, we must convert it to a string, first we access the entity field of the HttpResponse, the get the results as a ByteString which can finally be parsed to a String:\nval resp = response.\n  entity.\n  dataBytes.\n  map(_.utf8String)\nThis is an Akka Stream, containing the response from the server. In order to parse it into the sensor data, we map over the string using the JSON parsing function we have previously seen:\nresp.\n  map(_.parseJson.convertTo[List[Sensor]]).\n  runForeach(println)\nThis should print the parsed data to the console. There are a variety of other Akka Sinks which can be used to consume the HttpEntity, they can be found in the Akka docs overview of built in stages.\nA complete working example is available in this Gist."
  },
  {
    "objectID": "posts/2020-03-04-harrier_league_data/index.html",
    "href": "posts/2020-03-04-harrier_league_data/index.html",
    "title": "Releasing Harrier League Data",
    "section": "",
    "text": "The North East Harrier League is a series of cross country running races in the North East of England taking place over the winter from September to March. Results are available online from 2012-13 season to the present season 2019-20. The results are available online in HTML format. I have downloaded and cleaned the data and it can be used for analysis or exploration. The data for senior men and women is available in a tabular format in my blog package - see the file which contains the parsing functions here to get an insight into what it takes to parse this kind of data.\nI used the following R packages to download, parse the HTML and clean the resulting data\nThe data can be accessed by installing my R package which contains a selection of R code relating to this blog."
  },
  {
    "objectID": "posts/2020-03-04-harrier_league_data/index.html#determining-the-most-difficult-course",
    "href": "posts/2020-03-04-harrier_league_data/index.html#determining-the-most-difficult-course",
    "title": "Releasing Harrier League Data",
    "section": "Determining the most difficult course",
    "text": "Determining the most difficult course\nAs a quick example of what can be done with the data I will consider the running time by course. The data can be split by male and female. However the men and women don’t compete over the same distance with the women completing two laps and the men completing three. Therefore we can plot the average time for a single lap of the course (obviously this doesn’t account for changing pace throughout the race). It appears that the hardest (or longest) course is Aykley Heads with the highest median race time."
  },
  {
    "objectID": "posts/2019-04-15-scala-and-jupyter-notebook-with-almond/index.html",
    "href": "posts/2019-04-15-scala-and-jupyter-notebook-with-almond/index.html",
    "title": "Scala and Jupyter Notebook with Almond",
    "section": "",
    "text": "Typically, when programming with Scala I use a combination of ensime in emacs, sbt and the Scala repl. However, sometimes when working on a new project which requires a lot of data exploration and graphics it is sometimes more useful to have a notebook where figures are rendered inline with descriptions of why each figure has been generated and what it shows for future reference. Jupyter notebooks have long been the standard in Python (although I prefer rmarkdown and knitr when using R).\nJupyter notebooks can be initialised with many different kernels to serve a wide array of users. Recently there has been a release which combines the power of the Ammonite scala repl which empowers users to write small Scala scripts where dependencies can be stored in the same script file and are fetched using coursier without the need for a large SBT project. Ammonite has many more features besides this, however scripting is one of my favourites. It also allows us to write self-contained Jupyter notebooks with dependencies by utilising Ammonite as the kernel of the Jupyter notebook using Almond.\nIn this blog, I will show you how to use Almond to fit a linear regression using the probabilistic programming language, Rainier."
  },
  {
    "objectID": "posts/2019-04-15-scala-and-jupyter-notebook-with-almond/index.html#setup-of-almond",
    "href": "posts/2019-04-15-scala-and-jupyter-notebook-with-almond/index.html#setup-of-almond",
    "title": "Scala and Jupyter Notebook with Almond",
    "section": "Setup of Almond",
    "text": "Setup of Almond\n\nInstall Jupyter Notebook using pip\n\npython3 -m pip install --upgrade pip\npython3 -m pip install jupyter\n\nInstall Ammonite\n\nmkdir -p ~/.ammonite && curl -L -o ~/.ammonite/predef.sc https://git.io/vHaKQ\n\nInstall Almond https://almond.sh/docs/quick-start-install\nRun jupyter notebook by running jupyter notebook from a terminal and create a new document in the web interface selecting the “Scala” kernel"
  },
  {
    "objectID": "posts/2019-04-15-scala-and-jupyter-notebook-with-almond/index.html#scala-library-dependencies",
    "href": "posts/2019-04-15-scala-and-jupyter-notebook-with-almond/index.html#scala-library-dependencies",
    "title": "Scala and Jupyter Notebook with Almond",
    "section": "Scala library dependencies",
    "text": "Scala library dependencies\nAmmonite lets you import dependencies directly from Maven central using a special import syntax, for example to import the latest version of the Rainier core library simply type:\nimport $ivy.`com.stripe::rainier-core:0.2.2`\nThen all imports from the Rainier library should be available. Additionally, we want to be able to use a plotting library Evilplot which does not have a standard resolver. Luckily Ammonite makes adding new resolvers straightforward, simply add a new block which points to the Maven repository of cibotech. Note that this is not an especially common operation - since most OSS Scala libraries are stored in the Maven central repository.\nimport coursier.MavenRepository\n\ninterp.repositories() ++= Seq(MavenRepository(\n  \"http://dl.bintray.com/cibotech/public\"\n))\nThen the plotting library can be imported, ensure this is in a new block.\nimport $ivy.`com.stripe::rainier-plot:0.2.2`"
  },
  {
    "objectID": "posts/2019-04-15-scala-and-jupyter-notebook-with-almond/index.html#building-a-model-using-rainier",
    "href": "posts/2019-04-15-scala-and-jupyter-notebook-with-almond/index.html#building-a-model-using-rainier",
    "title": "Scala and Jupyter Notebook with Almond",
    "section": "Building a model using rainier",
    "text": "Building a model using rainier\nThe model under consideration is straightforward, a simple linear regression with unknown slope and intercept:\n\\[y_i = \\alpha + \\beta x_i + \\varepsilon_i, \\quad \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\]\nIn order to perform inference to determine the posterior distribution of the unknown parameters, \\(\\psi = \\{\\alpha, \\beta, \\sigma\\}\\) on this model using Rainier first we simulate some data from the model:\nimport com.stripe.rainier.core._\nimport com.stripe.rainier.sampler._\n\nval (alpha, beta, sigma) =  (-1.5, 2.0, 0.5)\n\nval lm = for {\n  x <- Normal(0, 1).param\n  y <- Normal(alpha + beta * x, sigma).param\n} yield (x, y)\n\nimplicit val s = RNG.default\nval sims = lm.sample(100)\nThe code above uses rainiers sampling-based monad in order to simulate standard Normal data representing the covariates, \\(x_i, i = 1,\\dots,100\\) and the dependent variable \\(y_i\\). 100 \\((x, y)\\) pairs are simulated from the model with the selected parameter values. Now it might be of interest to plot the data using the Evilplot plotting library. Here we write out the data to a csv and use ggplot in R\n\nlm_sims <- read_csv(here::here(\"notebooks/data/lm_sims.csv\"))\n\nRows: 100 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): x, y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nlm_sims %>% \n  ggplot(aes(x, y)) +\n  geom_point()\n\n\n\n\nThe code required to sample from the posterior distribution is similar to that required to simulate the model:\nimport com.stripe.rainier.compute._\n\ndef linearModel(data: Seq[(Double, Double)]): RandomVariable[Map[String, Real]] = for {\n    alpha <- Normal(0, 5).param\n    beta <- Normal(0, 5).param\n    sigma <- LogNormal(2, 2).param\n    _ <- Predictor[Double].from { x =>\n      Normal(alpha + beta * x, sigma)\n    }\n    .fit(data)\n  } yield Map(\"alpha\" -> alpha, \"beta\" -> beta, \"sigma\" -> sigma)\nFirst prior distributions are chosen for the static parameters, then the function Predictor is used to specify the likelihood for the linear regression as the Normal distribution. The data consists of a sequence of tuples. Finally to sample values from the posterior using Hamiltonian Monte Carlo with 5 leapfrog steps and auto-tuning of the leapfrog step-size using dual averaging.\nval iters = linearModel(sims).sample(HMC(5), 5000, 100000, 100)\n\niters <- read_csv(here::here(\"notebooks/data/lm_params.csv\"))\n\nRows: 1000 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): alpha, beta, sigma\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\niters %>% \n  mutate(iteration = row_number()) %>% \n  gather(key = Parameter, value, -iteration) %>% \n  ggplot() +\n    geom_line(ggplot2::aes(x = iteration, y = value), alpha = 0.5) +\n    facet_wrap(~Parameter, scales = \"free_y\", strip.position = \"right\")\n\n\n\n\nThe full notebook can be viewed on Github here."
  },
  {
    "objectID": "posts/2019-08-05-ad_r/index.html",
    "href": "posts/2019-08-05-ad_r/index.html",
    "title": "Forward Mode AD in R",
    "section": "",
    "text": "Automatic differentiation can be used to calculate the exact derivative of a function at a point using applications of the chain rule. Dual numbers provide a straightforward implementation in R using S3 generic methods. A dual number has a real component and a “dual” component which can be used to exactly calculate the expression and derivative at a specific value of \\(x\\). Consider the quadratic form \\(f(x) = 5x^2 + 3x + 10\\) with derivative \\(f^\\prime(x) = 10x + 3\\). The function and derivative can be evaluated at a value, say \\(x = 5\\) using the dual number \\(5 + \\varepsilon\\), the dual component \\(\\varepsilon\\) is considered small such that \\(\\varepsilon^2 = 0\\) then calculating \\(f(5 + \\varepsilon)\\):\n\\[\\begin{align}\nf(5 + \\varepsilon) &= 5(5 + \\varepsilon)^2 + 3(5 + \\varepsilon) + 10,\\\\\n&= 5(25 + 10\\varepsilon + \\varepsilon^2) + 15 + 3\\varepsilon + 10,\\\\\n&= 5\\varepsilon^2 + 53\\varepsilon + 150.\n\\end{align}\\]\nThen the coefficient of \\(\\varepsilon\\) is the derivative and the constant is the evaluation of the function, \\(f(5) = 150\\) and \\(f^\\prime(5) = 53\\)."
  },
  {
    "objectID": "posts/2019-08-05-ad_r/index.html#s3-objects",
    "href": "posts/2019-08-05-ad_r/index.html#s3-objects",
    "title": "Forward Mode AD in R",
    "section": "S3 Objects",
    "text": "S3 Objects\nR has three systems for object oriented programming, S3, S4 and reference classes which can be learned about in the relevant chapter of Advanced R. Dual numbers can be implemented as an S3 class in R:\n\ndual <- function(real, eps) {\n  if (!is.numeric(real)) stop(\"real must be numeric\")\n  structure(list(real = real, eps = eps), class = \"dual\")\n} \nvar <- function(x) {\n  if (!is.numeric(x)) stop(\"x must be numeric\")\n  dual(x, 1)\n}\nconst <- function(x) {\n  if (!is.numeric(x)) stop(\"x must be numeric\")\n  dual(x, 0)\n}\n\nvar represents a variable which we want to differentiate, whereas const represents a constant.\nNext, primitive functions can be defined in terms of dual numbers which simultaneously evaluate the function and the derivative:\n\nplus <- function(x, y) \n  dual(x$real + y$real, x$eps + y$eps)\nminus <- function(x, y) \n  dual(x$real - y$real, x$eps - y$eps)\ntimes <- function(x, y) \n  dual(x$real * y$real, x$eps * y$real + y$eps * x$real)\ndivide <- function(x, y) \n  dual(\n      x$real / y$real,\n      (x$eps * y$real - x$real * y$eps) / (y$real * y$real)\n    )\n\nGroup generics can be used to implement the mathematics of dual numbers. Group generics included with base R include Math which includes special functions such such as abs and sqrt as well as trigonometric and hyperbolic functions. Ops which include the basic infix operations reqruired for arithmetic, +, -, *, / etc. For a full list of group generics associated with Math and Ops consult the R help by typing ?groupGeneric in the R console. In order to implement a group generic for the S3 class dual we implement Ops.dual:\n\nOps.dual <- function(x, y) {\n  switch(\n    .Generic,\n    `+` = plus(x, y),\n    `-` = minus(x, y),\n    `*` = times(x, y),\n    `/` = divide(x, y)\n  )\n}\n\nswitch is used to pattern match on the generic function being called within Ops by matching on .Generic. Implementing dual numbers in this way allows us to define a function using the in-built infix operators in a natural way. The function \\(f(x)\\) can be defined in terms of dual numbers as\n\nf <- function(x) \n  const(5) * x * x + const(3) * x + const(10)\n\nThen evaluated at \\(x = 5\\) using the constructor var which initialises a dual with \\(\\varepsilon = 1.0\\).\n\nf(var(5))\n\n$real\n[1] 150\n\n$eps\n[1] 53\n\nattr(,\"class\")\n[1] \"dual\"\n\n\nThe definition of f is cumbersome since we have to explicitly create the constants using the const constructor. The methods defined in Ops.dual can be extended to handle cases when a double is multiplied by a dual number to convert the double to a const and hence we can automatically differentiate any univariate function using forward mode automatic differentiation.\nWe can write a function which checks the arguments of plus, minus etc, then if the arguments aren’t explicitly dual number variables using the function var then they are converted to a dual constant using const. This function checks each argument (of a generic function of two arguments f) in turn to determine if they are doubles then promotes them to constants.\n\nlift_function <- function(f) {\n  function(x, y)\n    if (is.double(x)) {\n      f(const(x), y)\n    } else if (is.double(y)) {\n      f(x, const(y))\n    } else {\n      f(x, y)\n    }\n}\n\nThe ops can then be re-defined using the lift_function:\n\nOps.dual <- function(x, y) {\n  switch(\n    .Generic,\n    `+` = lift_function(plus)(x, y),\n    `-` = lift_function(minus)(x, y),\n    `*` = lift_function(times)(x, y),\n    `/` = lift_function(divide)(x, y)\n  )\n}\n\nThen f can be defined more naturally:\n\nf <- function(x) \n  5 * x * x + 3 * x + 10\n\nAnd the derivative calculated:\n\nf(var(5))\n\n$real\n[1] 150\n\n$eps\n[1] 53\n\nattr(,\"class\")\n[1] \"dual\""
  },
  {
    "objectID": "posts/2019-08-05-ad_r/index.html#testing-using-hedgehog",
    "href": "posts/2019-08-05-ad_r/index.html#testing-using-hedgehog",
    "title": "Forward Mode AD in R",
    "section": "Testing using Hedgehog",
    "text": "Testing using Hedgehog\nHedgehog is a package which utilises testthat to implement property based testing in R. Property based testing can be used to check a wide range of inputs to a function and determine if the code outputs the expected value. In standard unit testing the state before the test is defined by programmer and typically does not change - if we were to consider a test for the derivative of the quadratic function defined above then we might write a test which evaluates the function at \\(x = 5\\). This verifies we are correct for \\(x = 5\\), but what about \\(x = 0\\) or another value. With property based testing, we define a random generator for the input and the test checks hundreds of potential values for failure.\nThe input to this property based test is a, a number between \\(-100\\) and \\(100\\). The usual testthat syntax is then used to evaluate the gradient using forward mode AD and comparing it to the exact derivative calculated by hand.\n\ntest_that(\"Derivative of 5x^2 + 3x + 10\",\n          forall(list(a = gen.c(gen.element(\n            -100:100\n          ))),\n          function(a)\n            expect_equal(object = f(var(a))$eps, expected = 10 * a + 3)))\n\nTest passed 🎊"
  },
  {
    "objectID": "posts/2019-11-04-parsing-strava/index.html",
    "href": "posts/2019-11-04-parsing-strava/index.html",
    "title": "Analysing .fit files in R",
    "section": "",
    "text": "library(tidyr)\n\nWarning: package 'tidyr' was built under R version 4.1.2\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.1.2\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(readr)\n\nWarning: package 'readr' was built under R version 4.1.2\n\nlibrary(ggplot2)\nlibrary(reticulate)\n\nWarning: package 'reticulate' was built under R version 4.1.2\n\nlibrary(leaflet)\n\nWarning: package 'leaflet' was built under R version 4.1.2\n\ntheme_set(theme_minimal())\nGarmin running watches output a file type called .fit, the developer SDK can be downloaded from the ANT website. There is also Python library named fitparse which has been written to parse .fit files. This blog post will show you how to use reticulate to parse a .fit file.\nFirst create a Python virtual environment, this is commonly used to store a projects’ package collection together to enable more straightforward reproducibility. A virtual environment also contains its own Python and the python package manager pip for installing and managing packages. reticulate has a function to create a virtual environment:"
  },
  {
    "objectID": "posts/2019-11-04-parsing-strava/index.html#parsing",
    "href": "posts/2019-11-04-parsing-strava/index.html#parsing",
    "title": "Analysing .fit files in R",
    "section": "Parsing",
    "text": "Parsing\nThe virtual environment can be used to install the Python package fitparse\n\npy_install(\"fitparse\")\n\nThe library can be imported as an R object.\n\nfitparse <- reticulate::import(\"fitparse\")\n\nThen methods and classes defined in the fitparse Python libary can be accessed using the $ notation. Typing $ after fitparse (and hitting the TAB key) in the RStudio IDE gives a list of top-level methods and classes defined in the fitparse library.\n\nfit_file <- here::here(\"posts/2019-11-04-parsing-strava/1001800515.fit\")\n\n\nff <- fitparse$FitFile(fit_file)\n\nWe can use the get_messages method on the FitFile. This returns a generator, this is a special type of lazy list in Python.\n\ngenerator <- ff$get_messages(\"record\")\n\niterate is a function provided by the reticulate library which can be used to traverse a Python generator:\n\nactivity <- reticulate::iterate(ff$get_messages(\"record\"), function(x) x$get_values())\n\nThis evaluates the generator and applies the function get_values to retrieve the details associated with this activity. A list object is returned by R, the first element looks like this:\n\nactivity[[1]]\n\n$timestamp\n2017-03-16 17:22:08\n\n$position_lat\n[1] 655852851\n\n$position_long\n[1] -19374352\n\n$distance\n[1] 3.47\n\n$enhanced_altitude\n[1] 88.8\n\n$altitude\n[1] 88.8\n\n$enhanced_speed\n[1] 3.471\n\n$speed\n[1] 3.471\n\n$vertical_oscillation\n[1] 120\n\n$stance_time_percent\n[1] 34.25\n\n$stance_time\n[1] 259\n\n$heart_rate\n[1] 137\n\n$cadence\n[1] 79\n\n$activity_type\n[1] \"running\"\n\n$fractional_cadence\n[1] 0\n\n\nWe want to transform this list of lists into a dataframe. The most straightforward way is to extract the elements of interest using the map function from purrr:\n\n(activity_tibble <- activity %>%\n  purrr::map_dfr(function(x) tibble(\n    timestamp = readr::parse_datetime(as.character(x$timestamp)),\n    latitude = x$position_lat,\n    longitude = x$position_long,\n    elevation = x$enhanced_altitude,\n    heart_rate = x$heart_rate,\n    cadence = x$cadence\n    )))\n\n# A tibble: 611 × 6\n   timestamp            latitude longitude elevation heart_rate cadence\n   <dttm>                  <int>     <int>     <dbl>      <int>   <int>\n 1 2017-03-16 17:22:08 655852851 -19374352      88.8        137      79\n 2 2017-03-16 17:22:09 655853310 -19375987      90.2        138      79\n 3 2017-03-16 17:22:10 655854123 -19374810      81.2        138      80\n 4 2017-03-16 17:22:15 655856545 -19372657      39.2        139      78\n 5 2017-03-16 17:22:21 655859405 -19368861      54.2        140      79\n 6 2017-03-16 17:22:26 655860948 -19365257      54.6        140      80\n 7 2017-03-16 17:22:32 655860904 -19362723      65.4        138      79\n 8 2017-03-16 17:22:33 655861059 -19361314      69          138      79\n 9 2017-03-16 17:22:37 655860087 -19358357      98.8        135      79\n10 2017-03-16 17:22:44 655860947 -19354267      97          135      80\n# … with 601 more rows\n\n\nNotice that the latitude and longitude don’t look correct, it turns out they are in semicircles and can be converted to a recognisable coordinate system using the following function.\n\nsemicircle_to_degrees <- function(semicircle)\n  semicircle * (180 / 2**31)\n\nApplying the function to the latitude and longitude models.\n\nactivity_tibble <- activity_tibble %>% \n  mutate_at(vars(latitude, longitude), semicircle_to_degrees)\n\nThis is a very basic summary of the activity. We can derive the distance per timestep using the longitude, latitude and timestamp fields.\n\n(activity_tibble <- activity_tibble %>%\n  mutate(\n    time_diff_to_prev = as.numeric(difftime(timestamp, lag(timestamp, default = .$timestamp[1]))),\n    cumtime = cumsum(time_diff_to_prev),\n    dist_to_prev = c(0, sp::spDists(\n      x = as.matrix(.[, c(\"longitude\", \"latitude\")]),\n      longlat = TRUE,\n      segments = TRUE\n    )),\n    elevation_to_prev = elevation - lag(elevation),\n    distance = cumsum(dist_to_prev)\n    )) \n\n# A tibble: 611 × 11\n   timestamp           latitude longitude elevation heart_rate cadence\n   <dttm>                 <dbl>     <dbl>     <dbl>      <int>   <int>\n 1 2017-03-16 17:22:08     55.0     -1.62      88.8        137      79\n 2 2017-03-16 17:22:09     55.0     -1.62      90.2        138      79\n 3 2017-03-16 17:22:10     55.0     -1.62      81.2        138      80\n 4 2017-03-16 17:22:15     55.0     -1.62      39.2        139      78\n 5 2017-03-16 17:22:21     55.0     -1.62      54.2        140      79\n 6 2017-03-16 17:22:26     55.0     -1.62      54.6        140      80\n 7 2017-03-16 17:22:32     55.0     -1.62      65.4        138      79\n 8 2017-03-16 17:22:33     55.0     -1.62      69          138      79\n 9 2017-03-16 17:22:37     55.0     -1.62      98.8        135      79\n10 2017-03-16 17:22:44     55.0     -1.62      97          135      80\n# … with 601 more rows, and 5 more variables: time_diff_to_prev <dbl>,\n#   cumtime <dbl>, dist_to_prev <dbl>, elevation_to_prev <dbl>, distance <dbl>"
  },
  {
    "objectID": "posts/2019-11-04-parsing-strava/index.html#summarising",
    "href": "posts/2019-11-04-parsing-strava/index.html#summarising",
    "title": "Analysing .fit files in R",
    "section": "Summarising",
    "text": "Summarising\nWe can calculate a high level summary of the activity similar to what you would find on Garmin connect.\n\nactivity_tibble %>%\n  summarise(\n    total_distance = sum(dist_to_prev),\n    elapsed_time = max(timestamp) - min(timestamp),\n    moving_time = sum(time_diff_to_prev) - sum(\n      ifelse(dist_to_prev == 0, time_diff_to_prev, 0)\n    ),\n    elevation_gain = sum(if_else(elevation_to_prev > 0, elevation_to_prev, 0), na.rm = TRUE),\n    average_heart_rate = round(mean(heart_rate), 0)\n  ) %>%\n  mutate(average_pace = hms::as_hms(as.numeric(moving_time) / total_distance),\n         moving_time = lubridate::seconds_to_period(moving_time)) %>% \n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\ntotal_distance\nelapsed_time\nmoving_time\nelevation_gain\naverage_heart_rate\naverage_pace\n\n\n\n\n8.044634\n39.65 mins\n39M 39S\n380\n150\n00:04:55.72509\n\n\n\n\n\nWe can recreate plots commonly found on activity websites such as training peaks, Strava and Garmin Connect, for instance average speed for each 1km:\n\nactivity_tibble %>% \n  mutate(lap = distance %/% 1) %>% \n  group_by(lap) %>% \n  summarise(lap_distance = sum(dist_to_prev), \n            lap_time = sum(time_diff_to_prev), \n            pace = hms::as_hms(lap_time / lap_distance)) %>% \n  ggplot(aes(x = lap, y = pace)) +\n  geom_col() +\n  xlab(\"Distance (km)\") +\n  ylab(\"Pace (min / km)\") +\n  labs(title = \"Average pace per lap\")\n\n\n\n\n\nactivity_tibble %>% \n  mutate(distance = cumsum(dist_to_prev)) %>% \n  ggplot(aes(x = distance, y = elevation)) +\n  geom_area(alpha = 0.5) +\n  geom_line(aes(x = distance, y = heart_rate), colour = \"#ff0000\", alpha = 0.5) +\n  xlab(\"Distance (km)\") +\n  ylab(\"Elevation (m)\") +\n  labs(title = \"Elevation and heart rate\")"
  },
  {
    "objectID": "posts/2019-11-04-parsing-strava/index.html#analysing-heart-rate-data",
    "href": "posts/2019-11-04-parsing-strava/index.html#analysing-heart-rate-data",
    "title": "Analysing .fit files in R",
    "section": "Analysing heart rate data",
    "text": "Analysing heart rate data\nWe can determine how hard the activity was for the athlete using heart rate data. Heart rate is an individual metric and differs between athletes running the same pace. To that end, we must compute the heart rate relative to the maximum heart rate or using heart rate reserve (taking into account both the maximum and resting heart rate). Using the max heart rate and resting heart rate, training zones can be determined. These zones are broad and for the convenience of the athlete (and coach) when performing workouts at a given intensity. This intensity should vary depending on the purpose of the workout (recovery, threshold, VO2 max intervals etc.).\nSuggested heart rate zones according to Pete Pfitzinger are:\n\nActive recovery: less than 76% MHR\nGeneral Aerobic: 70%-81% MHR\nTempo (Marathon pace): 81%-88% MHR\nLactate Threshold: 82%-92% MHR\nAnaerobic: 95%+\n\nFor my maximum heart rate of 189, the zones can be written as.\n\nzones <- c(\n  \"one\" = 0.76 * 189,\n  \"two\" = 0.81 * 189,\n  \"three\" = 0.88 * 189,\n  \"four\" = 0.92 * 189,\n  \"five\" = 189)\n\n\nknitr::kable(tibble::rownames_to_column(data.frame(heart_rate = round(zones, 0)), var = \"zone\"))\n\n\n\n\nzone\nheart_rate\n\n\n\n\none\n144\n\n\ntwo\n153\n\n\nthree\n166\n\n\nfour\n174\n\n\nfive\n189\n\n\n\n\n\nThen the time in zones can be plotted for the given activity.\n\ntime_in_zones <- activity_tibble %>%\n  mutate(\n    zone = dplyr::case_when(\n      heart_rate <= zones[1] ~ names(zones[1]),\n      heart_rate <= zones[2] ~ names(zones[2]),\n      heart_rate <= zones[3] ~ names(zones[3]),\n      heart_rate <= zones[4] ~ names(zones[4]),\n      heart_rate <= zones[5] ~ names(zones[5]),\n    )\n  ) %>%\n  mutate(zone = factor(zone, levels = c(\"one\", \"two\", \"three\", \"four\", \"five\"))) %>%\n  group_by(zone) %>%\n  summarise(time_seconds = sum(time_diff_to_prev))\n\ntime_in_zones %>% \n  ggplot(aes(x = zone, y = time_seconds, fill = zone)) +\n  geom_col() +\n  scale_fill_brewer(type = \"seq\",\n                             direction = 1,\n                             palette = \"Reds\") +\n  scale_x_discrete(drop = FALSE) +\n  theme(legend.position = \"none\") +\n  theme_minimal() +\n  coord_flip() +\n  scale_y_time() +\n  geom_label(aes(label = hms::as_hms(time_seconds))) +\n  theme(\n    axis.title.x = element_blank(),\n    legend.position = \"none\",\n    axis.ticks.x = element_blank(),\n    axis.text.x = element_blank()\n  ) +\n  labs(title = \"Time in zones\")"
  },
  {
    "objectID": "posts/2019-11-04-parsing-strava/index.html#training-impulse",
    "href": "posts/2019-11-04-parsing-strava/index.html#training-impulse",
    "title": "Analysing .fit files in R",
    "section": "Training impulse",
    "text": "Training impulse\nTRIMP can be used (TRaining IMPulse) to calculate a one-number summary of the activity difficulty, more information on TRIMP can be found here.\nThe most straightforward way to calculate TRIMP is calculating the total time in each zone by multiplying the zone number by the total minutes in the corresponding zone.\n\ntime_in_zones %>% \n  summarise(trimp_zone = sum(as.numeric(zone) * time_seconds / 60)) %>% \n  knitr::kable()\n\n\n\n\ntrimp_zone\n\n\n\n\n87.86667\n\n\n\n\n\nThis number is straightforward to calculate however it lacks nuance. For instance it remains the same if the athlete is at either the upper or lower end of the heart rate range for a given zone. To account for this TRIMP exp can be calculated:\n\\[\\textrm{TRIMP}^{\\textrm{exp}} = \\sum_{i=1}^T \\textrm{D}_i \\cdot \\textrm{HRr} \\cdot 0.64e^y\\]\nWhere, \\(\\textrm{D}_i\\) is the duration of a single measurement (typically one to five seconds on a Garmin watch), HRr is the heart rate reserve (maximum heart rate - resting heart rate), \\(y\\) is the percentage of heart rate reserve multiplied by 1.92 for men and 1.67 for women.\n\ntrimp_exp <- function(heartrate, time_seconds, max_hr, resting_hr, sex = \"Male\") {\n  heart_rate_reserve <- max_hr - resting_hr\n  hrr <- heartrate / heart_rate_reserve\n  constant <- if_else(sex == \"Male\", 1.92, 1.67)\n  sum((time_seconds / 60) * hrr * 0.64 * exp(constant * hrr))\n}\n\n\nactivity_tibble %>% \n  summarise(trimp_exp = trimp_exp(heart_rate, time_diff_to_prev, 189, 42)) %>% \n  knitr::kable()\n\n\n\n\ntrimp_exp\n\n\n\n\n187.6727\n\n\n\n\n\nThese summaries can be used to calculate the overall training workload for an athlete to assist with planning and reviewing training plans. This is typically used in addition to training time and distance covered."
  },
  {
    "objectID": "posts/2020-04-19-multi-state-survival-models/index.html",
    "href": "posts/2020-04-19-multi-state-survival-models/index.html",
    "title": "Multi State Models",
    "section": "",
    "text": "Multi-state models are used to model disease progression. The model is a continuous time Markov process. The states and time of transitions are fully observed. There are three states a patient can be in, “healthy”, “illness” and “deceased”. The possible pairs of transitions between these states include healthy -> illness, illness -> healthy, illness -> death and healthy -> death. The model can be expressed as a directed graph.\nThe state “Deceased” is an absorbing state, whereas the other two states are transient. This means we can’t transition away from the Deceased state.\nThe process is a Markov process, it has a transition kernel, \\(p(x_{i,t_j}|x_{i,t_{j-1}}, \\theta)\\) which depends only on the previous state and some static parameters \\(\\theta\\). The state for the \\(i^{\\text{th}}\\) patient at time \\(t_j\\) is written \\(x_{i,t_j}\\). The parameters for the transition kernel populate the transition rate matrix. The rate matrix is the derivative of the transition kernel at \\(t=0\\)\n\\[\\begin{aligned}\nQ &= \\frac{d}{dt}P(t)\\Bigr|_{\\substack{t=0}} \\\\\n&= \\lim_{\\delta t \\rightarrow 0}\\frac{P(\\delta t) - P(0)}{\\delta t} \\\\\n&= \\lim_{\\delta t \\rightarrow 0}\\frac{P(\\delta t) - I}{\\delta t}\n\\end{aligned}\\]\nThen we can rearrange for the transition kernel,\n\\[P(\\delta t) = I + Q \\delta t.\\]\nThis gives the infinitesimal transition for a very small time increment. Using this result, we can solve for the transition kernel over a finite time\n\\[\\begin{aligned}\n\\frac{d}{dt}P(t) &= \\frac{P(t + dt) - P(t)}{dt} \\\\\n&= \\frac{P(dt)P(t) - P(t)}{dt}\\\\\n&= \\frac{(P(dt) - I)}{dt}P(t)\\\\\n&= QP(t).\n\\end{aligned}\\]\nThen solve the resulting differential equation to see that \\(P(t) = \\exp(Qt)\\), hence the transition matrix is the matrix exponential of the transition rate matrix. The transition rate matrix for this problem can be written as\n$$\nThe non-zero elements of the rate-matrix are potential transitions. The final state is absorbing - hence we can’t transition from it."
  },
  {
    "objectID": "posts/2020-04-19-multi-state-survival-models/index.html#simulating-data-from-the-model",
    "href": "posts/2020-04-19-multi-state-survival-models/index.html#simulating-data-from-the-model",
    "title": "Multi State Models",
    "section": "Simulating Data from the Model",
    "text": "Simulating Data from the Model\nWe can simulate forward using a grid of times, \\(t_i = t_0, \\dots, t_n\\) where \\(t_i - t_{i-1} = \\Delta t\\) is a small time increment, using the exact solution for the transition rate matrix \\(P(\\Delta t) = \\exp(Q \\Delta t)\\).\n\nSample the rate parameters from the prior distribution\nConstruct a rate matrix from each sample\nCompute the matrix exponential and simulate forward conditional on the previous step\n\nForward simulation is drawing next state, \\(x_t\\) from a categorical distribution with probabilities from the row of the transition matrix corresponding to the state at time \\(t-1\\), \\(P(\\Delta t)_{x_{t-1}\\cdot}\\).\nWe use Gamma priors for the non-zero elements of the rate matrix:\n\\[\\begin{aligned}\nq_{12} &\\sim \\textrm{Gamma}(3, 3/0.05)\\\\\nq_{13} &\\sim \\textrm{Gamma}(3, 3/0.001)\\\\\nq_{21} &\\sim \\textrm{Gamma}(3, 3/0.02)\\\\\nq_{23} &\\sim \\textrm{Gamma}(3, 3/0.01)\n\\end{aligned}\\].\n\n\n\n\n\n\n\n\nThe following function populates a rate matrix given a vector of hazards.\n\nbuild_rate_matrix <- function(lambda, n_states = 3, n_absorbing = 1) {\n  q <- matrix(rep(0, times = n_states * n_states), byrow = TRUE, nrow = n_states)\n  k <- 1\n  for (i in 1:n_states) {\n    for (j in 1:n_states) {\n      if (i != j & i <= (n_states - n_absorbing)) {\n        q[i, j] = lambda[k]\n        k = k + 1\n      }\n    }\n  }\n  \n  ## fix the diagonal to be negative the sum of the remaining elements in the row\n  diag(q) = -rowSums(q)\n  q\n}\n\nThe next function can be used to simulate the process on a grid of times \\(t_1, \\dots, t_n\\). The step-size between each realisation must be small enough to see any transitions.\n\n# Simulate the markov chain\nsim_markov <- function(lambdas, step_size, n_steps) {\n  state <- numeric(n_steps)\n  \n  ## Build the rate and transition matrices\n  rate_matrix <- build_rate_matrix(lambdas)\n  transition_matrix <- Matrix::expm(rate_matrix * step_size)\n  n_states <- nrow(rate_matrix)\n  \n  # initial state is always healthy\n  state[1] <- 1\n\n  for (i in 2:n_steps) {\n    state[i] <- sample(x = n_states, size = 1, prob = transition_matrix[state[i-1], ])\n  }\n  tibble(time = seq_len(n_steps), state = state)\n}\n\n\n\n\nSimulating 1,000 trajectories for (50 * 0.1 = 5 days) transitions results in the following state transitions\n\n\n# A tibble: 3 × 4\n   from   `1`   `2`   `3`\n  <dbl> <int> <int> <int>\n1     1 43000   227     1\n2     2    11  5700     2\n3     3     0     0    59\n\n\nInstead of simulating on a fine grid we can using discrete event simulation:\n\nGiven the initial state is \\(i\\)\nSimulate the time to the next event, \\(t \\sim \\text{Exp}(-q_{ii})\\)\nSimulate the next state by simulating from a distribution with pmf \\(q_{ij} / q_{ii}, i \\neq j\\)\nReturn the sample path if we have landed in an absorbing state, \\(q_{ii} = 0\\)\n\n\nsim_exact <- function(x, Q, n) {\n  xs = numeric(n + 1)\n  ts = numeric(n)\n  r = nrow(Q)\n  t = 0\n  ts[1] <- t\n  xs[1] = x\n  for (i in seq_len(n)) {\n    t <- t + rexp(1, -Q[x, x]) # Sim time to next observation\n    weights <- Q[x, ] # Calculate the probability of transitioning away to another state\n    weights[x] <- 0 # We can't stay in the same state\n    x <- sample(r, 1, prob = weights) # Sample the next state\n    xs[i + 1] <- x # add to vector of states\n    ts[i + 1] <- t # add to vector of event times\n    if (Q[x, x] == 0) { # If the new state is an absorbing state then return event times\n      return(tibble(time = ts[seq_len(i + 1)], state = xs[seq_len(i + 1)]))\n    }\n  }\n  tibble(time = ts, state = xs) # Return event times without absorbing\n}\n\n\n\n        1    2   3\n[1,]    0 3019  80\n[2,] 2150    0 869\n\n\nThe figure below shows the mean time in each state with 66% and 95% credible intervals. This is calculated by sampling 1,000 rate matrices from the prior distribution and calculating \\(1 / q_i = \\sum_{j\\neq i}q_{ij}\\) using each sample.\n\n\n\n\n\n\nSimulating a real-world example\nIn a real world example patients are observed at a different number of times, \\(n_i\\) represents the number of state observations for patient \\(i\\). To simulate realistic data we will randomise the number of steps recorded for each “patient” using the exact algorithm. Let’s sample the number of steps uniformly between 1 and 5.\n\n\n\nThe plot below shows patient journeys for patients 3, 11, 13 and 100. Patient 3 has only two observed state changes and censoring on the final state. Patient 11 has multiple observed transitions through illness and healthy, then a final transition to the absorbing state.\n\n\n\n\n\nWe can write down the likelihood for the \\(i^{\\text{th}}\\) patient with state transitions at times, \\(t_{ij}, j = 0,\\dots,n_i\\)\n$$\n\\[\\begin{aligned}\n\n\np(X_{i,t_{0:n_i}}|Q) &= p(x_{i,0})\\prod_{j=1}^{n_i}p(x_{i,t_j}|x_{i,t_{j-1}}, Q) \\\\\n&= \\prod_{j=1}^{n_i}\\exp(Q(t_{ij} - t_{ij-1}))_{x_{i,t_j},x_{i,t_{j-1}}}\n\\end{aligned}\\]\n$$\nThe initial state is fixed at one and the transition kernel is given by the matrix exponential of the rate matrix. There is one problem with this likelihood: It does not incorporate censored paths.\nA multi-state model such as this can be thought of as multiple survival models. I introduced Survival models in a previous blog post. In a survival model, the transition is governed by a hazard function. The hazard function for transitioning to state \\(j\\) from state \\(i\\) is\n\\[H_{ij}(t_1, t_2) = \\int_{u=t_1}^{t_2} q_{ij}\\, du = (t_2-t_1)q_{ij}.\\]\nThe Survival function, \\(Pr(T > t)\\) is:\n\\[S_{ij}(t) = \\exp(-H_{ij}(0, t)) = \\exp(-tq_{ij})\\]\nThe pdf is \\(f_{ij}(t) = \\frac{d}{dt}F_{ij}(t)\\) where \\(F_{ij}(t) = 1 - S_{ij}(t)\\), hence \\(f_{ij} = q_{ij}\\exp(-tq_{ij})\\).\nLet’s consider the likelihood for patient 13.\n\n\n\n\n\npatient\ntime\nstate\n\n\n\n\n13\n0.00\n1\n\n\n13\n3.93\n2\n\n\n13\n8.20\n1\n\n\n\n\n\nFor each state transition all other possible transitions are considered censored. The data-frame for patient 13 can be re-written by first considering a data-frame of all possible transitions and determining which transitions end in an absorbing state.\n\n\n\nWe can then create a “from” column representing the previous state of a transition, then left join the possible states using “from”. Observed states are when the “to” in both tables match, censored states are non-matching.\n\n\n\n\n\npatient\ntime\nto.x\nfrom\nto.y\nabsorbing\nobserved\n\n\n\n\n13\n0.00\n1\nNA\nNA\nNA\nNA\n\n\n13\n3.93\n2\n1\n2\nFALSE\nTRUE\n\n\n13\n3.93\n2\n1\n3\nTRUE\nFALSE\n\n\n13\n8.20\n1\n2\n1\nFALSE\nTRUE\n\n\n13\n8.20\n1\n2\n3\nTRUE\nFALSE\n\n\n\n\n\nThis layout explicitly allows us to see which state transitions are observed and which are censored. Patient 13 starts in state 1, as do all patients. The first observation at time \\(t = 3.92\\) is a transition from \\(1 \\rightarrow 2\\), illness - this observation implies a censored observation for the transition \\(1 \\rightarrow 3\\). Then we transition from state 2 back to state 1 and never observe the terminal state.\n\\[\\begin{aligned}\np(X_{i=13,t_{0:3}}|Q) &= Pr(X_{t_1} = 2|X_{t_0} = 1)Pr(X_{t>t_1} = 3)Pr(X_{t_2} = 1|X_{t_1} = 2)Pr(X_{t>t_2} = 3) \\\\\n&=f_{12}(t_1-t_0)S_{13}(t_1-t_0)f_{21}(t_2-t_1)S_{23}(t_2-t_1) \\\\\n&=q_{12}\\exp(-q_{12}(t_1-t_0))\\exp(-(t_1-t_0)q_{13})q_{21}\\exp(-q_{21}(t_2-t_1))\\exp(-(t_2-t_1)q_{23}) \\\\\n&= q_{12}q_{21}\\exp(-q_{12}(t_1-t_0) -(t_1-t_0)q_{13} -q_{21}(t_2-t_1) -(t_2-t_1)q_{23}) \\\\\n&= q_{12}q_{21}\\exp(-(q_{12} + q_{13})(t_1-t_0) - (q_{21} + q_{23})(t_2-t_1))\n\\end{aligned}\\]\nThe final line shows that the likelihood consists of the hazards of the observed transitions \\(1 \\rightarrow 2\\) and \\(2 \\rightarrow 1\\), multiplied by the exponential of the sum of the off-diagonal elements of the rate matrix multiplied by the total time those states have been observed.\nThis can be generalised:\n\\[p(X_{i,t_{0:3}}|Q) = \\prod_{j=1}^3\\prod_{k=1,k\\neq j}^3q_{jk}^{n_{ijk}}\\exp(-\\tau_{ij}q_j)\\]\nWhere \\(q_j = \\sum_{j=1,j\\neq k}^3q_{jk}\\), \\(\\tau_{ij}\\) is the time in the \\(j^{\\text{th}}\\) state for patient \\(i\\) and \\(n_{ijk}\\) is a matrix with a count of the number of transitions from state \\(j\\) to state \\(k\\). We can then calculate the likelihood for all patients:\n\\[\\begin{aligned}\np(\\textbf{X}_t|Q) &= \\prod_{i=1}^N\\prod_{j=1}^3\\prod_{k=1,k\\neq j}^3q_{jk}^{n_{ijk}}\\exp(-\\tau_{ij}q_j)\\\\\n&= \\prod_{j=1}^3\\prod_{k=1,k\\neq j}^3q_{jk}^{n_{1jk} + \\dots + n_{Njk}}\\exp(-\\sum_{i=1}^N\\tau_{ij}q_j)\\\\\n&= \\prod_{j=1}^3\\prod_{k=1,k\\neq j}^3q_{jk}^{n_{jk}}\\exp(-\\tau_{j}q_j)\\\\\n\\end{aligned}\\]\nWhere, \\(n_{jk}\\) is the sum of all \\(N\\) matrices representing the transitions \\(j \\rightarrow k\\) and \\(\\tau_j\\) is the total time spent in state \\(j\\) for all patients.\nFor reasons of numerical stability, the log-likelihood is used,\n$$\n\\[\\begin{aligned}\n\n\n\\log p(\\textbf{X}_t|Q) &= \\sum_{j=1}^3\\sum_{k=1,k\\neq j}^3\\left(n_{jk}\\log(q_{jk})-\\tau_jq_j\\right).\n\\end{aligned}\\]\n$$"
  },
  {
    "objectID": "posts/2020-04-19-multi-state-survival-models/index.html#parameter-inference",
    "href": "posts/2020-04-19-multi-state-survival-models/index.html#parameter-inference",
    "title": "Multi State Models",
    "section": "Parameter Inference",
    "text": "Parameter Inference\nThe posterior distribution of the free parameters in the rate matrix is determined using a random walk Metropolis algorithm. The prior distribution for the rate parameters are independent Gamma distributions parameterised with shape, \\(\\alpha\\) and rate, \\(\\beta\\) such that the mean is \\(\\alpha/\\beta\\)\n\\[\\lambda_i \\sim \\text{Gamma}\\left(3, \\frac{3}{0.01}\\right), \\quad i = 1,\\dots,12.\\]\nThe rate parameters are transformed to the log scale and the proposal distribution is a symmetric Normal distribution centered at the value of the previously accepted parameter at iteration \\(k-1\\)\n\\[\\log\\lambda_k \\sim \\text{MVN}(\\log\\lambda_{k-1}, I_{4}\\delta), \\quad \\delta = 0.01.\\]\nwhere \\(\\delta\\) is a tuning parameter of the MCMC and \\(I_{4}\\) represents the 4 dimensional identity matrix.\nCalculate the total-time in each state.\n\n\n\n\n\nstate\ntotal_time\n\n\n\n\n1\n2284.0808\n\n\n2\n189.7724\n\n\n3\n0.0000\n\n\n\n\n\nCalculate the matrix of observed transitions. Note that no transitions occur from state 3, the absorbing state.\n\n\n      1   2  3\n[1,]  0 107 21\n[2,] 38   0 43\n[3,]  0   0  0\n\n\nProgram the log-likelihood, prior and proposal distribution.\n\n## rate_matrix is the constructed rate-matrix\n## tau is a vector containing total time in each state\n## observed_transitions is a matrix with all observed transitions\n## with the state from in the rows and state to in the columns.\nlog_likelihood <- function(rate_matrix, tau, observed_transitions) {\n  n_states <- nrow(rate_matrix)\n  qi <- - diag(rate_matrix)\n  sum(log(rate_matrix - diag(diag(rate_matrix))) * observed_transitions, na.rm = TRUE) - (n_states - 1) * sum(qi * tau)\n}\n\nlog_prior <- function(lambda) {\n  sum(dgamma(lambda, shape = 3, scale = 3 / 0.1, log = TRUE))\n}\n\nproposal <- function(lambda) {\n  lambda * exp(rnorm(4, sd = 0.01))\n}\n\nlog_posterior <- function(lambda) {\n    Q <- build_rate_matrix(lambda)\n    log_likelihood(Q, tau, observed_transitions) + log_prior(lambda)\n  }\n\nWe are ready to sample from the posterior distribution of the rate parameters using the Metropolis algorithm. We run four chains in parallel using furrr as explained in my previous post on efficient MCMC in R.\n\niters <- jonnylaw::metropolis(\n  lambda,\n  log_posterior,\n  proposal,\n  m = 1e5, \n  chains = 4, \n  parallel = TRUE\n)\n\nThe posterior diagnostics are plotted below.\n\n\n\n\n\nThe plot below shows posterior distribution of the mean time in each state, \\(1 / q_i\\). The blue points are the actual observed values of each patient.\n\n\n\n\n\nMost applications of multi-state survival models have patient attributes associated with each patient. This can be used to inform the next transition and the time to the next transition. I will consider this in a future post.\nIn addition, fully observed processes are rare. If the exact time of a state transition is not known or multiple state transitions can happen between observations then the multi-state survival model is partially observed. A continuous time Hidden Markov Model can be used in this case."
  },
  {
    "objectID": "posts/2019-02-11-metropolis_r/index.html",
    "href": "posts/2019-02-11-metropolis_r/index.html",
    "title": "Efficient Markov chain Monte Carlo in R with Rcpp",
    "section": "",
    "text": "Metropolis-Hastings algorithm\nA Metropolis-Hastings algorithm can be used to determine the posterior distribution of the parameters, \\(theta = \\{\\mu, \\Sigma\\}\\). The Metropolis algorithm constructs a Markov chain whose stationary distribution corresponds to the target posterior distribution, \\(p(\\theta|y)\\). In order to construct the Markov chain with this property, a carefully chosen tansition function \\(P(\\theta^\\prime|\\theta)\\) is used. In order to prove the Metropolis algorithm has the target distribution as its stationary distribution, the existence and uniqueness of the stationary distribution must be determined. A transition function which satisfies detailed balance is chosen which is a sufficient condition for the existence of the stationary distribution:\n\\[P(\\theta^\\prime|\\theta)p(\\theta|y) = P(\\theta|\\theta^\\prime)p(\\theta^\\prime|y)\\]\nThe Markov chain proceeds by proposing a new value of the parameters, \\(\\theta^\\prime\\) from a distribution which can be easily simulated from (typically a Normal distribution centred at the previously accepted value of the parameter, \\(\\theta\\)), \\(q(\\theta^\\prime|\\theta)\\). The transition function is the product of the proposal distribution and the acceptance ratio. The acceptance ration which satisfies detailed balance is called the Metropolis choice:\n\\[A = \\operatorname{min}\\left(1, \\frac{p(\\theta^\\prime|y)q(\\theta|\\theta^\\prime)}{p(\\theta|y)q(\\theta^\\prime|\\theta)}\\right).\\]\n\n\nR Implementation\nFirst of a single step of the Metropolis algorithm is implementated. This is a higher order function, since two of the arguments are functions themselves. The function log_posterior is a function from parameters to log-likelihood and the proposal is a symmetric proposal distribution for the parameters, a function from parameters to parameters. The final argument, theta represents the parameters.\n\nmetropolis_step <- function(theta, log_posterior, proposal) {\n  propTheta <- proposal(theta)\n  a <- log_posterior(propTheta) - log_posterior(theta)\n  u <- runif(1)\n  if (log(u) < a) {\n    propTheta\n  } else {\n    theta\n  }\n}\n\nNext the step function can be used in a for loop to generate m samples, each dependent on the previous step. An matrix containing \\(m\\) rows is initialised to contain each iteration of the Metropolis algorithm.\n\nmetropolis <- function(theta, log_posterior, proposal, m) {\n  out = matrix(NA_real_, nrow = m, ncol = length(theta))\n  out[1, ] = theta\n  for (i in 2:m) {\n    out[i, ] <- metropolis_step(out[i-1, ], log_posterior, proposal)\n  }\n  out\n}\n\nThe strictly positive variance parameters are proposed on the log-scale:\n\nproposal <- function(x) {\n  z = rnorm(4, sd = 0.05)\n  c(x[1] + z[1], x[2] * exp(z[2]),\n    x[3] + z[3], x[4] * exp(z[4]))\n}\n\nFinally, all the components are there to sample from the posterior distribution of the parameters. The mean of the sampled posterior distribution should coincide with the parameters used to simulate the data. In the figure below the actual values used to simulate the data are plotted with dashed lines.\n\nout = metropolis(theta, log_posterior(xs), proposal, 10000)\n\n\n\n\n\n\n\n\nParallel Chains in R\nTypically, multiple chains are run in parallel, a straightforward way to do this in R is to use a parallel map from the furrr package. First we create a new function which alters the metropolis function to return a dataframe:\n\nmetropolis_df <- function(theta, log_posterior, proposal, m, parameter_names) {\n  function(x) {\n    mat <- metropolis(theta, log_posterior, proposal, m)\n    colnames(mat) <- parameter_names\n    as.data.frame(mat)\n  }\n}\n\nThen future_map_dfr is used which performs the function .f for each element of .x. It then rowbinds into a dataframe. This is explicit in the function name, the suffix _dfr meaning a dataframe is the return type and is created by rowbinding the results. The id of each function run is provided by the .id column and takes on the values of .x.\n\nplan(multiprocess)\nmh_samples <- future_map_dfr(\n  .x = 1:2,\n  .f = metropolis_df(theta, log_posterior(xs), proposal, 10000, actual_values$parameter),\n  .id = \"chain\"\n)\n\nThe figure below shows the trace plots and marginal densities from 10,000 draws of the parallel Metropolis hastings algorithm.\n\n\n\n\n\n\n\nRcpp implementation\nR has a straightforward interface to C++, the Metropolis-Hastings algorithm can be re-implemented using C++. C++ is a statically typed imperative language, hopefully the effort of reimplementing in C++ will result in a significant speed-up. The log_posterior and proposal functions are run many times to calculate the Markov chain. Let’s first implement these two functions using C++:\n\n#include <Rcpp.h>\nusing namespace Rcpp;\n// [[Rcpp::plugins(cpp11)]]\n\n// [[Rcpp::export]]\ndouble logDensity(NumericMatrix ys, NumericVector p) {\n  double ll = 0;\n  int n = ys.nrow();\n  for (int i = 0; i < n; i++) {\n    ll += R::dnorm(ys(i, 0), p(0), p(1), true) + R::dnorm(ys(i, 1), p(2), p(3), true);\n  }\n  return ll;\n}\n\n// [[Rcpp::export]]\nNumericVector proposalCpp(NumericVector p, double delta) {\n  int d = p.size();\n  NumericVector z(d);\n  NumericVector propP(d);\n  for (int i = 0; i < d; i++) {\n    propP(i) = p(i);\n    z(i) = R::rnorm(0, delta);\n  }\n  propP(0) += z(0);\n  propP(1) *= exp(z(1));\n  propP(2) += z(2);\n  propP(3) *= exp(z(3));\n  return propP;\n}\n\nThese functions can then be used in the Metropolis algorithm written using R, as we can see from the below code chunk the C++ function appears as if it was an R function.\n\nout_cpp <- metropolis(theta, function(p) logDensity(xs, p), function(p) proposalCpp(p, 0.05), 10000)\n\n\n\n\n\n\n\n\nPerformance Improvements\nBut what about the performance, the relative speedup can be calculated using the bench package. The plot below shows the absolute timings of the R implementation and the Rcpp implementation.\n\ntimings <-\n  bench::mark(\n    R = metropolis(theta, log_posterior(xs), proposal, 100),\n    Rcpp = metropolis(theta, function(p)\n      logDensity(xs, p),\n      function(p)\n        proposalCpp(p, 0.05), 100),\n    iterations = 500,\n    check = FALSE\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{law2019,\n  author = {Jonny Law},\n  title = {Efficient {Markov} Chain {Monte} {Carlo} in {R} with {Rcpp}},\n  date = {2019-02-11},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJonny Law. 2019. “Efficient Markov Chain Monte Carlo in R with\nRcpp.” February 11, 2019."
  },
  {
    "objectID": "posts/2020-04-08-tidy-tuesday-tour-de-france/index.html",
    "href": "posts/2020-04-08-tidy-tuesday-tour-de-france/index.html",
    "title": "Tidy Tuesday: Tour de France",
    "section": "",
    "text": "Code\nlibrary(tidyr) \n\n\nWarning: package 'tidyr' was built under R version 4.1.2\n\n\nCode\nlibrary(dplyr)\n\n\nWarning: package 'dplyr' was built under R version 4.1.2\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(readr)\n\n\nWarning: package 'readr' was built under R version 4.1.2\n\n\nCode\nlibrary(ggplot2)\nlibrary(leaflet)\n\n\nWarning: package 'leaflet' was built under R version 4.1.2\n\n\nCode\nlibrary(stringr)\ntheme_set(theme_minimal())\nThe Tour de France is the biggest annual sporting event in the world featuring 21 days of bicycle racing and two rest days around France (sometimes starting other countries, including Yorkshire in 2014). There have been 106 editions up to the 2019 race with the first event held 116 years ago in July 1903. During that time the race has evolved. Initially the races were entirely self-supported, meaning you had to carry your own spare tyres and fix any mechanical issues. Additionally, many of the mountain passes had gravel roads instead of the pristine tarmac of modern day. In the 1913 race, Eugène Christophe was hit by a race vehicle on his descent from the Tourmalet, a 2,115m mountain pass in the French Pyrenees. This caused Christophe’s front fork to break which he would be forced to repair himself. He walked 10km to the nearest village and used a forge to render a new fork and thus repair his bicycle. However, Christophe paid a boy to operate the bellows on the forge meaning he received a ten minute penalty! The image below is Christophe during the 1913 tour, credit Bike Race Info.\nThe modern Tour de France is not so tough, now team cars and neutral service vehicles follow the riders throughout the stage to change wheels, fix mechanicals and hand out food and drinks. Additionally, riders work in teams. Before 1987 the team size was 10 riders and a total of 22 teams for 220 riders. The UCI reduced the team size for grand tours to nine in 1987 and kept that size until 2017. The team size in the grand tours (Tour de France, Vuelta a España and Giro d’Italia) was reduced to eight beginning with the 2018 season. It was thought by some, that teams (particularly Team Sky, now Team Ineos) were dominating the narrative of the race by riding hard on the front, thus neutralising attacks. From cycling news “The Grand Tour organisers have been pushing for a reduction in team sizes in order to open up the races and prevent one team from controlling the race.”\nThe Tour de France has several competitions running simultaneously. There is one race for the overall title which is called the general classification and is awarded to the rider who completes the full course with the lowest cumulative time. The rider in the lead of the general classification (GC) at the end of the previous days racing is awarded the yellow jersey (introduced in the 1919 edition of the Tour). Each stage is a race in its own right, with stages on offer for different kinds of riders. Flat stages allow recovery for the GC riders and are typically won by sprinters from bunch sprints. Time trial stages can often be won by time trial specialists providing they come early enough in the program (such as a prologue stage before stage 1) such that they are not too tired to perform. The moutain stages of the Pyrenees and Alps are the testing grounds of the GC riders.\nThere are two other jerseys, the green jersey awarded to the rider who has the most accumulated the most points from stage wins and intermediate sprints. This can reward riders for trying to break away from the pelaton and work hard in a small group battling the wind. The polka-dot jersey is awarded to the best climber, with points being awarded for the first few over key climbs in the race. The final jersey is the white jersey for best young rider, awarded to the rider with the lowest cumulative time under the age of 26. Other prizes include the team classification, which awards a yellow number to the leading team calculated by adding the times of the three best riders of each team per stage. The image below shows the 2018 Tour de France Jersey winners, Pierre Latour in White, Geraint Thomas in Yellow, Julian Alaphilippe in Polka-dot and Peter Sagan in Green."
  },
  {
    "objectID": "posts/2020-04-08-tidy-tuesday-tour-de-france/index.html#cumulative-wins-by-nationality",
    "href": "posts/2020-04-08-tidy-tuesday-tour-de-france/index.html#cumulative-wins-by-nationality",
    "title": "Tidy Tuesday: Tour de France",
    "section": "Cumulative wins by nationality",
    "text": "Cumulative wins by nationality\nThis weeks data consists of TdF winners, stage results and information about each stage. First we will look at the TdF overall winners by nationality.\n\n\nCode\nwinners <- tuesdata$tdf_winners\n\nwinners %>% \n  select(start_date, edition, nationality) %>% \n  mutate(year = lubridate::year(start_date), true = TRUE) %>% \n  mutate(nationality = stringr::str_trim(nationality)) %>% \n  pivot_wider(names_from = nationality, values_from = true) %>% \n  mutate_at(vars(France:Colombia), ~ if_else(is.na(.x), FALSE, .x)) %>% \n  mutate_at(vars(France:Colombia), cumsum) %>% \n  pivot_longer(names_to = \"country\", values_to = \"cumulative_wins\", France:Colombia) %>% \n  ggplot(aes(x = start_date, y = cumulative_wins, group = country, colour = country)) +\n  geom_line() +\n  gghighlight::gghighlight(country %in% c(\"France\", \"Belgium\", \"Great Britain\")) +\n  labs(x = \"Edition\", y = \"Wins\", title = \"Tour de France wins by Country\")\n\n\nWarning: Tried to calculate with group_by(), but the calculation failed.\nFalling back to ungrouped filter operation...\n\n\nWarning: Using `across()` in `filter()` is deprecated, use `if_any()` or\n`if_all()`.\n\n\nlabel_key: country\n\n\n\n\n\nFrance have won the most Tours, unsurprisingly. However France haven’t had a winner since Bernard Hinault in 1985, 35 years ago! On the other hand Britain didn’t have a winner until Bradley Wiggins in 2012 and have since won the yellow jersey a further five times with Chris Froome winner four times and Geraint Thomas winning last for GB in 2018.\nTotal number of wins.\n\n\nCode\nwinners %>% \n  select(start_date, edition, winner_name) %>% \n  mutate(year = lubridate::year(start_date), true = TRUE) %>% \n  mutate(nationality = stringr::str_trim(winner_name)) %>% \n  pivot_wider(names_from = winner_name, values_from = true) %>% \n  mutate_at(vars(`Maurice Garin`:`Egan Bernal`), ~ if_else(is.na(.x), FALSE, .x)) %>% \n  mutate_at(vars(`Maurice Garin`:`Egan Bernal`), cumsum) %>% \n  pivot_longer(names_to = \"winner\", values_to = \"cumulative_wins\", `Maurice Garin`:`Egan Bernal`) %>% \n  ggplot(aes(x = start_date, y = cumulative_wins, group = winner, colour = winner)) +\n  geom_line() +\n  gghighlight::gghighlight(winner %in% c(\"Jacques Anquetil\", \"Bernard Hinault\", \"Eddy Merckx\", \"Miguel Induráin\", \"Lance Armstrong\")) + \n  labs(title = \"Total wins\", y = \"Wins\")\n\n\nWarning: Tried to calculate with group_by(), but the calculation failed.\nFalling back to ungrouped filter operation...\n\n\nWarning: Using `across()` in `filter()` is deprecated, use `if_any()` or\n`if_all()`.\n\n\nlabel_key: winner"
  },
  {
    "objectID": "posts/2020-04-08-tidy-tuesday-tour-de-france/index.html#specialists",
    "href": "posts/2020-04-08-tidy-tuesday-tour-de-france/index.html#specialists",
    "title": "Tidy Tuesday: Tour de France",
    "section": "Specialists",
    "text": "Specialists"
  },
  {
    "objectID": "posts/2020-04-08-tidy-tuesday-tour-de-france/index.html#which-was-the-most-difficult-edition",
    "href": "posts/2020-04-08-tidy-tuesday-tour-de-france/index.html#which-was-the-most-difficult-edition",
    "title": "Tidy Tuesday: Tour de France",
    "section": "Which was the most difficult edition",
    "text": "Which was the most difficult edition\nHow can we characterise the most difficult Tour de France. Here are a few variables which affect the difficulty or could be a proxy for the difficulty of the full tour\n\nDistance covered\nNumber of stage types (flat, mountain, TT)\nTotal time\nAverage Speed\nProportion of finishers\nWeather\nPaved roads\n\nSome of these will be difficult to quantify - for instance is weather data available for the France in 1903? Can we determine when the mountain passes in the Pyrenees and the Alps were paved? Let’s look at some of these which are present in the data.\nFirst consider the total distance of each Tour.\n\n\nCode\nstages <- tuesdata$tdf_stages\n\nstages %>% \n  mutate(year = lubridate::year(Date)) %>% \n  count(year, wt = Distance, name = \"total_distance\") %>% \n  ggplot(aes(y = total_distance, x = year)) + \n  geom_col() +\n  gghighlight::gghighlight(total_distance > 5000) +\n  coord_flip()\n\n\nWarning: Using `across()` in `filter()` is deprecated, use `if_any()` or\n`if_all()`.\n\n\n\n\n\nIf we look at the composition of the stages we see that the 1903 had only six stages! Let’s calculate the total distance by stage type.\n\n\nCode\nstage_types <- stages %>% \n  rowwise() %>% \n  mutate(year = lubridate::year(Date),\n         type = case_when(\n           str_detect(Type, regex(\"time\", ignore_case = T)) ~ \"time trial\",\n           str_detect(Type, regex(\"mountain\", ignore_case = T)) ~ \"mountain\",\n           str_detect(Type, regex(\"hilly\", ignore_case = T)) ~ \"hilly\",\n           T ~ \"flat\")) %>% \n  group_by(year, type) %>% \n  summarise(total_distance = sum(Distance), average_distance = mean(Distance))\n\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\n\n\nCode\nstage_types %>%\n  ungroup() %>%\n  tidyr::complete(year, type) %>% \n  mutate_if(is.numeric, ~ replace_na(., 0)) %>% \n  ggplot(aes(x = year, y = total_distance, fill = type)) +\n  geom_col() +\n  coord_flip() +\n  scale_x_reverse()"
  },
  {
    "objectID": "posts/2016-12-01-PracticalAkkaStreams/index.html",
    "href": "posts/2016-12-01-PracticalAkkaStreams/index.html",
    "title": "Practical Introduction to Akka Streaming",
    "section": "",
    "text": "Akka Streaming is a streaming IO engine used to build high performance, fault tolerant and scalable streaming data services. In this post I will describe how you can implement some of the features included in Akka Streaming using only simple streams of integers and strings, although the true power of Akka streams only becomes apparent when we are consuming data from real sources such as Websockets, databases and files. Akka is available in Java and Scala, but I will be focusing on the Scala API in this post."
  },
  {
    "objectID": "posts/2016-12-01-PracticalAkkaStreams/index.html#building-a-new-sbt-project",
    "href": "posts/2016-12-01-PracticalAkkaStreams/index.html#building-a-new-sbt-project",
    "title": "Practical Introduction to Akka Streaming",
    "section": "Building a new SBT Project",
    "text": "Building a new SBT Project\nSimple Build Tool is the most used build tool of Scala developers, despite the name it is incredibly powerful with many advanced features. In this post, we will be using SBT to manage the dependency on Akka. Firstly we must specify the following directory structure:\n.\n├── build.sbt\n└── src\n    └── main\n        └── scala\n\n3 directories, 1 file\nThe file build.sbt will contain the information required by SBT to download the Akka Stream dependencies. The .scala source code will live in the scala directory.\n\nDependencies in SBT\nFirst, we need to to specify some library dependencies in the file build.sbt:\nname := \"Akka-Stream-Example\"\nversion := \"1.0\"\n\nscalaVersion := \"2.11.8\"\n\nlibraryDependencies += \"com.typesafe.akka\" %% \"akka-stream\" % \"2.4.14\"\nNow, in the terminal, navigate to the root directory of the project and run sbt. The dependencies will be downloaded automatically, and available to use in any source files."
  },
  {
    "objectID": "posts/2016-12-01-PracticalAkkaStreams/index.html#source",
    "href": "posts/2016-12-01-PracticalAkkaStreams/index.html#source",
    "title": "Practical Introduction to Akka Streaming",
    "section": "Source",
    "text": "Source\nSource represents the start of an Akka stream, there are many methods for constructing streams from Source. For now, we will define a ticking stream of integers and investigate how we can transform and output this stream using Flows and Sinks respectively. Here is a Source which outputs a steady stream of 1s every second\nimport akka.actor.ActorSystem\nimport akka.stream.ActorMaterializer\nimport akka.stream.scaladsl._\n\nobject Streaming {\n  implicit val system = ActorSystem(\"Streaming\")\n  implicit val executor = system.dispatcher\n  implicit val materializer = ActorMaterializer()\n\n  val in = Source.tick(1.second, 1.second, 1)\n}"
  },
  {
    "objectID": "posts/2016-12-01-PracticalAkkaStreams/index.html#flow",
    "href": "posts/2016-12-01-PracticalAkkaStreams/index.html#flow",
    "title": "Practical Introduction to Akka Streaming",
    "section": "Flow",
    "text": "Flow\nA Flow is a data processing stage. We will define a data flow which takes in an integer, then doubles it.\nval doubleFlow = Flow[Int].map(a => a * 2)\nThis Flow is reusable and can be joined on to any stream which emits an Int. The map function is an example of a higher-order function; a higher-order function accepts a function as an argument. The map function here is used to access the value held inside of the Flow, in this case an Int. The function passed as the argument to map is an anonymous (or lambda) function, it says we take the Int and multiply it by two, a type annotation is not needed on the value a as the compiler infers the type to be Int."
  },
  {
    "objectID": "posts/2016-12-01-PracticalAkkaStreams/index.html#sink",
    "href": "posts/2016-12-01-PracticalAkkaStreams/index.html#sink",
    "title": "Practical Introduction to Akka Streaming",
    "section": "Sink",
    "text": "Sink\nA Sink is an endpoint to a stream, we can use it to print to the console, write to a database or another external service. However only when the stream is materialized is the side effect in the Sink performed. Let’s define a simple sink which prints each element out on a new line\nval out = Sink.foreach(println)"
  },
  {
    "objectID": "posts/2016-12-01-PracticalAkkaStreams/index.html#putting-it-all-together",
    "href": "posts/2016-12-01-PracticalAkkaStreams/index.html#putting-it-all-together",
    "title": "Practical Introduction to Akka Streaming",
    "section": "Putting it all together",
    "text": "Putting it all together\nNow we want to get our stream printing to the console, we must define a main method for the Streaming object connecting the Source to the Flow and finally to the Sink.\nimport akka.actor.ActorSystem\nimport akka.stream.ActorMaterializer\nimport akka.stream.scaladsl.{Sink, Flow, Source}\nimport scala.concurrent.duration._\n\nobject Streaming {\n  implicit val system = ActorSystem(\"Streaming\")\n  implicit val executor = system.dispatcher\n  implicit val materializer = ActorMaterializer()\n\n  val in = Source.tick(1.second, 1.second, 1)\n  val double_flow = Flow[Int].map(a => a * 2)\n  val print_sink = Sink.foreach(println)\n\n  def main(args: Array[String]) {\n      in.\n        via(double_flow).\n        take(10).\n        runWith(print_sink).\n        onComplete(_ => system.terminate)\n  }\n}\nYou can now run this code block using by executing sbt run from the terminal, in the project directory root (where build.sbt lives). We should get a stream of twos emitting once every second. The function take will limit the amount of twos printed to the console and once the stream is exhausted the Akka system is shutdown using the function onComplete."
  },
  {
    "objectID": "posts/2016-12-01-PracticalAkkaStreams/index.html#graph-dsl",
    "href": "posts/2016-12-01-PracticalAkkaStreams/index.html#graph-dsl",
    "title": "Practical Introduction to Akka Streaming",
    "section": "Graph DSL",
    "text": "Graph DSL\nAkka Streaming provides a domain specific language (DSL) to express stream processing pipelines using a graph. Here is another way to define the main method using a RunnableGraph:\nval graph = RunnableGraph.fromGraph(GraphDSL.create() { implicit builder =>\n\n  in ~> double_flow ~> Flow[Int].take(10) ~> print_sink\n\n  ClosedShape\n})\n  \ngraph.run()\nThe graph DSL requires a bit of work, namely defining a runnable graph and specifying that the graph is closed. This is because we can define partial graphs (a graph which isn’t connected to a Source, Sink or both) which compose with other graphs, handy if you want to reuse a block of processing.\nIn order to specify a partial graph with no connections, we use FlowShape(inlet, outlet). Let’s define a partial graph which takes in one stream a integers, splits them on a condition, performs some processing then sends them out:\nval partial_graph = Flow.fromGraph(GraphDSL.create() { implicit builder =>\n    val broadcast = builder.add(Broadcast[Int](2))\n    val zip = builder.add(Zip[Int, Int]())\n\n    broadcast.out(0) ~> Flow[Int].filter(_ % 2 == 0) ~> Flow[Int].map(_ / 2) ~> zip.in0\n    broadcast.out(1) ~> Flow[Int].filter(_ % 2 != 0) ~> Flow[Int].map(_ * 2) ~> zip.in1\n\n    FlowShape(broadcast.in, zip.out)\n  })\nThis FlowShape is expecting a Source containing integers, in the first line of processing it checks if the items are even, then divides them by two. The second line of processing doubles all the even numbers. The two streams are then recombined using a zip. In order to materialize data through this processing stage, a Source of integers and a Sink must be connected."
  },
  {
    "objectID": "posts/2016-12-01-PracticalAkkaStreams/index.html#merging-a-stream",
    "href": "posts/2016-12-01-PracticalAkkaStreams/index.html#merging-a-stream",
    "title": "Practical Introduction to Akka Streaming",
    "section": "Merging a stream",
    "text": "Merging a stream\nIf we have two streams containing the same datatype, then we can merge these two streams into one:\nLet’s reuse our stream of ones and merge it into the stream of twos we already have:\nval merge_graph = RunnableGraph.fromGraph(GraphDSL.create() { implicit builder =>\n  val merge = builder.add(Merge[Int](2))\n  \n  in ~> double_flow ~> merge ~> print_sink\n                in ~> merge\n  ClosedShape\n})\nWe add a Merge to the graph builder, Merge requires we specify the type of the stream elements we are merging and the number of stream sources we are merging. We then alter the stream processing flow to include a stream of ones and perform the merge.\nIn this case, if the stream of ones was publishing at a higher frequency than the other stream, we would have a stream with more ones than twos. ie:\n1 1 1 2 1 1 1 2 …"
  },
  {
    "objectID": "posts/2016-12-01-PracticalAkkaStreams/index.html#zipping-a-stream",
    "href": "posts/2016-12-01-PracticalAkkaStreams/index.html#zipping-a-stream",
    "title": "Practical Introduction to Akka Streaming",
    "section": "Zipping a Stream",
    "text": "Zipping a Stream\nWe can zip a stream just as we can zip collections in Scala. This results in a tuple, which can have heterogeneous types. Zip requires that both streams have an element available, so if one stream is publishing at a quicker rate than the others there will be buffering of those elements.\nTo illustrate this, we will build a continuous stream of natural numbers using the unfold function:\nval naturalNumbers = Source.unfold(1)(a => Some(a + 1, a))\nunfold is the dual of fold and is an Anamorphism. unfold starts with a seed value and applies a function to produce the next value in the stream, the result of this function evaluation is sent to the next evaluation and so on. Using unfold is a simple way to define a stream which depends on the previous value.\nNow if we zip together a continuous source of ones which publishes every ten seconds, Zip will wait for both streams to have an element before publishing the tuple of both streams, guaranteeing order.\nval in = Source.tick(1.second, 10.seconds, 1)\n\nval zipStream = RunnableGraph.fromGraph(FlowGraph.create() { implicit builder =>\n    val zip = builder.add(Zip[Int, Int])\n    naturalNumbers ~> zip.in0\n    in ~> zip.in1\n    zip.out ~> out\n\n    ClosedShape\n  })\n\n  def main(args: Array[String]): Unit = {\n    zipStream.run(materializer)\n  }\nThe output from this stream is: (1,1) (2,1) (3,1) …"
  },
  {
    "objectID": "posts/2016-12-01-PracticalAkkaStreams/index.html#summary",
    "href": "posts/2016-12-01-PracticalAkkaStreams/index.html#summary",
    "title": "Practical Introduction to Akka Streaming",
    "section": "Summary",
    "text": "Summary\nWe have covered a few ways to express simple streams using Akka Streaming. The real power of Akka streaming is when it is combined with file or connection handling. Streaming libraries can be used to process extremely large, or unbounded, data files using a bounded amount of computational power. This is useful when dealing with infinite sources of data, such as streaming data from Twitter."
  },
  {
    "objectID": "posts/2021-02-02-neural-networks-in-r/index.html",
    "href": "posts/2021-02-02-neural-networks-in-r/index.html",
    "title": "Neural Networks in R",
    "section": "",
    "text": "knitr::opts_chunk$set(echo = TRUE)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n✔ tibble  3.1.6     ✔ dplyr   1.0.8\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\nWarning: package 'tidyr' was built under R version 4.1.2\n\n\nWarning: package 'readr' was built under R version 4.1.2\n\n\nWarning: package 'dplyr' was built under R version 4.1.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(torch)\n\nWarning: package 'torch' was built under R version 4.1.2\n\ntheme_set(theme_minimal())\nIn this post we will see how to train a neural network model using R and the Torch R library which is a port of the Python torch library without dependencies on Python. Torch provides tensors (n-dimensional arrays), automatic differentiation of tensors, optimisation routines and additional helpers for common deep learning tasks such as computer vision and audio processing.\nA neural network is built of layers. A layer consists of a set of weights, which are the parameters of the layer and an activation function (this can have additional parameters too). A single layer looks like the linear predictor in a generalised linear model,\n\\[\n\\eta = g(x^Tw),\n\\]\nwhere \\(\\eta\\) is the linear predictor, \\(g\\) is the linking function and \\(w\\) represent the coefficients of the covariates \\(x\\). In machine learning, \\(x\\) is referred to simply as the input, \\(w\\) are the weights and \\(g\\) is the activation function. There is often an additional parameter, termed the intercept in generalised linear models and the bias in machine learning. This can be rolled in to the weight vector by appending a one to the input / covariates. We can encapsulate this logic in a function\nWe also require a loss function, to understand how well our model is fitting to the data. For a regression problem we can use squared loss.\nWe will define a simple linear regression problem, our observations are noisy observations of a straight line.\n\\[y \\sim \\mathcal{N}(x^Tw, 2.0)\\]\nWe wish to learn the relationship between the inputs \\(x\\) and the outputs \\(y\\) using the model. To understand how well the model fits the observed data, we make a prediction by passing an observed input to the model (which is defined as a single layer), then we calculate how far the prediction is from the observed output using the squared loss function. The activation function is linear, or the identity function (function(x) x).\nTo find the best fit for this model to the observed data, we need to manipulate the weights to reduce the loss function. We can think of the weights as parameterising a family of related models, some of which may fit the data well."
  },
  {
    "objectID": "posts/2021-02-02-neural-networks-in-r/index.html#optimisation",
    "href": "posts/2021-02-02-neural-networks-in-r/index.html#optimisation",
    "title": "Neural Networks in R",
    "section": "Optimisation",
    "text": "Optimisation\nTo find the maximum of a function in calculus, we first calculate the derivative and determine the point at which the slope is equal to zero. This can find both maximums and minimums (or saddle points), so we can additionally calculate the second derivative and if it’s negative then we have a maximum. This is fine for linear optimisation, however when it comes to non-linear optimisation we have to be more creative. We can use gradient descent to take steps in the opposite direction of the gradient to find the minimum of a non-linear function\n\ngradient_step <- function(learning_rate, params, grad_params) \n  params - learning_rate * grad_params\n\nWe must calculate the derivative of the network with respect to the weight parameters. For a single layer network with univariate inputs, a linear activation function and a squared loss function the derivative is\n\\[\\frac{d \\text{ network}}{dw} = \\frac{d}{dw} (y - x^Tw)^2 = -2x^T(y-x^Tw).\\]\nWe can encapsulate this derivative as a function.\n\nnetwork_gradient <- function(x, y, w) {\n  -2 * t(x) %*% (y - x %*% w)\n}\n\nWe can check the analytically calculated gradient using Torch. First we use our calculation of the gradient.\n\nx_test <- matrix(rnorm(2))\nw <- matrix(rnorm(2))\ny_test <- matrix(rnorm(1))\nnetwork_gradient(t(x_test), y_test, w)\n\n           [,1]\n[1,] 0.15098599\n[2,] 0.05417119\n\n\nThen we must write the forward function of the model, pred and calculate the loss using the functions available on Torch tensors. We can then call backward() which performs reverse mode automatic differentiation then we can access the grad attribute of any tensor which has requires_grad = TRUE.\n\nnetwork_gradient_torch <- function(x, y, w) {\n  pred <- w$t()$mm(x)\n  loss <- (y - pred)$pow(2)$sum()\n  loss$backward()\n  w$grad\n}\n\nnetwork_gradient_torch(x = torch_tensor(as.matrix(x_test)),\n                       y = torch_tensor(as.matrix(y_test)),\n                       w = torch_tensor(as.matrix(w), requires_grad = TRUE))\n\ntorch_tensor\n 0.1510\n 0.0542\n[ CPUFloatType{2,1} ]\n\n\nWe can fit this simple model by writing a training loop which updates the parameters using gradient descent. We keep track of the loss function at each iteration of gradient descent and plot it.\n\nobserved <- tibble(x, y) %>%\n  sample_n(50)\n\n\ntraining_loop <- function(x, y, init_w, epochs, learning_rate) {\n  # Record all changes to parameters and training loss\n  ws <- matrix(NA_real_, nrow = epochs + 1, ncol = length(init_w))\n  ws[1,] = init_w\n  losses <- numeric(length(y))\n  \n  for (i in seq_len(epochs)) {\n    # Pad the input with 1 for intercept/bias\n    input <- cbind(rep(1, times = length(x)), x)\n    \n    # Made a prediction using the model\n    pred <- layer(input, ws[i,], function(z) z)\n    \n    # We can calculate and log/print the loss \n    losses[i] <- loss(y, pred)\n    \n    # calculate the gradient at this point\n    gradient <- network_gradient(x = input, y = y, w = ws[i, ])\n    \n    # Update using gradient descent\n    ws[i + 1, ] <- gradient_step(learning_rate, \n                                 ws[i, ], \n                                 gradient)\n  }\n  \n  list(weights = ws, losses = losses)\n}\n\n\nout <- training_loop(x = scale(observed$x), y = scale(observed$y), c(1, 1), 500, 1e-4)\nqplot(x = seq_along(out$losses), y = out$losses, geom = \"line\") +\n  labs(x = \"Epoch\", y = \"Loss\")\n\n\n\n\nSince this model is so small, consisting of only two weights. We can plot the actual function learned by the model using geom_abline.\n\nggplot(observed, aes(scale(x), scale(y))) +\n  geom_point() +\n  geom_abline(intercept = out$weights[501, 1], slope = out$weights[501,2]) + \n  labs(x = \"x\", y = \"y\")\n\n\n\n\nWe can try to use this model on a simple non-linear regression problem, of course we probably won’t do very well here! We define the regression problem as\n\\[y \\sim \\mathcal{N}(4\\sin(x), 1^2).\\]\nWe plot the true function and the observed values in red below.\n\nn <- 100\nx <- seq(-5, 5, length.out=n)\ny <- 4 * sin(x)\ny_obs <- 4 * sin(x) + rnorm(n, sd = 1)\nnon_linear <- tibble(x, y_obs) %>% sample_n(20)\nqplot(x, y, geom = \"line\") +\n  geom_point(data = non_linear, aes(x = x, y = y_obs, colour = \"Observed\")) +\n  theme(legend.position = \"none\")\n\n\n\n\n\nout <- training_loop(non_linear$x, non_linear$y_obs, c(1, 1), 200, 1e-4)\nqplot(x = seq_along(out$losses), y = out$losses, geom = \"line\") +\n  labs(x = \"Epoch\", y = \"Loss\")\n\n\n\n\nWe can then plot the learned function against the observed values and the true function. We can see that a straight line is not a good fit for this data, we need more flexibility in the network.\n\nqplot(x, y, geom = \"line\", colour = \"truth\") +\n  geom_point(data = non_linear, aes(x, y_obs, colour = \"observed\")) +\n  geom_abline(intercept = out$weights[201,1], slope = out$weights[201,1]) +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/2021-02-02-neural-networks-in-r/index.html#using-torch",
    "href": "posts/2021-02-02-neural-networks-in-r/index.html#using-torch",
    "title": "Neural Networks in R",
    "section": "Using Torch",
    "text": "Using Torch\nIf we want to approximate a non-linear function, we best use non-linear activation functions. We can calculate the derivative of each layer using automatic differentiation. We will use the R Torch library. We now initialise a torch tensor with the same values as x and pass it through the layers. We must re-write the layer and loss functions assuming the input is a torch_tensor. First we will re-write the linear example using Torch\n\nmodel <- nn_linear(1, 1)\n\nloss <- function(y, pred) {\n  (y - pred)$pow(2)$sum()\n}\n\ntrain_torch <- function(x, y, model, loss, epochs) {\n  alpha <- 1e-4\n  x_in <- torch_tensor(as.matrix(x))\n  for (i in seq_len(epochs)) {\n    pred <- model(x_in)\n    losses <- loss(torch_tensor(y), pred)\n    model$zero_grad()\n    losses$backward()\n    if (i %% 10 == 0)\n      cat(\"Epoch: \", i, \"   Loss: \", losses$item(), \"\\n\")\n    with_no_grad({\n      model$parameters %>% \n        purrr::walk(function(param) param$sub_(alpha * param$grad))\n    })\n  }\n  model\n}\n\ntrained_model <- train_torch(scale(observed$x), scale(observed$y), model, loss, 200)\n\nEpoch:  10    Loss:  58.6479 \nEpoch:  20    Loss:  48.48629 \nEpoch:  30    Loss:  40.14468 \nEpoch:  40    Loss:  33.2971 \nEpoch:  50    Loss:  27.67593 \nEpoch:  60    Loss:  23.06152 \nEpoch:  70    Loss:  19.27356 \nEpoch:  80    Loss:  16.16403 \nEpoch:  90    Loss:  13.6114 \nEpoch:  100    Loss:  11.51595 \nEpoch:  110    Loss:  9.795779 \nEpoch:  120    Loss:  8.383685 \nEpoch:  130    Loss:  7.224489 \nEpoch:  140    Loss:  6.272895 \nEpoch:  150    Loss:  5.491727 \nEpoch:  160    Loss:  4.850457 \nEpoch:  170    Loss:  4.324034 \nEpoch:  180    Loss:  3.891886 \nEpoch:  190    Loss:  3.53713 \nEpoch:  200    Loss:  3.245904 \n\n\n\nggplot(observed, aes(scale(x), scale(y))) +\n  geom_point() +\n  geom_abline(intercept = trained_model$parameters$bias$item(), slope = trained_model$parameters$weight$item())\n\n\n\n\nTry the non-linear example with multiple layers and a non-linear activation function from the first layer (where the input goes). We’ll also try a different optimizer, Adam.\n\ntrain_torch <- function(x, y, model, loss, epochs, learning_rate) {\n  x_in <- x\n  optimiser <- optim_adam(model$parameters, lr = learning_rate)\n  for (i in seq_len(epochs)) {\n    pred <- model(x_in)\n    losses <- loss(y, pred)\n    model$zero_grad()\n    losses$backward()\n    if (i %% 10 == 0)\n      cat(\"Epoch: \", i, \"   Loss: \", losses$item(), \"\\n\")\n    optimiser$step()\n  }\n  model\n}\n\nmodel <- nn_sequential(\n  nn_linear(1, 64),\n  nn_relu(),\n  nn_linear(64, 1)\n)\n\ntrained_model <-\n  train_torch(torch_tensor(as.matrix(non_linear$x)),\n              torch_tensor(as.matrix(non_linear$y_obs)),\n              model,\n              nnf_mse_loss,\n              100, \n              0.1)\n\nEpoch:  10    Loss:  6.853224 \nEpoch:  20    Loss:  2.670638 \nEpoch:  30    Loss:  1.007208 \nEpoch:  40    Loss:  0.7993301 \nEpoch:  50    Loss:  0.683284 \nEpoch:  60    Loss:  0.6011851 \nEpoch:  70    Loss:  0.5383755 \nEpoch:  80    Loss:  0.5088955 \nEpoch:  90    Loss:  1.185604 \nEpoch:  100    Loss:  0.5675938 \n\n\nWe can plot the predictions alongside the observed values and the true function.\n\npredictions <- tibble(x, prediction = as_array(trained_model(torch_tensor(x)$unsqueeze(-1))))\n\nqplot(x, y, geom = \"line\", colour = \"truth\") +\n  geom_line(data = predictions, aes(x, prediction, colour = \"fitted\")) +\n  geom_point(data = non_linear, aes(x, y_obs, colour = \"observed\")) +\n  labs(colour = \"\") +\n  theme(legend.position = c(0.9, 0.9))"
  },
  {
    "objectID": "posts/2019-07-31-hmc/index.html",
    "href": "posts/2019-07-31-hmc/index.html",
    "title": "Hamiltonian Monte Carlo in R",
    "section": "",
    "text": "Determining the posterior distribution for the parameters of a real-world Bayesian model inevitably requires calculating high-dimensional integrals. Often these are tedious or impossible to calculate by hand. Markov chain Monte Carlo (MCMC) algorithms are popular approaches, samplers such as the Gibbs sampler can be used to sample from models with conditionally conjugate specifications and the Metropolis-Hastings algorithm can be used when the conditionally conjugate form is not present.\nThere are downsides to these established methods, Gibbs sampling puts a restrictive form on the prior distribution. Although Metropolis-Hastings (MH) allows any prior distribution from which the probability density function can be evaluated, the proposal distribution is often a multivariate Normal distribution with mean corresponding to the previous value of the parameters. This proposal results in random walk behaviour and although the MH algorithm is guaranteed to converge it can take a long time to get satisfactory draws from the posterior distribution.\nThe gradient of the un-normalised log-posterior distribution can be used to explore the posterior distribution more efficiently. Hamiltonian Monte Carlo (HMC) is an MCMC method which utilises a discretisation of Hamilton’s equations in order to model a physical system where the parameters are represented by the position of a particle in \\(\\theta \\in \\mathbb{R^d}\\). In order to implement HMC, the posterior distribution is augmented with a momentum vector, \\(\\phi\\), which is used to propose updates to the position which can be far away from the initial position."
  },
  {
    "objectID": "posts/2019-07-31-hmc/index.html#hmc-in-r",
    "href": "posts/2019-07-31-hmc/index.html#hmc-in-r",
    "title": "Hamiltonian Monte Carlo in R",
    "section": "HMC in R",
    "text": "HMC in R\nHamilton’s equations are discretised and a “leapfrog” update is used. These leapfrog steps can be written as:\n\nleapfrog_step <- function(gradient, step_size, position, momentum, d) {\n  momentum1 <- momentum + gradient(position) * 0.5 * step_size\n  position1 <- position + step_size * momentum1\n  momentum2 <- momentum1 + gradient(position1) * 0.5 * step_size\n\n  matrix(c(position1, momentum2), ncol = d*2)\n}\n\n\nleapfrogs <- function(gradient, step_size, l, position, momentum, d) {\n  for (i in 1:l) {\n    pos_mom <- leapfrog_step(gradient, step_size, position, momentum, d)\n    position <- pos_mom[seq_len(d)]\n    momentum <- pos_mom[-seq_len(d)]\n  }\n  pos_mom\n}\n\nThe log-acceptance can be written as:\n\nlog_acceptance <- function(propPosition,\n                           propMomentum,\n                           position,\n                           momentum,\n                           log_posterior) {\n  log_posterior(propPosition) + sum(dnorm(propMomentum, log = T)) - \n    log_posterior(position) - sum(dnorm(momentum, log = T))\n}\n\nIn order to propose a new set of parameters a random momentum vector is drawn from the Normal distribution and used in the leapfrog steps. To ensure detailed balance and that the stationary distribution of the Markov chain is equivalent to the target distribution, a metropolis step is used accepting the newly proposed parameters with log-probability equal to the log_acceptance defined above. To implement this in R, we compare a log uniform random number to the log acceptance criteria. A single HMC step can be written as:\n\nhmc_step <- function(log_posterior, gradient, step_size, l, position) {\n  d <- length(position)\n  momentum <- rnorm(d)\n  pos_mom <- leapfrogs(gradient, step_size, l, position, momentum, d)\n  propPosition <- pos_mom[seq_len(d)]\n  propMomentum <- pos_mom[-seq_len(d)]\n  a <- log_acceptance(propPosition, propMomentum, position, momentum, log_posterior)\n  if (log(runif(1)) < a) {\n    propPosition\n  } else {\n    position\n  }\n}\n\nThe HMC algorithm can be written as\n\nhmc <- function(log_posterior, gradient, step_size, l, initP, m) {\n  out <- matrix(NA_real_, nrow = m, ncol = length(initP))\n  out[1, ] <- initP\n  for (i in 2:m) {\n    out[i, ] <- hmc_step(log_posterior, gradient, step_size, l, out[i-1,])\n  }\n  out\n}"
  },
  {
    "objectID": "posts/2019-07-31-hmc/index.html#an-example-model-bivariate-normal-model",
    "href": "posts/2019-07-31-hmc/index.html#an-example-model-bivariate-normal-model",
    "title": "Hamiltonian Monte Carlo in R",
    "section": "An Example Model: Bivariate Normal Model",
    "text": "An Example Model: Bivariate Normal Model\nThe same bivariate Normal model from a previous post implementing the Metropolis algorithm is used. See that post for details of deriving the log-likelihood and choice of prior distributions for the parameters.\n\n\n\n\n\n\n\n\nFrom the previous post, the log-posterior distribution is the sum of the log-prior and the log-likelihood. The log-likelihood is given by:\n\\[\\log p(y|\\mu, \\Sigma) = \\sum_{j=1}^2\\left(-\\frac{N}{2}\\log(2\\pi\\sigma_{j}^2) - \\frac{1}{2\\sigma_{j}^2}\\sum_{i=1}^N(y_{ij}-\\mu_j)^2\\right)\\] Where \\(\\Sigma = \\operatorname{diag}(\\sigma_1, \\sigma_2)\\), the prior distributions are chosen to be:\n$$\\[\\begin{align}\n\n\np(\\mu_j) &= \\mathcal{N}(0, 3), \\\\\np(\\sigma_j) &= \\textrm{Gamma}(3, 3), \\quad j = 1, 2.\n\\end{align}\\]$$\nThe log-pdf of these distributions are:\n\\[\\begin{align}\n\\log p(\\mu_j) &= -\\frac{1}{2}\\log(18\\pi)-\\frac{\\mu_j^2}{18} \\\\\n\\log p(\\sigma_j) &= \\alpha\\log(\\beta)-\\log(\\Gamma(\\alpha)) + (\\alpha-1)\\log(\\sigma_j)-\\beta \\sigma_j\n\\end{align}\\]\nThe gradient of the log-posterior with respect to each of the paramters can be written as:\n$$\\[\\begin{align}\n\n\n\\frac{\\partial \\ell}{\\partial \\mu_j} &= \\frac{1}{\\sigma_j^2}\\sum_{i=1}^N(y_{ij}-\\mu_j) - \\frac{\\mu_j}{9}, \\\\\n\\frac{\\partial \\ell}{\\partial \\sigma_j} &= -\\frac{N}{\\sigma_j} +  \\frac{1}{\\sigma_j^3}\\sum_{i=1}^N(y_{ij}-\\mu_j)^2 + \\frac{2}{\\sigma_j}-3, \\quad j = 1, 2.\n\\end{align}\\]$$\nIn R the gradient can be programmed by hand:\n\ngradient <- function(ys) {\n  function(theta) {\n    mu <- c(theta[1], theta[3])\n    sigma <- c(theta[2], theta[4])\n    n <- nrow(ys)\n    c(1/sigma[1]^2*sum(ys[,1] - mu[1]) - mu[1]/9,\n      -n/sigma[1] + sum((ys[,1] - mu[1])^2) / sigma[1]^3 + 2/sigma[1] - 3,\n      1/sigma[2]^2*sum(ys[,2] - mu[2]) - mu[2]/9,\n      -n/sigma[2] + sum((ys[,2] - mu[2])^2) / sigma[2]^3 + 2/sigma[2] - 3)\n  }\n}\n\nTo ensure the value of the gradient is correct we can compare it to a numerical approximation of the gradient using the https://cran.r-project.org/web/packages/numDeriv/numDeriv.pdf package:\n\napprox_gradient <- function(xs, theta) {\n    grad(log_posterior(xs), theta)\n}\n\ncompare_gradient <- function(theta, tol) {\n  abs(gradient(xs)(theta) - approx_gradient(xs, theta)) < tol\n}\n\ncompare_gradient(theta, 1e-3)\n\n[1] TRUE TRUE TRUE TRUE\n\n\nIt appears the calculated derivative is correct. Next, HMC works best when the leapfrog proposal can propose unconstrained values of the parameters which lie on the whole real line. A transform function is defined for the parameters, \\(\\theta\\) which calculates the exponential of the standard deviation parameters. The log-posterior is calculated using the transformed values, the appropriate transformation and inverse transformation functions can be written as:\n\ntransform <- function(theta) {\n  c(theta[1], exp(theta[2]), theta[3], exp(theta[4]))\n}\n\ninv_transform <- function(theta) {\n  c(theta[1], log(theta[2]), theta[3], log(theta[4]))\n}\n\nThe leapfrog step proposal is calculated using the unconstrained parameters, hence the derivative of the log-jacobian of the transformation is required to be added to the value of the gradient of the log-density. Then the derivative of the log-jacobian is calculated to get the value of the gradient corresponding to the unconstrained parameters in the leapfrog step.\n\nlog_jacobian <- function(theta) {\n  c(0, theta[2], 0, theta[4])\n}\n\nderiv_log_jacobian <- function(theta) {\n  c(0, 1, 0, 1)\n}\n\nThe derivative of the log-jacobian contributes the value 1 to each of the partial derivatives \\(\\frac{\\partial \\ell}{\\partial \\sigma_j}, j = 1, 2.\\)\n\n# evaluate the log-posterior on the appropriate scale, using the transform function\nbounded_log_posterior <- function(xs) {\n  function(theta) {\n    log_posterior(xs)(transform(theta)) + sum(log_jacobian(theta))\n  }\n}\n\nbounded_gradient <- function(xs) {\n  function(theta) {\n    gradient(xs)(transform(theta)) + deriv_log_jacobian(theta)\n  }\n}\n\nThe HMC algorithm can be run in parallel using the furrr package as described in my post about the Metropolis algorithm. First the hmc function is used in another function which returns a dataframe called hmc_df.\n\nhmc_df <- function(log_posterior, gradient, step_size, l, initP, m, parameter_names) {\n  mat <- hmc(log_posterior, gradient, step_size, l, initP, m)\n  colnames(mat) <- parameter_names\n  as.data.frame(mat) %>% \n    mutate(iteration = row_number())\n}\n\nThen the function is used in future_map_dfr:\n\nfuture::plan(future::multiprocess)\n\nWarning: Strategy 'multiprocess' is deprecated in future (>= 1.20.0). Instead,\nexplicitly specify either 'multisession' or 'multicore'. In the current R\nsession, 'multiprocess' equals 'multicore'.\n\nstart_time <- Sys.time()\nout_hmc <-\n  furrr::future_map_dfr(\n    .x = 1:2,\n    .f = function(x)\n      hmc_df(\n        bounded_log_posterior(xs),\n        bounded_gradient(xs),\n        0.01,\n        4,\n        inv_transform(theta),\n        10000,\n        c(\"mu1\", \"sigma1\", \"mu2\", \"sigma2\")\n      ),\n    .id = \"chain\"\n  )\n\nWarning: UNRELIABLE VALUE: Future ('<none>') unexpectedly generated random\nnumbers without specifying argument 'seed'. There is a risk that those random\nnumbers are not statistically sound and the overall results might be invalid.\nTo fix this, specify 'seed=TRUE'. This ensures that proper, parallel-safe random\nnumbers are produced via the L'Ecuyer-CMRG method. To disable this check, use\n'seed=NULL', or set option 'future.rng.onMisuse' to \"ignore\".\n\n\nWarning: UNRELIABLE VALUE: Future ('<none>') unexpectedly generated random\nnumbers without specifying argument 'seed'. There is a risk that those random\nnumbers are not statistically sound and the overall results might be invalid.\nTo fix this, specify 'seed=TRUE'. This ensures that proper, parallel-safe random\nnumbers are produced via the L'Ecuyer-CMRG method. To disable this check, use\n'seed=NULL', or set option 'future.rng.onMisuse' to \"ignore\".\n\nend_time <- Sys.time()\nhmc_time <- end_time - start_time\n\nThe traceplots of both chains are plotted below."
  },
  {
    "objectID": "posts/2019-07-31-hmc/index.html#evaluating-the-efficiency",
    "href": "posts/2019-07-31-hmc/index.html#evaluating-the-efficiency",
    "title": "Hamiltonian Monte Carlo in R",
    "section": "Evaluating the efficiency",
    "text": "Evaluating the efficiency\nIn order to compare between Markov chain Monte Carlo algorithms the amount of information from each correlated sample can be measured. This is termed the effective sample size, corresponding to the number of effectively independent draws from the posterior distribution. The code below calculates the ESS of each parameter in the chain using ess_bulk from the R interface to stan rstan library. The ESS per second can be calculated which is a measure of the efficiency of the sampler\n\nout_hmc %>% \n  summarise_at(2:5, rstan::ess_bulk) %>% \n  mutate_all(~ . / as.numeric(hmc_time))\n\n       mu1   sigma1      mu2   sigma2\n1 10169.87 3713.415 1147.888 4983.936\n\n\nThis could be compared to a similar method, such as the Metropolis algorithm. To determine which algorithm is the most efficient for sampling from the posterior distribution of the bivariate Normal model.\n\nproposal <- function(x) {\n  z = rnorm(4, sd = 0.05)\n  c(x[1] + z[1], x[2] * exp(z[2]),\n    x[3] + z[3], x[4] * exp(z[4]))\n}\nnames(theta) <- c(\"mu1\", \"sigma1\", \"mu2\", \"sigma2\")\n\nstart_time <- Sys.time()\nout_met <- metropolis(theta, log_posterior(xs), proposal, 1e4, chains = 2, parallel = TRUE)\n\nWarning: UNRELIABLE VALUE: Future ('<none>') unexpectedly generated random\nnumbers without specifying argument 'seed'. There is a risk that those random\nnumbers are not statistically sound and the overall results might be invalid.\nTo fix this, specify 'seed=TRUE'. This ensures that proper, parallel-safe random\nnumbers are produced via the L'Ecuyer-CMRG method. To disable this check, use\n'seed=NULL', or set option 'future.rng.onMisuse' to \"ignore\".\n\n\nWarning: UNRELIABLE VALUE: Future ('<none>') unexpectedly generated random\nnumbers without specifying argument 'seed'. There is a risk that those random\nnumbers are not statistically sound and the overall results might be invalid.\nTo fix this, specify 'seed=TRUE'. This ensures that proper, parallel-safe random\nnumbers are produced via the L'Ecuyer-CMRG method. To disable this check, use\n'seed=NULL', or set option 'future.rng.onMisuse' to \"ignore\".\n\nend_time <- Sys.time()\nmetropolis_time <- end_time - start_time\n\nThe ESS/s can be computed for the Metropolis algorithm\n\nout_met %>% \n  summarise_at(2:5, rstan::ess_bulk) %>% \n  mutate_all(~ . / as.numeric(metropolis_time))\n\n# A tibble: 1 × 4\n  accepted   mu1 sigma1   mu2\n     <dbl> <dbl>  <dbl> <dbl>\n1   12850. 1780.  1052.  424."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian Statistics and Functional Programming",
    "section": "",
    "text": "Comparing the performance of multiple machine learning models using Bayesian Hierarchical models.\n\n\n\n\n\n\nSep 27, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython\n\n\nDeep Learning\n\n\nBayesian\n\n\n\n\nUsing MC Dropout to get probability intervals for neural network predictions.\n\n\n\n\n\n\nAug 16, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython\n\n\nDeep Learning\n\n\n\n\nCreating entity embeddings for categorical predictors using Python.\n\n\n\n\n\n\nAug 4, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\nDeep Learning\n\n\n\n\nThis post explores how to create a simple neural network to learn a linear function and a non-linear function using both standard R and the Torch library for R.\n\n\n\n\n\n\nFeb 2, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBayesian\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nMay 1, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\nBayesian\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2020\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nApr 8, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\nBayesian\n\n\n\n\n\n\n\n\n\n\n\nMar 27, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntidy-tuesday\n\n\nR\n\n\nBayesian\n\n\n\n\n\n\n\n\n\n\n\nMar 17, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntidy-tuesday\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nMar 10, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nMar 4, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\ntidy-tuesday\n\n\n\n\n\n\n\n\n\n\n\nMar 3, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\nBayesian\n\n\n\n\n\n\n\n\n\n\n\nAug 9, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nAug 5, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\nBayesian\n\n\n\n\n\n\n\n\n\n\n\nJul 31, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\nBayesian\n\n\n\n\n\n\n\n\n\n\n\nJun 14, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScala\n\n\n\n\n\n\n\n\n\n\n\nApr 16, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScala\n\n\n\n\n\n\n\n\n\n\n\nApr 15, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR,Bayesian\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nFeb 22, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\nBayesian\n\n\n\n\n\n\n\n\n\n\n\nFeb 11, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nOct 26, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScala,Bayesian\n\n\n\n\n\n\n\n\n\n\n\nApr 23, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScala\n\n\n\n\n\n\n\n\n\n\n\nFeb 21, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScala\n\n\n\n\n\n\n\n\n\n\n\nJan 4, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBayesian\n\n\nScala\n\n\n\n\n\n\n\n\n\n\n\nDec 13, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScala\n\n\nBayesian\n\n\n\n\n\n\n\n\n\n\n\nDec 12, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScala\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2016\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Jonny Law is a senior data scientist at the National Innovation Centre for Data, working closely with external collaborators to teach them data skills to deliver real world data science projects. Previously he was a Statistics PhD student on the Cloud Computing for Big Data CDT."
  },
  {
    "objectID": "notebooks/rainier_linear_model.html",
    "href": "notebooks/rainier_linear_model.html",
    "title": "blog-quarto",
    "section": "",
    "text": "import $ivy.`com.stripe::rainier-core:0.2.2`\nimport com.stripe.rainier.core._\nimport com.stripe.rainier.sampler._\nimport $ivy.`com.stripe::rainier-plot:0.2.2`\n\n\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                               \n\u001b[39m\n\u001b[32mimport \u001b[39m\u001b[36mcom.stripe.rainier.core._\n\u001b[39m\n\u001b[32mimport \u001b[39m\u001b[36mcom.stripe.rainier.sampler._\n\u001b[39m\n\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                               \u001b[39m\n\n\n\nval (alpha, beta, sigma) =  (-1.5, 2.0, 0.5)\n\n// using sampling monad to create synthetic data\nval lm = for {\n    x <- Normal(0, 1).param\n    y <- Normal(alpha + beta * x, sigma).param\n} yield (x, y)\n\nimplicit val s = RNG.default\nval sims = lm.sample(100)\n\n\u001b[36malpha\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m-1.5\u001b[39m\n\u001b[36mbeta\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m2.0\u001b[39m\n\u001b[36msigma\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.5\u001b[39m\n\u001b[36mlm\u001b[39m: \u001b[32mRandomVariable\u001b[39m[(\u001b[32mcom\u001b[39m.\u001b[32mstripe\u001b[39m.\u001b[32mrainier\u001b[39m.\u001b[32mcompute\u001b[39m.\u001b[32mReal\u001b[39m, \u001b[32mcom\u001b[39m.\u001b[32mstripe\u001b[39m.\u001b[32mrainier\u001b[39m.\u001b[32mcompute\u001b[39m.\u001b[32mReal\u001b[39m)] = com.stripe.rainier.core.RandomVariable@303a2c9e\n\u001b[36ms\u001b[39m: \u001b[32mRNG\u001b[39m = \u001b[33mScalaRNG\u001b[39m(\u001b[32m1555339946882L\u001b[39m)\n\u001b[36msims\u001b[39m: \u001b[32mList\u001b[39m[(\u001b[32mDouble\u001b[39m, \u001b[32mDouble\u001b[39m)] = \u001b[33mList\u001b[39m(\n  (\u001b[32m-0.27247704057213673\u001b[39m, \u001b[32m-2.937174139009242\u001b[39m),\n  (\u001b[32m0.904706738880923\u001b[39m, \u001b[32m0.2873337749353697\u001b[39m),\n  (\u001b[32m0.852183004859444\u001b[39m, \u001b[32m0.21651653790799275\u001b[39m),\n  (\u001b[32m-0.39035717167844597\u001b[39m, \u001b[32m-1.7128969360400819\u001b[39m),\n  (\u001b[32m-0.39035717167844597\u001b[39m, \u001b[32m-1.7128969360400819\u001b[39m),\n  (\u001b[32m-0.32022958270507923\u001b[39m, \u001b[32m-2.6778655637209248\u001b[39m),\n  (\u001b[32m-0.46351051511185715\u001b[39m, \u001b[32m-2.191504684058077\u001b[39m),\n  (\u001b[32m-0.46351051511185715\u001b[39m, \u001b[32m-2.191504684058077\u001b[39m),\n  (\u001b[32m-0.46351051511185715\u001b[39m, \u001b[32m-2.191504684058077\u001b[39m),\n  (\u001b[32m-0.46351051511185715\u001b[39m, \u001b[32m-2.191504684058077\u001b[39m),\n  (\u001b[32m1.3771155460388853\u001b[39m, \u001b[32m1.3365959279685458\u001b[39m),\n  (\u001b[32m-0.49530687121967953\u001b[39m, \u001b[32m-1.833522063303271\u001b[39m),\n  (\u001b[32m1.0768869181666785\u001b[39m, \u001b[32m0.2563581689102623\u001b[39m),\n  (\u001b[32m1.0768869181666785\u001b[39m, \u001b[32m0.2563581689102623\u001b[39m),\n  (\u001b[32m-1.0116365008420507\u001b[39m, \u001b[32m-3.752541734789177\u001b[39m),\n  (\u001b[32m2.7476547917502754\u001b[39m, \u001b[32m3.8144224426177082\u001b[39m),\n  (\u001b[32m2.7476547917502754\u001b[39m, \u001b[32m3.8144224426177082\u001b[39m),\n  (\u001b[32m-1.9494596187935684\u001b[39m, \u001b[32m-5.97285704598621\u001b[39m),\n  (\u001b[32m-0.029076281551169814\u001b[39m, \u001b[32m-1.2606332122515638\u001b[39m),\n  (\u001b[32m0.8957907429984171\u001b[39m, \u001b[32m0.7423301548354151\u001b[39m),\n  (\u001b[32m0.8957907429984171\u001b[39m, \u001b[32m0.7423301548354151\u001b[39m),\n  (\u001b[32m0.8957907429984171\u001b[39m, \u001b[32m0.7423301548354151\u001b[39m),\n  (\u001b[32m0.8957907429984171\u001b[39m, \u001b[32m0.7423301548354151\u001b[39m),\n  (\u001b[32m0.8957907429984171\u001b[39m, \u001b[32m0.7423301548354151\u001b[39m),\n  (\u001b[32m0.8957907429984171\u001b[39m, \u001b[32m0.7423301548354151\u001b[39m),\n  (\u001b[32m0.8957907429984171\u001b[39m, \u001b[32m0.7423301548354151\u001b[39m),\n  (\u001b[32m0.8957907429984171\u001b[39m, \u001b[32m0.7423301548354151\u001b[39m),\n  (\u001b[32m0.0023588460061185756\u001b[39m, \u001b[32m-1.3506243761132446\u001b[39m),\n  (\u001b[32m-0.0935197030194973\u001b[39m, \u001b[32m-1.3679664205943545\u001b[39m),\n  (\u001b[32m-0.0935197030194973\u001b[39m, \u001b[32m-1.3679664205943545\u001b[39m),\n  (\u001b[32m-0.0935197030194973\u001b[39m, \u001b[32m-1.3679664205943545\u001b[39m),\n  (\u001b[32m-0.0935197030194973\u001b[39m, \u001b[32m-1.3679664205943545\u001b[39m),\n  (\u001b[32m-0.0935197030194973\u001b[39m, \u001b[32m-1.3679664205943545\u001b[39m),\n  (\u001b[32m0.9936677194000182\u001b[39m, \u001b[32m0.027360397529156755\u001b[39m),\n  (\u001b[32m-0.5437438839438696\u001b[39m, \u001b[32m-2.9048447906186814\u001b[39m),\n  (\u001b[32m0.5717862996712749\u001b[39m, \u001b[32m-0.14270893763715198\u001b[39m),\n  (\u001b[32m0.5717862996712749\u001b[39m, \u001b[32m-0.14270893763715198\u001b[39m),\n  (\u001b[32m1.5491575238352386\u001b[39m, \u001b[32m1.3029810178933499\u001b[39m),\n...\n\n\n\nimport com.cibo.evilplot.numeric.Point\nimport com.cibo.evilplot.plot._\nimport com.cibo.evilplot.plot.renderers.PointRenderer\nimport com.cibo.evilplot.plot.aesthetics.DefaultTheme._\n\ndef renderBytes(plot: com.cibo.evilplot.plot.Plot) = {\n    val baos = new java.io.ByteArrayOutputStream\n    javax.imageio.ImageIO\n      .write(\n        plot.render().asBufferedImage,\n        \"png\",\n        baos)\n    val array = baos.toByteArray\n    baos.close\n    array\n}\n\n\u001b[32mimport \u001b[39m\u001b[36mcom.cibo.evilplot.numeric.Point\n\u001b[39m\n\u001b[32mimport \u001b[39m\u001b[36mcom.cibo.evilplot.plot._\n\u001b[39m\n\u001b[32mimport \u001b[39m\u001b[36mcom.cibo.evilplot.plot.renderers.PointRenderer\n\u001b[39m\n\u001b[32mimport \u001b[39m\u001b[36mcom.cibo.evilplot.plot.aesthetics.DefaultTheme._\n\n\u001b[39m\ndefined \u001b[32mfunction\u001b[39m \u001b[36mrenderBytes\u001b[39m\n\n\n\nimport almond.interpreter.api._\n\nDisplayData\n  .png(renderBytes(ScatterPlot(\n      sims.map { case (x, y) => Point(x, y) }\n    ).xAxis()\n     .yAxis()\n     .frame()\n     .rightLegend()))\n .show()\n\n\n\n\n\u001b[32mimport \u001b[39m\u001b[36malmond.interpreter.api._\n\n\u001b[39m\n\n\n\nimport com.stripe.rainier.compute._\n// import com.stripe.rainier.core._\n// import com.stripe.rainier.sampler._\n\ndef linearModel(data: Seq[(Double, Double)]): RandomVariable[Map[String, Real]] = for {\n    alpha <- Normal(0, 5).param\n    beta <- Normal(0, 5).param\n    sigma <- LogNormal(2, 2).param\n    _ <- Predictor[Double].from { x =>\n      Normal(alpha + beta * x, sigma)\n    }\n    .fit(data)\n  } yield Map(\"alpha\" -> alpha, \"beta\" -> beta, \"sigma\" -> sigma)\n\n\u001b[32mimport \u001b[39m\u001b[36mcom.stripe.rainier.compute._\n// import com.stripe.rainier.core._\n// import com.stripe.rainier.sampler._\n\n\u001b[39m\ndefined \u001b[32mfunction\u001b[39m \u001b[36mlinearModel\u001b[39m\n\n\n\nval iters = linearModel(sims).sample(HMC(5), 5000, 100000, 100)\n\n\u001b[36miters\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mMap\u001b[39m[\u001b[32mString\u001b[39m, \u001b[32mDouble\u001b[39m]] = \u001b[33mList\u001b[39m(\n  \u001b[33mMap\u001b[39m(\n    \u001b[32m\"alpha\"\u001b[39m -> \u001b[32m-1.5103698284824398\u001b[39m,\n    \u001b[32m\"beta\"\u001b[39m -> \u001b[32m2.1544564171494365\u001b[39m,\n    \u001b[32m\"sigma\"\u001b[39m -> \u001b[32m0.41662922813248277\u001b[39m\n  ),\n  \u001b[33mMap\u001b[39m(\n    \u001b[32m\"alpha\"\u001b[39m -> \u001b[32m-1.5184685380426082\u001b[39m,\n    \u001b[32m\"beta\"\u001b[39m -> \u001b[32m2.151465637838073\u001b[39m,\n    \u001b[32m\"sigma\"\u001b[39m -> \u001b[32m0.44342253807901993\u001b[39m\n  ),\n  \u001b[33mMap\u001b[39m(\n    \u001b[32m\"alpha\"\u001b[39m -> \u001b[32m-1.4660649259572445\u001b[39m,\n    \u001b[32m\"beta\"\u001b[39m -> \u001b[32m2.109083551551442\u001b[39m,\n    \u001b[32m\"sigma\"\u001b[39m -> \u001b[32m0.4400355956497668\u001b[39m\n  ),\n  \u001b[33mMap\u001b[39m(\n    \u001b[32m\"alpha\"\u001b[39m -> \u001b[32m-1.4109510885911971\u001b[39m,\n    \u001b[32m\"beta\"\u001b[39m -> \u001b[32m2.1277107205510815\u001b[39m,\n    \u001b[32m\"sigma\"\u001b[39m -> \u001b[32m0.4686446685131451\u001b[39m\n  ),\n  \u001b[33mMap\u001b[39m(\n    \u001b[32m\"alpha\"\u001b[39m -> \u001b[32m-1.5024888711982174\u001b[39m,\n    \u001b[32m\"beta\"\u001b[39m -> \u001b[32m2.177295567537438\u001b[39m,\n    \u001b[32m\"sigma\"\u001b[39m -> \u001b[32m0.4441577745103689\u001b[39m\n  ),\n  \u001b[33mMap\u001b[39m(\n    \u001b[32m\"alpha\"\u001b[39m -> \u001b[32m-1.5198813109824225\u001b[39m,\n    \u001b[32m\"beta\"\u001b[39m -> \u001b[32m2.17897636639043\u001b[39m,\n    \u001b[32m\"sigma\"\u001b[39m -> \u001b[32m0.5047230361547242\u001b[39m\n  ),\n  \u001b[33mMap\u001b[39m(\n    \u001b[32m\"alpha\"\u001b[39m -> \u001b[32m-1.4834223247926301\u001b[39m,\n    \u001b[32m\"beta\"\u001b[39m -> \u001b[32m2.172806338771708\u001b[39m,\n    \u001b[32m\"sigma\"\u001b[39m -> \u001b[32m0.48139800434682717\u001b[39m\n  ),\n  \u001b[33mMap\u001b[39m(\n    \u001b[32m\"alpha\"\u001b[39m -> \u001b[32m-1.544972407765386\u001b[39m,\n    \u001b[32m\"beta\"\u001b[39m -> \u001b[32m2.1307286606911577\u001b[39m,\n...\n\n\n\nimport com.cibo.evilplot.geometry._\nimport com.stripe.rainier.plot._\n\ndef traces(out: Seq[Map[String, Double]],\n         truth: Map[String, Double] = Map(),\n         lagMax: Int = 40,\n         numBars: Int = 50): Unit =\n    DisplayData\n      .png(\n        EvilTracePlot.renderBytes(\n          EvilTracePlot.traces(out, truth, lagMax, numBars),\n          Extent(1200, out.head.keys.size * 300.0)))\n      .show()\n\n  def pairs(out: Seq[Map[String, Double]],\n            truth: Map[String, Double] = Map(),\n            numBars: Int = 30): Unit =\n    DisplayData\n      .png(\n        EvilTracePlot.renderBytes(EvilTracePlot.pairs(out, truth, numBars),\n                                  Extent(out.head.keys.size * 300.0,\n                                         out.head.keys.size * 300.0)))\n      .show()\n\n\u001b[32mimport \u001b[39m\u001b[36mcom.cibo.evilplot.geometry._\n\u001b[39m\n\u001b[32mimport \u001b[39m\u001b[36mcom.stripe.rainier.plot._\n\n\u001b[39m\ndefined \u001b[32mfunction\u001b[39m \u001b[36mtraces\u001b[39m\ndefined \u001b[32mfunction\u001b[39m \u001b[36mpairs\u001b[39m\n\n\n\ntraces(iters, truth = Map(\"alpha\" -> -1.5, \"beta\" -> 2.0, \"sigma\" -> 0.5))"
  },
  {
    "objectID": "notebooks/multi_armed_bandit.html",
    "href": "notebooks/multi_armed_bandit.html",
    "title": "blog-quarto",
    "section": "",
    "text": "import $ivy.`com.stripe::rainier-core:0.2.2`\nimport $ivy.`com.stripe::rainier-plot:0.2.2`\nimport $ivy.`org.scalanlp::breeze:0.13.2`\n\n\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                               \n\u001b[39m\n\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                               \n\u001b[39m\n\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                            \u001b[39m\n\n\n\nimport breeze.stats.distributions._\nimport breeze.linalg._\nimport almond.interpreter.api._\n\n\u001b[32mimport \u001b[39m\u001b[36mbreeze.stats.distributions._\n\u001b[39m\n\u001b[32mimport \u001b[39m\u001b[36mbreeze.linalg._\n\u001b[39m\n\u001b[32mimport \u001b[39m\u001b[36malmond.interpreter.api._\u001b[39m\n\n\n\ncase class BanditState(\n    reward: Array[Double],\n    longTermReward: List[Double],\n    actions: Map[Int, Int]\n)\n\ndef banditStep(\n    epsilon: Double,\n    reward: Int => Rand[Double])(s: BanditState): Rand[BanditState] = {\n    for {\n        u <- Uniform(0, 1)\n        nextAction <- if (u < epsilon) {\n          Multinomial(DenseVector.ones[Double](s.actions.size))\n        } else {\n          Rand.always(s.longTermReward.zipWithIndex.maxBy(_._1)._2)\n        }\n        newReward <- reward(nextAction)\n        prevCount = s.actions.get(nextAction).get\n        nextCount  = prevCount + 1\n        newLongTermReward = s.longTermReward(nextAction) + (newReward - s.longTermReward(nextAction)) / nextCount\n    } yield BanditState(s.reward :+ newReward, \n                s.longTermReward.updated(nextAction, newLongTermReward),\n                s.actions.updated(nextAction, nextCount))\n}\n\ndefined \u001b[32mclass\u001b[39m \u001b[36mBanditState\u001b[39m\ndefined \u001b[32mfunction\u001b[39m \u001b[36mbanditStep\u001b[39m\n\n\n\ndef buildActions(actions: Int): Map[Int, Int] = {\n    (0 until actions).map(a => a -> 0).toMap\n}\n\ndef bandit(\n    epsilon: Double, \n    actions: Int, \n    reward: Int => Rand[Double],\n    n: Int): BanditState = {\n    \n    val initState = BanditState(Array(0.0), List.fill(10)(0.0), buildActions(actions))\n    MarkovChain(initState)(banditStep(epsilon, reward)).steps.drop(n-1).next\n}\n\ndefined \u001b[32mfunction\u001b[39m \u001b[36mbuildActions\u001b[39m\ndefined \u001b[32mfunction\u001b[39m \u001b[36mbandit\u001b[39m\n\n\n\nval qs = Gaussian(0, 1).sample(10)\n\n// The reward is selected from a N(q(A_t), 1)\ndef r(qa: Seq[Double])(action: Int): Rand[Double] = \n    Gaussian(qa(action), 1)\n\n\u001b[36mqs\u001b[39m: \u001b[32mIndexedSeq\u001b[39m[\u001b[32mDouble\u001b[39m] = \u001b[33mVector\u001b[39m(\n  \u001b[32m-1.1319170735731177\u001b[39m,\n  \u001b[32m0.5392647196381599\u001b[39m,\n  \u001b[32m0.7127636875526561\u001b[39m,\n  \u001b[32m0.8765526115252499\u001b[39m,\n  \u001b[32m-0.9555744042626685\u001b[39m,\n  \u001b[32m-0.2723645491439034\u001b[39m,\n  \u001b[32m0.10029206857194808\u001b[39m,\n  \u001b[32m0.3758538986470721\u001b[39m,\n  \u001b[32m1.9412629812694995\u001b[39m,\n  \u001b[32m1.0620845496569054\u001b[39m\n)\ndefined \u001b[32mfunction\u001b[39m \u001b[36mr\u001b[39m\n\n\n\nimport com.cibo.evilplot.numeric.Point\nimport com.cibo.evilplot.plot._\nimport com.cibo.evilplot.plot.renderers.PointRenderer\nimport com.cibo.evilplot.plot.aesthetics.DefaultTheme._\n\ndef renderBytes(plot: com.cibo.evilplot.plot.Plot) = {\n    val baos = new java.io.ByteArrayOutputStream\n    javax.imageio.ImageIO\n      .write(\n        plot.render().asBufferedImage,\n        \"png\",\n        baos)\n    val array = baos.toByteArray\n    baos.close\n    array\n}\n\n\u001b[32mimport \u001b[39m\u001b[36mcom.cibo.evilplot.numeric.Point\n\u001b[39m\n\u001b[32mimport \u001b[39m\u001b[36mcom.cibo.evilplot.plot._\n\u001b[39m\n\u001b[32mimport \u001b[39m\u001b[36mcom.cibo.evilplot.plot.renderers.PointRenderer\n\u001b[39m\n\u001b[32mimport \u001b[39m\u001b[36mcom.cibo.evilplot.plot.aesthetics.DefaultTheme._\n\n\u001b[39m\ndefined \u001b[32mfunction\u001b[39m \u001b[36mrenderBytes\u001b[39m\n\n\n\n// plot distribution of rewards\nval oneBandit = bandit(0.5, 10, r(qs), 1000)\nDisplayData.png(renderBytes(\n    BarChart(oneBandit.actions.toList.sortBy(_._1).map(_._2.toDouble).toSeq)\n  .standard(xLabels = oneBandit.actions.keys.toSeq.sorted.map(_.toString))\n  .hline(0))).show()\n\n\n\n\n\u001b[36moneBandit\u001b[39m: \u001b[32mBanditState\u001b[39m = \u001b[33mBanditState\u001b[39m(\n  \u001b[33mArray\u001b[39m(\n    \u001b[32m0.0\u001b[39m,\n    \u001b[32m2.976100360524757\u001b[39m,\n    \u001b[32m3.320624254718964\u001b[39m,\n    \u001b[32m1.735391673758119\u001b[39m,\n    \u001b[32m-0.1178421782132375\u001b[39m,\n    \u001b[32m-0.4267401704485142\u001b[39m,\n    \u001b[32m0.05976466063572933\u001b[39m,\n    \u001b[32m1.9647217525681615\u001b[39m,\n    \u001b[32m-1.1268489919523372\u001b[39m,\n    \u001b[32m-0.11423861554973747\u001b[39m,\n    \u001b[32m-1.6367143503567467\u001b[39m,\n    \u001b[32m1.169397937010581\u001b[39m,\n    \u001b[32m0.804300072782806\u001b[39m,\n    \u001b[32m2.2835936434257436\u001b[39m,\n    \u001b[32m2.31290098287337\u001b[39m,\n    \u001b[32m2.6236486501806926\u001b[39m,\n    \u001b[32m2.836115544022664\u001b[39m,\n    \u001b[32m-0.7839856021716222\u001b[39m,\n    \u001b[32m2.054859432324436\u001b[39m,\n    \u001b[32m2.474021337551546\u001b[39m,\n    \u001b[32m-0.9610215574366667\u001b[39m,\n    \u001b[32m-1.6665573871211612\u001b[39m,\n    \u001b[32m3.263486902771481\u001b[39m,\n    \u001b[32m2.737138911325928\u001b[39m,\n    \u001b[32m-0.15454857068858474\u001b[39m,\n    \u001b[32m2.4385642340240636\u001b[39m,\n    \u001b[32m1.6016866119680087\u001b[39m,\n    \u001b[32m2.2073837929940456\u001b[39m,\n    \u001b[32m2.4998150437397846\u001b[39m,\n    \u001b[32m0.1438041237245966\u001b[39m,\n    \u001b[32m0.3606162721163373\u001b[39m,\n    \u001b[32m2.6577340535039324\u001b[39m,\n    \u001b[32m2.769632524242227\u001b[39m,\n    \u001b[32m-0.9252861813602815\u001b[39m,\n    \u001b[32m0.2816266052603311\u001b[39m,\n    \u001b[32m-0.7243237512391794\u001b[39m,\n    \u001b[32m2.1141386653850893\u001b[39m,\n...\n\n\n\n// Calculate the average reward for n 10-arm bandit models with steps and an epsilon-greedy method\ndef averageReward(n: Int, steps: Int, epsilon: Double) = {\n    Vector.fill(n)(DenseVector(bandit(epsilon, 10, r(qs), steps).reward)).\n      reduce(_ + _).map(_ / n)\n}\n\ndefined \u001b[32mfunction\u001b[39m \u001b[36maverageReward\u001b[39m\n\n\n\nval aveReward = averageReward(2000, 1000, 0.1)\n\n\u001b[36maveReward\u001b[39m: \u001b[32mDenseVector\u001b[39m[\u001b[32mDouble\u001b[39m] = DenseVector(0.0, -0.9426273839522797, 0.26889712041848457, 0.5332672833580145, 0.5592108247423051, 0.6056358871271748, 0.6515241800245118, 0.6513086554499391, 0.6469931829377825, 0.7089842469243052, 0.66667240644473, 0.7082220589822795, 0.6853350709144816, 0.7442480967859841, 0.7333679234328236, 0.7605616555788542, 0.7801774338435793, 0.7875742317521988, 0.7732938950479266, 0.8079389127764451, 0.8242092185211091, 0.8290599121138151, 0.8357268085155818, 0.8389036026370922, 0.8517266494247785, 0.9054726316177655, 0.8760328141792109, 0.846222974505453, 0.9673659214993594, 0.9233230163685952, 0.9002610917535993, 0.9365621510181116, 0.9786856617181927, 0.9568787318575506, 0.9858490289296279, 1.0167017081287388, 0.9870224011843569, 1.0060798711049337, 0.9998857746758901, 1.0421054630796218, 1.0537332007460791, 1.0282931280576844, 1.008952977774679, 1.0208445677717755, 1.0609347426367055, 1.063006707436476, 1.1229697215325798, 1.1047251761098666, 1.0750978812332435, 1.0637026844581847, 1.044110375235368, 1.0871876789703356, 1.1361526682238134, 1.0998171039116673, 1.1067374106604526, 1.1187018654439462, 1.11406880822824, 1.1211580215969423, 1.2217583726618366, 1.1117763214366856, 1.202746571669961, 1.1175687889316082, 1.1687978370134444, 1.158946227844552, 1.1445647356816222, 1.1723152709976914, 1.2078232412185232, 1.2044329739573876, 1.2402679470908902, 1.221340076568395, 1.210372112996346, 1.2689220026593333, 1.2466216910696593, 1.2300418463866867, 1.2329017925945553, 1.2169757468020392, 1.24098331044688, 1.285691235524763, 1.2723049598010796, 1.2115234624264228, 1.2710862846166213, 1.2748234748664855, 1.2778862507391775, 1.26089794890763, 1.2969402741388933, 1.3083834410562216, 1.3390144723914494, 1.2799534082483122, 1.283972091301586, 1.3169671093943474, 1.3226623432625997, 1.371082382179368, 1.3059059090159557, 1.341233705468368, 1.3525439216310706, 1.3327781491140327, 1.3488428304311613, 1.3798159534769794, 1.3102183991308147, 1.3779276106494664, 1.3589120420117637, 1.3615370817894483, 1.3457615967007528, 1.3437871060320017, 1.366949911471863, 1.4306957713206283, 1.3952829655539205, 1.3773138300349317, 1.393695083868195, 1.4185595938682236, 1.3845740293270234, 1.4402617308191383, 1.398781349231281, 1.3959982596473264, 1.402891587101111, 1.4031552482217666, 1.372635843278831, 1.4116859349928343, 1.4216975607903832, 1.396273353462508, 1.423202773739358, 1.4620562656917628, 1.4370669784171992, 1.4404995591594736, 1.4327330922413717, 1.4445663107942428, 1.4596576272120672, 1.442270358405475, 1.434162625432162, 1.4136193053465973, 1.3981555709280917, 1.4132299354096591, 1.4774129862802015, 1.4615110852019135, 1.5013439841409684, 1.4479353223146718, 1.4445405594846188, 1.470718475708922, 1.5014365624248451, 1.4881901055958826, 1.4975844712483273, 1.4828395040478874, 1.479019078196321, 1.50122026330989, 1.4926226723844063, 1.5122917658447688, 1.4978513986720534, 1.4950739126339416, 1.470544568397562, 1.5224630921620759, 1.5228875582341996, 1.4899270885891023, 1.5578963147242968, 1.497749379659908, 1.5176067042376695, 1.5592140048882877, 1.5260853671734511, 1.52793284622676...\n\n\n\nimport com.cibo.evilplot.colors._\n\nDisplayData\n  .png(renderBytes(LinePlot(\n      aveReward.data.zipWithIndex.map { case (reward, i) => Point(i, reward) }\n    ).xAxis()\n     .yAxis()\n     .frame()\n     .rightLegend()))\n    .show()\n\n\n\n\n\u001b[32mimport \u001b[39m\u001b[36mcom.cibo.evilplot.colors._\n\n\u001b[39m\n\n\n\nval data = List(0.0, 0.1, 0.5).map ( eps => averageReward(2000, 1000, eps))\n\n\u001b[36mdata\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mDenseVector\u001b[39m[\u001b[32mDouble\u001b[39m]] = \u001b[33mList\u001b[39m(\n  DenseVector(0.0, -1.1743418790174853, 0.35628118154928096, 0.5444696198591045, 0.5745606123166515, 0.6011450064897833, 0.5860773160902875, 0.5773192948707362, 0.6551587600060409, 0.5929344059996865, 0.5869891978253066, 0.6014580560135625, 0.6169564700220459, 0.5993058562938953, 0.6159423995554062, 0.6226857540763373, 0.6156850091288895, 0.6482916431567618, 0.640230448244355, 0.6096791692857781, 0.5982924317357214, 0.6281804628861618, 0.6580875948509916, 0.6529535208980511, 0.6277957845742601, 0.6118020854733205, 0.6207439444919087, 0.6174124716245961, 0.6550331741316631, 0.6787972980107534, 0.6652070981057305, 0.612624838887662, 0.6552392240239654, 0.6820328585412322, 0.6446805628306075, 0.6682485541461307, 0.5799194256892576, 0.6647312818453811, 0.6418572597763432, 0.6186361430485355, 0.6287827275585954, 0.6523453583739043, 0.624009376918104, 0.6627575698581933, 0.6271505262888047, 0.6339295931690959, 0.655056139945157, 0.610440048793048, 0.6220973276208756, 0.6322237969848977, 0.630797178609878, 0.6545291942294472, 0.5920511636837023, 0.6721112028269238, 0.6161950339401036, 0.6505110182847058, 0.6056621622597791, 0.6509239953441854, 0.6252523509892426, 0.6852113025337538, 0.6523623631515703, 0.6403555410450873, 0.6341030781350059, 0.6903426060321238, 0.669665695549045, 0.6289699384630263, 0.657796077789866, 0.6134818488054002, 0.6124570271985275, 0.648432373414623, 0.6297617605729152, 0.6074966530419048, 0.6408810207352252, 0.6224466170503861, 0.6426170517168279, 0.6432779479630143, 0.6561074988331979, 0.6561066784835532, 0.6404149047476678, 0.6465317431598067, 0.6141865936483053, 0.6115193617225554, 0.6383768283041388, 0.6426062740682565, 0.6421199219086939, 0.6676076912549134, 0.6184663594716678, 0.6542091107939056, 0.6576180710989459, 0.6293987101899263, 0.6746111012092391, 0.6163739624525272, 0.6654324203853992, 0.624978877382943, 0.6394716773784885, 0.6466701642515587, 0.6998975641448953, 0.6285383747543807, 0.6413674058309872, 0.6103415533420439, 0.6274717198512721, 0.622152579290014, 0.6405989717286007, 0.6412012240617898, 0.6669345600290717, 0.6036561244657609, 0.6367993337412386, 0.6410077413526751, 0.6502858903886694, 0.65101902799816, 0.6607314578728575, 0.6594020286143406, 0.6655186029132041, 0.6194330303902904, 0.6292285870115212, 0.6095720639847764, 0.6756467115634871, 0.6424586054782403, 0.6058456513208611, 0.6444500356462737, 0.6675573698385395, 0.6302633158262844, 0.63001431310584, 0.6639881424437367, 0.619476440968879, 0.6405843357833966, 0.6611547370335453, 0.6050136941232428, 0.6483212606023441, 0.6542035407918955, 0.6307883067887196, 0.6573647322650826, 0.6433138611240464, 0.6639350351247647, 0.6618821622645878, 0.6369749882847818, 0.6468443941613019, 0.6312061841487676, 0.6491135957146563, 0.6326055217007085, 0.6226406996992059, 0.6501656872952037, 0.6319005317272793, 0.6347849639964621, 0.6309577926887223, 0.6741348791075593, 0.6388141317970568, 0.6196265358433113, 0.6590366459038346, 0.6548802451903392, 0.6455008008423934, 0.6186049030879386, 0.6172035179522...\n\n\n\nimport com.cibo.evilplot.plot.renderers.PathRenderer\nimport com.cibo.evilplot.colors._\n\nDisplayData\n  .png(renderBytes(Overlay(\n        LinePlot(data(0).data.zipWithIndex.map { case (reward, i) => Point(i, reward) },\n                Some(PathRenderer.named(\"epsilon = 0.0\", HTMLNamedColors.dodgerBlue))),\n        LinePlot(data(1).data.zipWithIndex.map { case (reward, i) => Point(i, reward) },\n                Some(PathRenderer.named(\"epsilon = 0.0\", HTMLNamedColors.red))),\n        LinePlot(data(2).data.zipWithIndex.map { case (reward, i) => Point(i, reward) },\n                Some(PathRenderer.named(\"epsilon = 0.0\", HTMLNamedColors.green)))\n       )\n  .title(\"A Bunch of Bandits\")\n  .bottomLegend()\n  .standard()))\n   .show()\n\ncmd64.sc:7: type mismatch;\n found   : Some[com.cibo.evilplot.plot.renderers.PathRenderer[Nothing]]\n required: Option[com.cibo.evilplot.plot.renderers.PathRenderer[com.cibo.evilplot.numeric.Point]]\n                Some(PathRenderer.named(\"epsilon = 0.0\", HTMLNamedColors.dodgerBlue))),\n                    ^Compilation Failed\n\n\n:"
  },
  {
    "objectID": "about.html#skills",
    "href": "about.html#skills",
    "title": "About",
    "section": "Skills",
    "text": "Skills\n\nPython\nR\nScala\nSQL\nBayesian Statistics\nTime series analysis\nMachine Learning\nDeep Learning"
  },
  {
    "objectID": "about.html#projects",
    "href": "about.html#projects",
    "title": "About",
    "section": "Projects",
    "text": "Projects\nBayesian State Space Model\ngit.io/dlm A Scala library for Dynamic Linear Models, with filtering and parameter inference algorithms\nGaussian Processes\ngit.io/gaussianprocesses A Scala library for Gaussian Processes\nComposable POMP Models\ngit.io/statespace A Scala library for online Bayesian filtering of univariate state space models, sometimes called POMP (Partially Observed Markov Process Models).%"
  }
]