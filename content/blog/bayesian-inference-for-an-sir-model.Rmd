---
title: 'Bayesian Inference for an SIR Model'
author: Jonny Law
date: '2020-03-27'
slug: bayesian-inference-for-an-sir-model
categories:
  - R
  - Bayesian
tags: []
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyr)
library(dplyr)
library(readr)
library(ggplot2)
library(jonnylaw)
library(deSolve)
theme_set(theme_minimal())
```

[Johns Hopkins University](https://github.com/CSSEGISandData/COVID-19) have put together a repository containing confirmed cases of COVID19, deaths and recovered patients. Below we plot the confirmed cases, confirmed recovered and deaths.

```{r read-covid-data, echo=FALSE}
confirmed <- readr::read_rds(url("https://github.com/jonnylaw/blog/blob/master/data/confirmed.Rds?raw=true"))
covid_deaths <- readr::read_rds(url("https://github.com/jonnylaw/blog/blob/master/data/covid_deaths.Rds?raw=true"))
recovered <- readr::read_rds(url("https://github.com/jonnylaw/blog/blob/master/data/recovered.Rds?raw=true"))

united_kingdom <- covid_deaths %>% 
  filter(country_region == "United Kingdom") %>% 
  inner_join(confirmed) %>% 
  inner_join(recovered) %>% 
  group_by(country_region, date) %>% 
  summarise_at(vars(deaths:recovered), sum, na.rm = TRUE) %>% 
  ungroup() %>% 
  arrange(date)
```

```{r echo=FALSE}
united_kingdom %>%
  pivot_longer(deaths:recovered, names_to = "state", values_to = "value") %>%
  mutate(label = if_else(date == max(date), state, NA_character_)) %>%
  ggplot(aes(x = date, y = value, group = state, colour = state)) +
  geom_line() +
  ggrepel::geom_label_repel(aes(label = label),
                            nudge_x = 1,
                            na.rm = TRUE) +
  scale_y_log10() +
  labs(title = paste(
    "COVID-19 confirmed cases, deaths and recoveries in UK to",
    scales::date_format(format = "%d %b %Y")(max(united_kingdom$date))),
    y = "Total", x = "Date") +
  scale_x_date(
    labels = scales::date_format(format = "%d %b"),
    breaks = seq(
      from = min(united_kingdom$date),
      to = max(united_kingdom$date),
      by = "week"
    )
  ) +
  theme(legend.position = "none")
```

## SIR Model

The system of ordinary differential equations (ODE) for the Susceptible Infected Recovered (SIR) model is given by

$$\begin{align}
& \frac{dS}{dt} = - \frac{\beta I S}{N}, \\
& \frac{dI}{dt} = \frac{\beta I S}{N}- \gamma I, \\
& \frac{dR}{dt} = \gamma I,\\
& N = S + I + R.
\end{align}$$

Where $S$ is the number of susceptible, $I$ the total infected and $R$ the total recovered. $\gamma$ is the recovery rate ($1/\gamma$ is the infectious period), $\beta$ is the infection rate ($1/\beta$ is the time between contacts). These parameters are unobserved.

We can Use `deSolve` to solve the ODE system startin with an initial state of 66.4 million people susceptible and one infected. This produces a simulation conditional on the parameters chosen. The parameters can change depending on each countries reaction to the virus. For instance the infection rate can be lowered by quarantine or social distancing, thus reducing 

```{r}
parameters <- c(beta = 0.5, gamma = 1/4.5)
initial_state <- c(S = 66.4e6, I = 1, R = 0) 

sir <- function(t, state, parameters) {
  with(as.list(c(state, parameters)), {
    N <- sum(S, I, R)
    dS = -beta * S * I / N
    dI = beta * S * I / N - gamma * I
    dR = gamma * I
    
    list(c(dS, dI, dR))
  })  
}

times <- seq_len(100)
out <- ode(y = initial_state, times = times, func = sir, parms = parameters)
```

```{r echo=FALSE}
out %>% 
  tibble::as_tibble() %>% 
  gather(key = state, value, -time) %>% 
  mutate(state = factor(state, levels = c("S", "I", "R"))) %>%
  ggplot(aes(x = time, y = value, colour = state)) +
  geom_line() +
  labs(x = "Time (Days)", y = "Population") +
  scale_y_continuous(labels = scales::number_format(big.mark = ","))
```

Consider the model in [this pre-print from Lourenco et al 2020](https://www.dropbox.com/s/oxmu2rwsnhi9j9c/Draft-COVID-19-Model%20%2813%29.pdf), which has since been criticised in [this response](https://www.bmj.com/content/bmj/368/bmj.m1216.full.pdf). We observe the cumulative deaths

$$\Lambda_t = \rho\eta R_{t-\psi},$$

where $\rho$ is the proportion of the population at risk of severe disease, $\theta$ is the probability of dying with the severe disease. $R_{t-\psi}$ is the removed population with a delay between the time of infection represented by $\psi$. The parameters are given prior distributions in the paper, we can simulate multiple trajectories of the cumulative deaths by first simulating from the prior distribution then solving the SIR system. The prior distributions as given in the paper are

$$\begin{aligned}
  \frac{1}{\gamma} &\sim \mathcal{N}(4.5, 1^2), \\
  \psi &\sim \mathcal{n}(17, 2^2), \\
  R_0 &\sim \mathcal{n}(2.25, 0.2^2), \\
  \eta &\sim \mathcal{n}(0.14, 0.007^2), \\
  \rho &\sim \text{Gamma}(5, 5/0.01).
\end{aligned}$$

There is also a parameter for the time of introduction relative to the time of the first reported case, $\tau$. It has a strange prior distribution, being uniform from $-\infty$ to $\infty$. Obviously this parameter can not be positive, since a confirmed case indicates that the time of introduction is in the past.

```{r echo = FALSE}
sim_prior <- function() {
  r0 <- rnorm(1, mean = 2.25, sd = 0.2)
  gamma <- 1/rnorm(1, mean = 4.5, sd = 1)
  rho <- rgamma(1, shape = 5, rate = 5/0.01)
  eta <- rnorm(1, mean = 0.14, sd = 0.007)
  psi <- rnorm(1, mean = 17, sd = 2)
  
  c(r0 = r0, gamma = gamma, rho = rho, eta = eta, psi = psi, beta = r0 * gamma)
}

cumulative_deaths <- function(t, R, parameters) {
  R[max(1, t - floor(parameters["psi"]))] * parameters["rho"] * parameters["eta"]
}

simulate_sir <- function(times, initial_state, params) {
  sir <- function(t, state, parameters) {
    with(as.list(c(state, parameters)), {
      N <- sum(S, I, R)
      dS = -beta * S * I / N
      dI = beta * S * I / N - gamma * I
      dR = gamma * I
      
      list(c(dS, dI, dR))
    })  
  }

  sim <- ode(y = initial_state, times = times, func = sir, parms = params)
  
  sim %>% 
    tibble::as_tibble() %>% 
    tibble::add_column(cumulative_deaths = 
                 purrr::map_dbl(sim[, 1], ~ cumulative_deaths(t = .x, sim[, 4], params)))
}

m <- 1e2
sims <-
  purrr::map_dfr(
    .x = seq_len(m),
    ~ sim_prior() %>% simulate_sir(
      times = seq_len(100),
      initial_state = c(S = 66.44e6, I = 116 * 10, R = 8),
      params = .
    ),
    .id = "replicate"
  )

sims %>% 
  ggplot(aes(x = time, y = cumulative_deaths, group = replicate)) + 
  geom_line(alpha = 0.5) +
  labs(title = tools::toTitleCase(paste0(m, " simulations of the cumulative deaths")),
       x = "Day", y = "Cumulative Deaths") +
  scale_y_continuous(labels = scales::number_format(big.mark = ","))
```

We can simulate more times from the prior and calculate the empirical intervals instead of plotting raw trajectories. The initial state is $S = 66.44 \times 10^6$, $I = 1$ and $R = 0$. The initial time is taken to be one week before the first confirmed case in the UK.

```{r echo=FALSE}
m <- 1e3
uk <- united_kingdom %>% filter(date > "2020-01-25")
sims <-
  purrr::map_dfr(
    .x = seq_len(m),
    ~ sim_prior() %>% 
      simulate_sir(times = seq_len(nrow(uk)), 
                   initial_state = c(S = 66.44e6, I = 1, R = 0),
                   params = .),
    .id = "replicate"
  )

sims %>% 
  group_by(time) %>% 
  tidybayes::median_qi(cumulative_deaths, .width = 0.5) %>% 
  bind_cols(uk) %>% 
  ggplot(aes(x = date, y = cumulative_deaths)) + 
  geom_line(alpha = 0.5) +
  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = 0.5, colour = NA) +
  geom_point(aes(y = deaths)) +
  labs(title = "Prior simulations of cumulative deaths", 
       subtitle = "The solid line is the prior median and the shaded area is a 50% credible interval") +
  scale_y_log10(labels = scales::number_format(big.mark = ",", accuracy = 1)) +
  scale_x_date(
    labels = scales::date_format(format = "%d %b"),
    breaks = seq(
      from = min(united_kingdom$date),
      to = max(united_kingdom$date),
      by = "week"
    )
  )
```

## Inference method

The inference method is explained clearly in [Louren√ßo et al (2017)](https://elifesciences.org/articles/29820), albeit with a different model. The Metropolis algorithm with a symmetric random walk proposal distribution is used, the likelihood is the product of independent Poisson distributions

$$\mathcal{L}(y_{1:T}|\Lambda_{1:T}, \theta^\star) = \prod_{t=1}^T\left(\textrm{Poisson}(y_t;\Lambda_t)\right)$$

The steps to perform inference for the static parameters are summarised below

1. Propose new (log) parameters from a symmetric Normal distribution $\log(\theta^\star) \sim \mathcal{N}(\log\theta^\star\mid\log\theta, \sigma I_d)$
2. Solve the ODE using the `deSolve` package using the proposed parameters
3. Calculate the un-normalised log-posterior $\log p(\Lambda_{1:T}, \theta^\star\mid y_{1:T}) = \log p(\theta) +\sum_{t=1}^T\log\left(\textrm{Poisson}(y_t\mid\Lambda_t)\right)$
3. Accept the new parameters with probability $\alpha$ where 

$$\alpha = \min\left(1, \frac{p(\Lambda_{1:T}, \theta^\star\mid y_{1:T})}{p(\Lambda_{1:T}, \theta\mid y_{1:T})}\right).$$ 

First we specify the likelihood in R.

```{r specify-likelihood-prior}
log_likelihood_sir <- function(parameters, ys, initial_state) {
  initial_state <- c(S = 60e6, I = 1, R = 0) # 
  
  # Transition function
  sir <- function(t, state, parameters) {
    beta <- parameters[1] * parameters[2]
    gamma <- parameters[2]
    
    with(as.list(state), {
      N <- sum(S, I, R)
      dS = -beta * S * I / N
      dI = beta * S * I / N - gamma * I
      dR = gamma * I
      
      list(c(dS, dI, dR))
    })  
  }
  
  sir_sim <-
    deSolve::ode(
      y = initial_state,
      times = seq_along(ys),
      func = sir,
      parms = parameters
    )
  
  cumulative_deaths <- function(t, R, parameters) {
    R[max(1, t - parameters[5])] * parameters[3] * parameters[4]
  }
  
  lambdas <- purrr::map_dbl(sir_sim[, 1], ~ cumulative_deaths(t = .x, sir_sim[, 4], parameters))
  
  ll <- sum(dpois(x = ys, lambda = lambdas, log = TRUE))
  
  if_else(is.nan(ll) || is.na(ll), -Inf, ll)
}
```

Then we specify the prior distributions.

```{r}
log_prior <- function(parameters) {
  r0 = parameters[1]; gamma = parameters[2]; rho = parameters[3]
  eta = parameters[4]; psi = parameters[5]
  
  dnorm(1/gamma, mean = 4.5, sd = 1, log = TRUE) +
    dnorm(psi, mean = 17, sd = 2, log = TRUE) +
    dnorm(r0, mean = 2.25, sd = 0.2, log = TRUE) +
    dnorm(eta, mean = 0.14, sd = 0.007, log = TRUE) +
    dgamma(rho, shape = 5, rate = 5/0.01, log = TRUE)
}

proposal <- function(p) {
  p * exp(rnorm(5, sd = c(0.02, 0.02, 0.02, 0.02, 0.05)))
}
```

We initialise the parameters at the mean of the prior distributions and simulate 1 million iterations from the Metropolis algorithm. The first half are discarded and every 100th iteration is retained in an attempt to reduce auto-correlation in the chain.

```{r metropolis-samples, cache=TRUE}
initial_parameters <- c(r0 = 2.25, gamma = 1/4.5, rho = 0.01, eta = 0.14, psi = 17)
ys <- uk %>% pull(deaths)
iters <-
  jonnylaw::metropolis(
    theta = initial_parameters,
    function(p) log_likelihood_sir(ys = ys, parameters = p) + log_prior(p),
    proposal = proposal,
    1e6, 
    chains = 2, 
    parallel = TRUE
  )
```

I have cached the results of the chunk running the Metropolis algorithm. The results can be loaded using `lazyLoad` - this is useful for long-running Rmarkdown chunks.

```{r eval=FALSE}
lazyLoad(here::here("content/blog/bayesian-inference-for-an-sir-model_cache/html/metropolis-samples_2dc7aa7ffb05056136d67d8c3b755b58"))
```

```{r traceplots, echo=FALSE}
# Add iteration number to the output for each chain
iters <- iters %>% 
  group_by(chain) %>% 
  mutate(iteration = row_number())

iters %>% 
  filter(iteration > 1e6 / 2) %>%
  filter(iteration %% 100 == 0) %>% 
  group_by(chain) %>% 
  mutate(iteration = row_number()) %>% 
  pivot_longer(-c("chain", "iteration"), names_to = "parameter") %>% 
  ggplot(aes(x = iteration, y = value, colour = chain)) +
  geom_line() +
  facet_wrap(~parameter, scales = "free_y", ncol = 1, strip.position = "right") +
  theme(legend.position = "none")
```

```{r densities, echo=FALSE}
iters %>% 
  filter(iteration > 1e6 / 2) %>%
  filter(iteration %% 100 == 0) %>% 
  mutate(beta = r0 * gamma) %>% 
  pivot_longer(-c("chain", "iteration"), names_to = "parameter") %>% 
  ggplot(aes(x = value, colour = parameter, fill = parameter)) +
  geom_histogram(alpha = 0.5, position = "identity") +
  facet_wrap(~parameter, scales = "free") +
  theme(legend.position = "none")
```

The next plot shows both the prior and posterior distribution. The prior is the solid black line and the posterior samples are plotted in a histogram. Most of the prior distributions are narrow and hence have resulted in little change. The posterior mean of the infectious period, $1/gamma$ is approximately 4 days, down from the prior mean of 4.5. The posterior mean of $\psi$ is, 13.5, 3.5 days shorter than the prior mean. 

```{r}
prior_posterior <- function(parameter, prior, limits) {
  iters %>%
    filter(iteration > 1e6 / 2) %>%
    filter(iteration %% 100 == 0) %>% 
    ggplot(aes(x = !!enquo(parameter))) +
    geom_histogram(aes(y = ..density.., colour = 'Posterior', fill = "Posterior"), alpha = 0.5) +
    stat_function(fun = prior, xlim = limits) +
    theme(legend.position = "none")
}

p1 <- prior_posterior(eta, ~dnorm(x = ., mean = 0.14, sd = 0.007), limits = c(0.1, 0.2))
p2 <- prior_posterior(gamma, ~dnorm(x = 1/., mean = 4.5, sd = 1), limits = c(0.1, 0.5))
p3 <- prior_posterior(psi, ~dnorm(x = ., mean = 17, sd = 2), limits = c(8, 25))
p4 <- prior_posterior(r0, ~dnorm(x = ., mean = 2.25, sd = 0.2), limits = c(1.5, 3))
p5 <- prior_posterior(rho, ~dgamma(x = ., shape = 5, rate = 5 / 0.01), limits = c(0, 0.1))

(p1 | p2 | p3) / (p4 | p5)
```

Now plot the posterior cumulative death curve.

```{r plot-posterior, echo=FALSE}
iters %>% 
  filter(iteration > 1e6 / 2) %>%
  filter(iteration %% 100 == 0) %>%
  sample_n(size = 1000) %>% 
  apply(1, function(row) {
    params <- as.numeric(row[c("r0", "gamma", "rho", "eta", "psi")])
    names(params) <- names(initial_parameters)
    beta = params["r0"] * params["gamma"]
    names(beta) <- "beta"
    simulate_sir(times = seq_len(nrow(uk)), 
                 initial_state = c(S = 66.44e6, I = 1, R = 0),
                 params = c(params, beta))
  }) %>% 
  dplyr::bind_rows(.id = "replicate") %>% 
  group_by(time) %>% 
  tidybayes::median_qi(cumulative_deaths, .width = 0.95) %>% 
  bind_cols(uk) %>% 
  ggplot(aes(x = date)) + 
  geom_line(aes(y = cumulative_deaths), alpha = 0.5) +
  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = 0.5, colour = NA) +
  geom_point(aes(y = deaths)) +
  labs(title = "Posterior simulations of cumulative deaths", 
       subtitle = "The solid line is the posterior median and the shaded area is a 95% credible interval.\nThe points indicate the observed cumulative deaths in the UK") +
  scale_y_log10(labels = scales::number_format(big.mark = ",", accuracy = 1)) +
  scale_x_date(
    labels = scales::date_format(format = "%d %b"),
    breaks = seq(
      from = min(united_kingdom$date),
      to = max(united_kingdom$date),
      by = "week"
    )
  )
```

Let's simulate forward 100 days from the hypothesised start date, 2020-01-26 using the posterior distribution.

```{r}
days <- 100

iters %>% 
  filter(iteration > 1e6 / 2) %>%
  filter(iteration %% 100 == 0) %>% 
  sample_n(size = 1000) %>% 
  apply(1, function(row) {
    params <- as.numeric(row[c("r0", "gamma", "rho", "eta", "psi")])
    names(params) <- names(initial_parameters)
    beta = params["r0"] * params["gamma"]
    names(beta) <- "beta"
    simulate_sir(times = seq_len(days), 
                 initial_state = c(S = 66.44e6, I = 1, R = 0),
                 params = c(params, beta)) %>% 
    tibble::add_column(date = seq(from = as.Date("2020-01-26"), length.out = days, by = "day"))
  }) %>% 
  dplyr::bind_rows(.id = "replicate") %>% 
  gather(key, value, S, I, R, cumulative_deaths) %>% 
  group_by(date, key) %>% 
  tidybayes::median_qi(value, .width = 0.95) %>% 
  ggplot(aes(x = date)) + 
  geom_line(aes(y = value, colour = key), alpha = 0.5) +
  geom_ribbon(aes(ymin = .lower, ymax = .upper, fill = key), alpha = 0.5, colour = NA) +
  scale_y_continuous(labels = scales::number_format(big.mark = ",")) +
  facet_wrap(vars(key), scales = "free_y") +
  theme(legend.position = "none")
```


